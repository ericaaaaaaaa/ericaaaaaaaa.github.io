<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-03-08T20:13:35+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Erica’s Blog</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name>ericaaaaaaaa</name></author><entry><title type="html">现代软件工程</title><link href="http://localhost:4000/softwareengineering/2022/03/08/ModernSoftwareEngineering.html" rel="alternate" type="text/html" title="现代软件工程" /><published>2022-03-08T00:00:00+08:00</published><updated>2022-03-08T00:00:00+08:00</updated><id>http://localhost:4000/softwareengineering/2022/03/08/ModernSoftwareEngineering</id><content type="html" xml:base="http://localhost:4000/softwareengineering/2022/03/08/ModernSoftwareEngineering.html">&lt;h1 id=&quot;读书笔记构建之法现代软件工程&quot;&gt;【读书笔记】构建之法：现代软件工程&lt;/h1&gt;

&lt;h1 id=&quot;第一章-概论&quot;&gt;第一章 概论&lt;/h1&gt;

&lt;h2 id=&quot;11-软件--程序--软件工程&quot;&gt;1.1 软件 = 程序 + 软件工程&lt;/h2&gt;

&lt;p&gt;一个复杂的软件不但要有合理的软件架构 (Software Architecture)、软件设计与实现 (software Design, Implementation and Debug)，还要有各种文件和数据来描述各个程序文件之间的依赖关系、编译参数、链接参数，等等。&lt;/p&gt;

&lt;h2 id=&quot;12-软件工程是什么&quot;&gt;1.2 软件工程是什么&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;软件工程&lt;/strong&gt;是把系统的、有序的、可量化的方法应用到软件的开发、运营和维护上的过程。&lt;/p&gt;

&lt;p&gt;软件工程包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;软件需求分析&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;软件设计&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;软件构件&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;软件测试&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;软件维护&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;121-软件的特殊性&quot;&gt;1.2.1 软件的特殊性&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;复杂性 (Complexity)&lt;/li&gt;
  &lt;li&gt;不可见性 (Invisibility)&lt;/li&gt;
  &lt;li&gt;易变性 (Changeability)&lt;/li&gt;
  &lt;li&gt;服从性 (Conformity)&lt;/li&gt;
  &lt;li&gt;非连续型 (Discontinuity)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;122-软件工程与计算机科学的关系&quot;&gt;1.2.2 软件工程与计算机科学的关系&lt;/h3&gt;

&lt;p&gt;工程：创造性的运用科学原理，设计和实现建筑、及其、装置或生产过程；或者是在实践中使用一个或多个上述实体；或者是在实现这些实体的过程。&lt;/p&gt;

&lt;h3 id=&quot;123-软件工程的知识领域&quot;&gt;1.2.3 软件工程的知识领域&lt;/h3&gt;

&lt;h3 id=&quot;124-软件工程的目标构建足够好的软件&quot;&gt;1.2.4 软件工程的目标——构建“足够好”的软件&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;用户满意度&lt;/li&gt;
  &lt;li&gt;可靠性&lt;/li&gt;
  &lt;li&gt;软件流程的质量&lt;/li&gt;
  &lt;li&gt;可维护性&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;研发出符合用户需求的软件说明&lt;/li&gt;
  &lt;li&gt;通过一定的软件流程，在预计时间内发布“足够好”的软件说明&lt;/li&gt;
  &lt;li&gt;通过数据和其他方式展现所开发的软件是可以维护和继续发展的说明&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;软件的种类&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ShrinkWrap （在包装盒子里面的软件）&lt;/li&gt;
  &lt;li&gt;Web APP （基于网页的软件）&lt;/li&gt;
  &lt;li&gt;Internal Software （企业或学校或某组织内部的软件）&lt;/li&gt;
  &lt;li&gt;Games （游戏）&lt;/li&gt;
  &lt;li&gt;Mobile Apps （手机应用）&lt;/li&gt;
  &lt;li&gt;Operating Systems （操作系统）&lt;/li&gt;
  &lt;li&gt;Tools （工具软件）&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;第二章-个人技术和流程&quot;&gt;第二章 个人技术和流程&lt;/h1&gt;

&lt;p&gt;PSP (Personal Software Process) 个人软件开发流程&lt;/p&gt;

&lt;h2 id=&quot;单元测试&quot;&gt;单元测试&lt;/h2&gt;

&lt;h3 id=&quot;211-用-vsts-写单元测试&quot;&gt;2.1.1 用 VSTS 写单元测试&lt;/h3&gt;

&lt;h3 id=&quot;212-好的单元测试的标准&quot;&gt;2.1.2 好的单元测试的标准&lt;/h3&gt;

&lt;p&gt;单元测试应该准确、快速地保证程序基本模块的正确性。&lt;/p&gt;

&lt;p&gt;单元测试需要有程序的作者编写，因为代码作者最了解代码的目的、特点和实现的局限性。&lt;/p&gt;

&lt;p&gt;单元测试应：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;速度快&lt;/li&gt;
  &lt;li&gt;认为构造数据，而非用随机数（可能导致错误不可复现）&lt;/li&gt;
  &lt;li&gt;覆盖所有代码路径，包括错误处理路径&lt;/li&gt;
  &lt;li&gt;测试公开的和私有的函数 / 方法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;100% 代码覆盖率不能保证 100% 程序正确性：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;未处理问题，如内存未释放&lt;/li&gt;
  &lt;li&gt;代码效能问题&lt;/li&gt;
  &lt;li&gt;多线程环境中的同步问题&lt;/li&gt;
  &lt;li&gt;其他与外部条件相关的问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;单元测试的运行与维护&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;团队一般在每日构建之后运行单元测试&lt;/li&gt;
  &lt;li&gt;单元测试一般与产品代码一起保存和维护&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;213-回归测试&quot;&gt;2.1.3 回归测试&lt;/h3&gt;

&lt;p&gt;在单元测试的基础上，建立关于某一模块的回归测试 (Regression Test)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Regress: return to a worse or less developed state.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;一旦有关的测试用例通过，我们就得到了此模块的功能基准线 (Baseline)，一个模块的所有单元测试就是这个模块最初的 Baseline。&lt;/p&gt;

&lt;p&gt;工程师们应该在新版本上运行所有已通过的测试用例，以验证有没有“退化”情况发生。&lt;/p&gt;

&lt;p&gt;如果倒退是由于模块功能发生了正常变化引起的，那么要修改测试用例，以便和新功能保持一致。&lt;/p&gt;

&lt;p&gt;针对一个 Bug Fix，也要做 Regression Test，目的是：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;验证新代码的确改正了缺陷&lt;/li&gt;
  &lt;li&gt;同时验证新代码有没有破坏模块的现有功能，有没有 Regression&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;回归测试最好自动化，因为这样就可以对每一个构建你快速运行所有的回归测试。&lt;/p&gt;

&lt;p&gt;在一个项目的最后稳定阶段，需要做全面的回归测试，确保所有已修复的 Bug 的确得到了修复，且没有复发。&lt;/p&gt;

&lt;p&gt;除回归测试外，还有功能测试——从用户的角度检查功能的完成情况。&lt;/p&gt;

&lt;h2 id=&quot;效能分析工具&quot;&gt;效能分析工具&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;抽样 (Sampling)
    &lt;ul&gt;
      &lt;li&gt;当程序运行时，每隔一段时间记录程序运行在哪个函数内，得到程序运行时间的大致印象&lt;/li&gt;
      &lt;li&gt;优点：无需改动程序，运行较快&lt;/li&gt;
      &lt;li&gt;缺点：结果不精确，不能准确表示代码中的调用关系树 (Call Tree)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;代码注入 (Instrumentation)
    &lt;ul&gt;
      &lt;li&gt;将检测的代码注入到每个函数中&lt;/li&gt;
      &lt;li&gt;优点：测量结果精确&lt;/li&gt;
      &lt;li&gt;缺点：程序运行时间长&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;效能分析名词&lt;/th&gt;
      &lt;th&gt;含义&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;调用者 Caller&lt;/td&gt;
      &lt;td&gt;函数 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Foo()&lt;/code&gt; 调用了 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Bar()&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Foo()&lt;/code&gt; 就是调用者&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;被调用函数 Callee&lt;/td&gt;
      &lt;td&gt;见上，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Bar()&lt;/code&gt; 就是被调用函数&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;调用关系树 Call Tree&lt;/td&gt;
      &lt;td&gt;从程序的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Main()&lt;/code&gt; 函数开始，调用者和被调用函数形成树形关系——调用树&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;消失时间 Elapsed Time&lt;/td&gt;
      &lt;td&gt;从用户的角度看程序运行所花的时间。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;应用程序事件 Application Time&lt;/td&gt;
      &lt;td&gt;应用程序占用 CPU 的事件，不包括调用者使用时间&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;本函数时间 Exclusive Time&lt;/td&gt;
      &lt;td&gt;所有在本函数花费的时间，不包括被调用者使用的时间&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;所有时间 Inclusive Time&lt;/td&gt;
      &lt;td&gt;包含本函数和所有调用者使用的时间&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;个人开发流程&quot;&gt;个人开发流程&lt;/h2&gt;

&lt;h1 id=&quot;第三章-软件工程师的成长&quot;&gt;第三章 软件工程师的成长&lt;/h1&gt;

&lt;h2 id=&quot;个人能力的衡量与发展&quot;&gt;个人能力的衡量与发展&lt;/h2&gt;

&lt;p&gt;软件开发的工作量与质量衡量标准&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;项目的大小
    &lt;ul&gt;
      &lt;li&gt;一般用代码行数表示&lt;/li&gt;
      &lt;li&gt;用功能点表示&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;项目耗时&lt;/li&gt;
  &lt;li&gt;项目质量
    &lt;ul&gt;
      &lt;li&gt;代码缺陷与代码行数比&lt;/li&gt;
      &lt;li&gt;re-work 数量（不与最终质量成正比关系）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;项目是否按时交付&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;问题的层次&quot;&gt;问题的层次&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;低层次问题（变成自动操作）&lt;/li&gt;
  &lt;li&gt;中间层次问题（花脑力解决）&lt;/li&gt;
  &lt;li&gt;高层次问题（无暇顾及）&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;第四章-两人合作&quot;&gt;第四章 两人合作&lt;/h1&gt;

&lt;h2 id=&quot;41-代码规范&quot;&gt;4.1 代码规范&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;代码风格规范
主要是文字上的规定&lt;/li&gt;
  &lt;li&gt;代码设计规范
牵涉到程序设计、模块之间的关系、设计模式等通用原则&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;42-代码风格规范&quot;&gt;4.2 代码风格规范&lt;/h2&gt;

&lt;p&gt;代码风格的原则是：简明，易读，无二义性。&lt;/p&gt;

&lt;h3 id=&quot;421-缩进&quot;&gt;4.2.1 缩进&lt;/h3&gt;

&lt;p&gt;用 4 个空格&lt;/p&gt;

&lt;h3 id=&quot;422-行宽&quot;&gt;4.2.2 行宽&lt;/h3&gt;

&lt;p&gt;100 字符&lt;/p&gt;

&lt;h3 id=&quot;423-括号&quot;&gt;4.2.3 括号&lt;/h3&gt;

&lt;p&gt;在复杂的条件表达式中，用括号清楚地表示逻辑优先级&lt;/p&gt;

&lt;h3 id=&quot;424-断行与空白的--行&quot;&gt;4.2.4 断行与空白的 {} 行&lt;/h3&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DoSomething&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DoSomethingElse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;425-分行&quot;&gt;4.2.5 分行&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;不要把多条语句放在一行上&lt;/li&gt;
  &lt;li&gt;更严格地说，不要把多个变量定义在一行上&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;426-命名&quot;&gt;4.2.6 命名&lt;/h3&gt;

&lt;h3 id=&quot;427-下划线&quot;&gt;4.2.7 下划线&lt;/h3&gt;

&lt;p&gt;下划线用来分隔变量名字中的作用域标注和变量的语义。&lt;/p&gt;

&lt;h3 id=&quot;428-大小写&quot;&gt;4.2.8 大小写&lt;/h3&gt;

&lt;p&gt;一个通用的做法是：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;所有的类型 / 类 / 函数名都用 Pascal 形式&lt;/li&gt;
  &lt;li&gt;所有变量都用 Camel 形式。&lt;/li&gt;
  &lt;li&gt;类 / 类型 / 变量用名词或组合名词形式&lt;/li&gt;
  &lt;li&gt;函数用动词或动宾组合词表示&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;429-注释&quot;&gt;4.2.9 注释&lt;/h3&gt;

&lt;p&gt;注释（包括所有源代码）应该只用 ASCII 字符，不用中文或其他特殊字符。&lt;/p&gt;

&lt;h2 id=&quot;43-代码设计规范&quot;&gt;4.3 代码设计规范&lt;/h2&gt;

&lt;h3 id=&quot;431-函数&quot;&gt;4.3.1 函数&lt;/h3&gt;

&lt;h3 id=&quot;432-goto&quot;&gt;4.3.2 goto&lt;/h3&gt;

&lt;p&gt;函数最好有单一的出口，为达到此目的，可以使用 goto&lt;/p&gt;

&lt;h3 id=&quot;433-错误处理&quot;&gt;4.3.3 错误处理&lt;/h3&gt;

&lt;h3 id=&quot;434-如何处理-c-中的类&quot;&gt;4.3.4 如何处理 c++ 中的类&lt;/h3&gt;

&lt;h2 id=&quot;44-代码复审&quot;&gt;4.4 代码复审&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;自我复审&lt;/li&gt;
  &lt;li&gt;同伴复审
    &lt;ul&gt;
      &lt;li&gt;不止一人&lt;/li&gt;
      &lt;li&gt;找熟悉代码且有经验的人&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;团队复审&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;441-为什么要代码复审&quot;&gt;4.4.1 为什么要代码复审&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;发现代码问题
    &lt;ul&gt;
      &lt;li&gt;编码错误&lt;/li&gt;
      &lt;li&gt;风格问题&lt;/li&gt;
      &lt;li&gt;逻辑错误&lt;/li&gt;
      &lt;li&gt;算法错误&lt;/li&gt;
      &lt;li&gt;潜在错误与回归性错误&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;发现可能的改进之处&lt;/li&gt;
  &lt;li&gt;从代码中学习&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;442-代码复审的步骤&quot;&gt;4.4.2 代码复审的步骤&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;代码必须通过编译&lt;/li&gt;
  &lt;li&gt;代码必须通过测试&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;复审结果&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;打回&lt;/li&gt;
  &lt;li&gt;有条件同意&lt;/li&gt;
  &lt;li&gt;放行&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;45-结对编程&quot;&gt;4.5 结对编程&lt;/h2&gt;

&lt;h3 id=&quot;结对编程的优点&quot;&gt;结对编程的优点&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;提供更好的设计质量和代码质量，两人合作解决问题的能力更强&lt;/li&gt;
  &lt;li&gt;带来更多信心，高质量的产出带来满足感&lt;/li&gt;
  &lt;li&gt;更有效的交流，相互学习和传递经验，分享知识，更好的应对人员流动&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;第五章-团队和流程&quot;&gt;第五章 团队和流程&lt;/h1&gt;

&lt;h2 id=&quot;51-非团队和团队&quot;&gt;5.1 非团队和团队&lt;/h2&gt;

&lt;h2 id=&quot;52-软件团队的模式&quot;&gt;5.2 软件团队的模式&lt;/h2&gt;

&lt;h2 id=&quot;53-开发流程&quot;&gt;5.3 开发流程&lt;/h2&gt;

&lt;h3 id=&quot;531-写了再改模式-code-and-fix&quot;&gt;5.3.1 写了再改模式 (Code-and-Fix)&lt;/h3&gt;

&lt;p&gt;适用场景：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;“只用一次”的程序&lt;/li&gt;
  &lt;li&gt;“看过了就扔”的原型&lt;/li&gt;
  &lt;li&gt;一些不实用的演示程序&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;532-瀑布模型-waterfall-model&quot;&gt;5.3.2 瀑布模型 (Waterfall Model)&lt;/h3&gt;

&lt;p&gt;局限性：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;各步骤之间相互分离&lt;/li&gt;
  &lt;li&gt;回溯修改困难，甚至不可能&lt;/li&gt;
  &lt;li&gt;最终产品知道最后才出现&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;532-瀑布模型的各种变形&quot;&gt;5.3.2 瀑布模型的各种变形&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;生鱼片模型&lt;/li&gt;
  &lt;li&gt;大瀑布带小瀑布&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;534-rational-unified-process-rup&quot;&gt;5.3.4 Rational Unified Process (RUP)&lt;/h3&gt;

&lt;p&gt;重计划，重事先设计，重文档表达。&lt;/p&gt;

&lt;p&gt;规程 (Discipline) 或工作流 (Workflow)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;业务建模
    &lt;ul&gt;
      &lt;li&gt;用精确的语言（通常是 UML）把用户的活动描述出来&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;需求
    &lt;ul&gt;
      &lt;li&gt;分析并确认软件系统提供什么样的功能满足用户需求&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分析和设计
    &lt;ul&gt;
      &lt;li&gt;将需求转化成系统设计&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;实现&lt;/li&gt;
  &lt;li&gt;测试&lt;/li&gt;
  &lt;li&gt;部署
    &lt;ul&gt;
      &lt;li&gt;将最终版本分发给最终用户&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;配置和变更管理&lt;/li&gt;
  &lt;li&gt;项目管理
    &lt;ul&gt;
      &lt;li&gt;平衡各种可能产生冲突的目标，管理风险&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;环境
    &lt;ul&gt;
      &lt;li&gt;向软件开发组织提供软件开发环境，包括过程和工具&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;阶段&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;初始阶段
    &lt;ul&gt;
      &lt;li&gt;分析软件系统大概的构成，系统与外部的边界在哪里&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;细化阶段
    &lt;ul&gt;
      &lt;li&gt;分析问题领域，建立健全的体系结构基础，编制项目计划，按优先级处理项目中的风险。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;构造阶段（beta）
    &lt;ul&gt;
      &lt;li&gt;开发出所有的功能集，有秩序地把功能集成为经过各种测试验证过的产品&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;交付阶段
    &lt;ul&gt;
      &lt;li&gt;确保软件能满足最终用户的实际需求&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;535-老板驱动的流程-boss-driven-process&quot;&gt;5.3.5 老板驱动的流程 (Boss-Driven Process)&lt;/h3&gt;

&lt;h3 id=&quot;536-渐进交付的流程-evolutionary-delivery-mvp-和-mbp&quot;&gt;5.3.6 渐进交付的流程 (Evolutionary Delivery), MVP 和 MBP&lt;/h3&gt;

&lt;p&gt;[开发 $\rightarrow$ 发布 $\rightarrow$ 听取反馈 $\rightarrow$ 根据反馈做改进]&lt;/p&gt;

&lt;h1 id=&quot;第六章-敏捷流程&quot;&gt;第六章 敏捷流程&lt;/h1&gt;

&lt;h2 id=&quot;61-敏捷的流程&quot;&gt;6.1 敏捷的流程&lt;/h2&gt;

&lt;h3 id=&quot;611-敏捷开发原则&quot;&gt;6.1.1 敏捷开发原则&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;尽早&lt;/strong&gt;并&lt;strong&gt;持续&lt;/strong&gt;地交付有价值的软件以满足顾客需求&lt;/li&gt;
  &lt;li&gt;敏捷流程欢迎&lt;strong&gt;需求的变化&lt;/strong&gt;，并利用这种变化来提高用户的竞争优势&lt;/li&gt;
  &lt;li&gt;经常发布可用的软件，发布间隔可以从几周到几个月，&lt;strong&gt;能短则短&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;业务人员和开发人员&lt;/strong&gt;在项目开发过程中应该每天共同工作&lt;/li&gt;
  &lt;li&gt;以&lt;strong&gt;有进取心&lt;/strong&gt;的人为项目核心，充分信任他们&lt;/li&gt;
  &lt;li&gt;无论团队内外，&lt;strong&gt;面对面&lt;/strong&gt;的交流始终是最有效的沟通方式&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;可用&lt;/strong&gt;的软件是衡量项目进展的主要指标&lt;/li&gt;
  &lt;li&gt;敏捷流程应能保持可持续发展。领导、团队和用户应该按照目前的步调持续合作下去&lt;/li&gt;
  &lt;li&gt;只有不断关注技术和设计，才能越来越敏捷&lt;/li&gt;
  &lt;li&gt;保持&lt;strong&gt;简明&lt;/strong&gt;——尽可能简化工作量&lt;/li&gt;
  &lt;li&gt;只有能自我管理的软对才能创造优秀的架构、需求和设计&lt;/li&gt;
  &lt;li&gt;时时总结如何提高团队效率，并付诸行动&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;612-敏捷流程概述&quot;&gt;6.1.2 敏捷流程概述&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;找出产品需要做的事情——Product Back-log&lt;/li&gt;
  &lt;li&gt;决定当前的冲刺 (Sprint) 需要解决的事情——Sprint Backlog&lt;/li&gt;
  &lt;li&gt;冲刺 (Sprint)
    &lt;ul&gt;
      &lt;li&gt;每日例会 (Scrum Meeting)&lt;/li&gt;
      &lt;li&gt;燃尽图 (Burn Down Chart)
        &lt;ul&gt;
          &lt;li&gt;实际剩余时间 (Remaining Hour)&lt;/li&gt;
          &lt;li&gt;预估剩余时间 (Projected Remaining Hour)&lt;/li&gt;
          &lt;li&gt;实际花费时间 (Completed Hour)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;看版图 (Kanban)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;得到软件的一个增量版本，发布给用户。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;62-敏捷流程的问题和解法&quot;&gt;6.2 敏捷流程的问题和解法&lt;/h2&gt;

&lt;h2 id=&quot;63-敏捷的团队&quot;&gt;6.3 敏捷的团队&lt;/h2&gt;

&lt;h2 id=&quot;64-敏捷总结&quot;&gt;6.4 敏捷总结&lt;/h2&gt;

&lt;h2 id=&quot;65-敏捷的故事&quot;&gt;6.5 敏捷的故事&lt;/h2&gt;

&lt;h1 id=&quot;第七章-msf&quot;&gt;第七章 MSF&lt;/h1&gt;

&lt;h2 id=&quot;71-msf-简史&quot;&gt;7.1 MSF 简史&lt;/h2&gt;

&lt;h2 id=&quot;72-msf-基本原则&quot;&gt;7.2 MSF 基本原则&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;推动信息共享与沟通 (Foster open communications)&lt;/li&gt;
  &lt;li&gt;为共同的远景而工作 (Work toward a shared vision)&lt;/li&gt;
  &lt;li&gt;充分授权和信任 (Empower team members)&lt;/li&gt;
  &lt;li&gt;各司其职，对项目共同负责 (Establish clear accountability and shared responsibility)&lt;/li&gt;
  &lt;li&gt;交付增量的价值 (Deliver incremental value)&lt;/li&gt;
  &lt;li&gt;保持敏捷，预期和适应变化 (Stay agile, expect and adapt change)&lt;/li&gt;
  &lt;li&gt;投资质量 (Invest in quality)&lt;/li&gt;
  &lt;li&gt;学习所有经验 (Learn from all experiences)&lt;/li&gt;
  &lt;li&gt;与顾客合作 (Partner with internal and external customers)&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;第八章-需求分析&quot;&gt;第八章 需求分析&lt;/h1&gt;

&lt;h2 id=&quot;81-软件需求&quot;&gt;8.1 软件需求&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;获取和引导需求 (Elicitation)
软件企业 = 软件 + 商业模式&lt;/li&gt;
  &lt;li&gt;分析和定义需求 (Analysis &amp;amp; Specification)&lt;/li&gt;
  &lt;li&gt;验证需求 (Validation)&lt;/li&gt;
  &lt;li&gt;在软件产品的生命周期中管理需求 (Management)
    &lt;ul&gt;
      &lt;li&gt;功能性要求&lt;/li&gt;
      &lt;li&gt;产品开发过程的需求&lt;/li&gt;
      &lt;li&gt;非功能性需求（服务质量需求）&lt;/li&gt;
      &lt;li&gt;综合需求&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;82-软件产品的利益相关者&quot;&gt;8.2 软件产品的利益相关者&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;用户（最终用户）&lt;/li&gt;
  &lt;li&gt;顾客（客户）&lt;/li&gt;
  &lt;li&gt;软件工程师&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;83-获取用户需求用户调查&quot;&gt;8.3 获取用户需求——用户调查&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;焦点小组 (Focus Group)
找到目标用户的代表，加上项目的利益相关者&lt;/li&gt;
  &lt;li&gt;深入面谈 (In-depth Interview)&lt;/li&gt;
  &lt;li&gt;卡片分类 (Card Sorting)&lt;/li&gt;
  &lt;li&gt;用户调查问卷 (User Survey)
常见错误
    &lt;ul&gt;
      &lt;li&gt;问题定义不准确&lt;/li&gt;
      &lt;li&gt;使用含糊不清的形容词&lt;/li&gt;
      &lt;li&gt;让用户花额外的努力来回答问题&lt;/li&gt;
      &lt;li&gt;问题带有有引导性的倾向&lt;/li&gt;
      &lt;li&gt;问题涉及用户隐私
问题形式&lt;/li&gt;
      &lt;li&gt;全开放式问题&lt;/li&gt;
      &lt;li&gt;二项选择题&lt;/li&gt;
      &lt;li&gt;多项选择题&lt;/li&gt;
      &lt;li&gt;顺位选择题（优先级）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;用户日志研究 (User Diary Study)&lt;/li&gt;
  &lt;li&gt;人类学调查 (Ethnographic Study)&lt;/li&gt;
  &lt;li&gt;眼动跟踪研究&lt;/li&gt;
  &lt;li&gt;快速原型调研&lt;/li&gt;
  &lt;li&gt;A/B 测试 (A/B Testing)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;84-竞争性需求分析的框架&quot;&gt;8.4 竞争性需求分析的框架&lt;/h2&gt;

&lt;p&gt;NABCD 模型&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;N (Need，需求)&lt;/li&gt;
  &lt;li&gt;A (Approach，做法)&lt;/li&gt;
  &lt;li&gt;B (Benefit，好处)&lt;/li&gt;
  &lt;li&gt;C (Competitors，竞争)&lt;/li&gt;
  &lt;li&gt;D (Delivery，推广)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;85-功能的定位和优先级&quot;&gt;8.5 功能的定位和优先级&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;功能和需求分类&lt;/li&gt;
  &lt;li&gt;杀手功能&lt;/li&gt;
  &lt;li&gt;外围功能&lt;/li&gt;
  &lt;li&gt;必要需求&lt;/li&gt;
  &lt;li&gt;辅助需求&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;做法的分类&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;维持&lt;/li&gt;
  &lt;li&gt;抵消&lt;/li&gt;
  &lt;li&gt;优化&lt;/li&gt;
  &lt;li&gt;差异化&lt;/li&gt;
  &lt;li&gt;不做&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;86-计划和估计&quot;&gt;8.6 计划和估计&lt;/h2&gt;

&lt;p&gt;整个软件项目的时间估计：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;自底向上&lt;/li&gt;
  &lt;li&gt;回溯&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在敏捷开发中不需要精确的估计，只需要粗粒度的估计，然后进入实现阶段并不断复盘即可。&lt;/p&gt;

&lt;h2 id=&quot;87-分而治之-work-breakdown-structure-wbs&quot;&gt;8.7 分而治之 (Work Breakdown Structure, WBS)&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;保证所有子结点覆盖了全部父节点包含的内容&lt;/li&gt;
  &lt;li&gt;保证各个子结点不要相互覆盖&lt;/li&gt;
  &lt;li&gt;叶子结点要保证足够小，能在一个里程碑中完成&lt;/li&gt;
  &lt;li&gt;从结果 (Outcome) 出发构建 WBS，而不是从团队的活动 (Action) 出发&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;第九章-项目经理&quot;&gt;第九章 项目经理&lt;/h1&gt;

&lt;h2 id=&quot;91-pm-是啥&quot;&gt;9.1 PM 是啥&lt;/h2&gt;

&lt;p&gt;PM&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Product Manager: 产品经理&lt;/li&gt;
  &lt;li&gt;Program Manager: 项目经理&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;92-微软-pm-的来历&quot;&gt;9.2 微软 PM 的来历&lt;/h2&gt;

&lt;h1 id=&quot;第十章-典型用户和场景&quot;&gt;第十章 典型用户和场景&lt;/h1&gt;

&lt;h1 id=&quot;第十一章-软件设计与实现&quot;&gt;第十一章 软件设计与实现&lt;/h1&gt;

&lt;h1 id=&quot;第十二章-用户体验&quot;&gt;第十二章 用户体验&lt;/h1&gt;

&lt;h1 id=&quot;第十三章-软件测试&quot;&gt;第十三章 软件测试&lt;/h1&gt;

&lt;h2 id=&quot;131-基本名词解释及分类&quot;&gt;13.1 基本名词解释及分类&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Bug: 软件的缺陷&lt;/li&gt;
  &lt;li&gt;Test Case: 测试用例&lt;/li&gt;
  &lt;li&gt;Test Suite: 测试用例集&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1311-按测试设计的方法分类&quot;&gt;13.1.1 按测试设计的方法分类&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;黑箱 (Black Box)&lt;/li&gt;
  &lt;li&gt;白箱 (White Box)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1312-按测试的目的分类&quot;&gt;13.1.2 按测试的目的分类&lt;/h3&gt;

&lt;h3 id=&quot;1313-按测试的时机和作用分类&quot;&gt;13.1.3 按测试的时机和作用分类&lt;/h3&gt;

&lt;h2 id=&quot;132-各种测试方法&quot;&gt;13.2 各种测试方法&lt;/h2&gt;

&lt;h3 id=&quot;1321-单元测试-unit-test&quot;&gt;13.2.1 单元测试 (Unit Test)&lt;/h3&gt;

&lt;h3 id=&quot;1322-代码覆盖率测试-code-coverage-analysis&quot;&gt;13.2.2 代码覆盖率测试 (Code Coverage Analysis)&lt;/h3&gt;

&lt;h3 id=&quot;1323-构建验证测试-build-verification-test-bvt&quot;&gt;13.2.3 构建验证测试 (Build Verification Test, BVT)&lt;/h3&gt;

&lt;h3 id=&quot;1324-验收测试-acceptance-test&quot;&gt;13.2.4 验收测试 (Acceptance Test)&lt;/h3&gt;

&lt;h3 id=&quot;1325-探索式的测试-ad-hoc-test&quot;&gt;13.2.5 “探索式”的测试 (Ad hoc Test)&lt;/h3&gt;

&lt;h3 id=&quot;1326-回归测试-regression-test&quot;&gt;13.2.6 回归测试 (Regression Test)&lt;/h3&gt;

&lt;h3 id=&quot;1327-场景--集成--系统测试-scenario--integration--system-test&quot;&gt;13.2.7 场景 / 集成 / 系统测试 (Scenario / Integration / System Test)&lt;/h3&gt;

&lt;h3 id=&quot;1328-伙伴测试-buddy-test&quot;&gt;13.2.8 伙伴测试 (Buddy Test)&lt;/h3&gt;

&lt;h3 id=&quot;1329-效能测试-performance-test&quot;&gt;13.2.9 效能测试 (Performance Test)&lt;/h3&gt;

&lt;h3 id=&quot;13210-压力测试-stress-test&quot;&gt;13.2.10 压力测试 (Stress Test)&lt;/h3&gt;

&lt;h3 id=&quot;13211-内部--外部公开测试-alpha--beta-test&quot;&gt;13.2.11 内部 / 外部公开测试 (Alpha / Beta Test)&lt;/h3&gt;

&lt;h3 id=&quot;13212-易用性测试-usability-test&quot;&gt;13.2.12 易用性测试 (Usability Test)&lt;/h3&gt;

&lt;h3 id=&quot;13213-小强大扫荡-bug-bash&quot;&gt;13.2.13 “小强”大扫荡 (Bug Bash)&lt;/h3&gt;

&lt;h1 id=&quot;第十四章-质量保障&quot;&gt;第十四章 质量保障&lt;/h1&gt;

&lt;h2 id=&quot;141-软件的质量&quot;&gt;14.1 软件的质量&lt;/h2&gt;

&lt;h2 id=&quot;1411-程序的质量&quot;&gt;14.1.1 程序的质量&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;准确度 (Precision)&lt;/li&gt;
  &lt;li&gt;覆盖率 (Recall)&lt;/li&gt;
  &lt;li&gt;速度&lt;/li&gt;
  &lt;li&gt;吞吐量&lt;/li&gt;
  &lt;li&gt;用户数量&lt;/li&gt;
  &lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;1412-软件工程的质量&quot;&gt;14.1.2 软件工程的质量&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;软件开发过程的可见性 (Visibility)&lt;/li&gt;
  &lt;li&gt;软件开发过程的风险控制 (Risk Management)&lt;/li&gt;
  &lt;li&gt;软件内部模块，项目中间阶段的交付质量，项目管理工具的因素&lt;/li&gt;
  &lt;li&gt;软件开发成本的控制 (Cost Control)&lt;/li&gt;
  &lt;li&gt;内部质量指标的完成情况 (Internal Benchmarks)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1413-软件工程的质量&quot;&gt;14.1.3 软件工程的质量&lt;/h3&gt;

&lt;p&gt;CMMI (Capacity Maturity Model Integrated，能力成熟度模型集成)&lt;/p&gt;

&lt;h1 id=&quot;第十五章-稳定和发布阶段&quot;&gt;第十五章 稳定和发布阶段&lt;/h1&gt;

&lt;h1 id=&quot;第十六章-it-行业的创新&quot;&gt;第十六章 IT 行业的创新&lt;/h1&gt;

&lt;h1 id=&quot;第十七章-人绩效和职业道德&quot;&gt;第十七章 人、绩效和职业道德&lt;/h1&gt;</content><author><name>ericaaaaaaaa</name></author><category term="SoftwareEngineering" /><category term="book-report" /><category term="software-engineering" /><summary type="html">【读书笔记】构建之法：现代软件工程</summary></entry><entry><title type="html">提问的智慧</title><link href="http://localhost:4000/others/2022/03/05/HowToAskQuestion.html" rel="alternate" type="text/html" title="提问的智慧" /><published>2022-03-05T00:00:00+08:00</published><updated>2022-03-05T00:00:00+08:00</updated><id>http://localhost:4000/others/2022/03/05/HowToAskQuestion</id><content type="html" xml:base="http://localhost:4000/others/2022/03/05/HowToAskQuestion.html">&lt;center&gt;&lt;h1&gt;提问的智慧&lt;/h1&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;提问的目的绝不是为了轻而易举地获得答案，而是为了逐步培养自己的思考能力，去形成自己分析问题、解决问题的思路。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;提问前&quot;&gt;提问前&lt;/h2&gt;

&lt;h3 id=&quot;试图寻找答案&quot;&gt;试图寻找答案&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;手册&lt;/li&gt;
  &lt;li&gt;FAQ&lt;/li&gt;
  &lt;li&gt;网络 (Google)&lt;/li&gt;
  &lt;li&gt;熟人&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;准备好问题&quot;&gt;准备好问题&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;前提是否正确&lt;/li&gt;
  &lt;li&gt;说明&lt;strong&gt;做了哪些准备&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;说明&lt;strong&gt;期待的结果&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;准备好心态&quot;&gt;准备好心态&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;可能无法得到回答&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;提问时&quot;&gt;提问时&lt;/h2&gt;

&lt;h3 id=&quot;谨慎选择论坛&quot;&gt;谨慎选择论坛&lt;/h3&gt;

&lt;p&gt;难度、方向、面向人群&lt;/p&gt;

&lt;h3 id=&quot;语言组织&quot;&gt;语言组织&lt;/h3&gt;

&lt;p&gt;用词贴切、语法正确、拼写无误&lt;/p&gt;

&lt;h3 id=&quot;标题选择&quot;&gt;标题选择&lt;/h3&gt;

&lt;p&gt;使用含义丰富、描述准确的标题&lt;/p&gt;

&lt;h3 id=&quot;内容描述&quot;&gt;内容描述&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;谨慎明确的描述症状&lt;/li&gt;
  &lt;li&gt;提供发生问题的环境
    &lt;ul&gt;
      &lt;li&gt;操作系统&lt;/li&gt;
      &lt;li&gt;环境配置&lt;/li&gt;
      &lt;li&gt;版本&lt;/li&gt;
      &lt;li&gt;……&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;说明提问前的理解&lt;/li&gt;
  &lt;li&gt;说明提问前的尝试&lt;/li&gt;
  &lt;li&gt;罗列近期可能有影响的软硬件变更&lt;/li&gt;
  &lt;li&gt;话不在多&lt;/li&gt;
  &lt;li&gt;只说症状，&lt;strong&gt;不说猜想&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;按时间顺序列出症状&lt;/li&gt;
  &lt;li&gt;明白想问什么&lt;/li&gt;
  &lt;li&gt;不要问应该自己解决的问题&lt;/li&gt;
  &lt;li&gt;去除无意义的提问&lt;/li&gt;
  &lt;li&gt;谦逊的提问
    &lt;ul&gt;
      &lt;li&gt;在提问中预先道谢&lt;/li&gt;
      &lt;li&gt;在收到回答后也发出感谢&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;提问模板&quot;&gt;提问模板&lt;/h3&gt;

&lt;h4 id=&quot;工具使用&quot;&gt;工具使用&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;我使用XXXX程序时，环境情况是（操作系统版本，浏览器版本，…）,我做了XXX操作，结果出现了XXX问题，我在搜索引擎上找到XXX解答，我的理解是XXXX，我操作时出现了XXXX问题，还是无法解决问题，我也请教了同学ＸＸＸ，也没有解决问题，老师，您能帮我看看是怎么回事吗？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;教材学习&quot;&gt;教材学习&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;在每个问题后面，请说明哪一章节的什么内容引起了你的提问，提供一些&lt;strong&gt;上下文&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;列出一些&lt;strong&gt;事例或资料&lt;/strong&gt;，支持你的提问 。&lt;/li&gt;
  &lt;li&gt;说说你&lt;strong&gt;提问题的原因&lt;/strong&gt;，你说因为自己的假设和书中的不同而提问，还是不懂书中的术语，还是对推理过程有疑问，还是书中的描述和你的经验（直接经验或间接经验）矛盾?&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;我看了这一段文字 （引用文字），有这个问题 （提出问题）。 我查了资料，有这些说法（引用说法），根据我的实践，我得到这些经验（描述自己的经验）。 但是我还是不太懂，我的困惑是（说明困惑）。
【或者】我反对作者的观点（提出作者的观点，自己的观点，以及理由）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;教材代码&quot;&gt;教材代码&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;教材ＰXX代码运行结查为什么是xxxx呢？我原来认为这个地方应该是XXX，我写的代码的码云链接是XXXX。
教材ＰXX代码第X行是什么意思？这个问题我查找了XXXX资料，我的困惑是XXX。我写的代码的码云链接是XXXX。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;提问后&quot;&gt;提问后&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;问题解决
    &lt;ul&gt;
      &lt;li&gt;发个简短的说明，表达谢意，说明实践情况&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;问题未解决
    &lt;ul&gt;
      &lt;li&gt;不要重复发帖&lt;/li&gt;
      &lt;li&gt;先尝试搜索资料，说明做过的努力再提出新问题&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;问题无答案
    &lt;ul&gt;
      &lt;li&gt;不要重复发帖&lt;/li&gt;
      &lt;li&gt;向产品公司寻求帮助&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.dianbo.org/9238/stone/tiwendezhihui.htm&quot;&gt;提问的智慧 D.H.Grand&lt;/a&gt;
[2] &lt;a href=&quot;https://www.cnblogs.com/rocedu/p/5167941.html&quot;&gt;如何提问 娄老师&lt;/a&gt;&lt;/p&gt;</content><author><name>ericaaaaaaaa</name></author><category term="Others" /><category term="others" /><summary type="html">提问的智慧</summary></entry><entry><title type="html">计算机网络</title><link href="http://localhost:4000/internet/2022/03/04/Internet.html" rel="alternate" type="text/html" title="计算机网络" /><published>2022-03-04T00:00:00+08:00</published><updated>2022-03-04T00:00:00+08:00</updated><id>http://localhost:4000/internet/2022/03/04/Internet</id><content type="html" xml:base="http://localhost:4000/internet/2022/03/04/Internet.html">&lt;blockquote&gt;
  &lt;p&gt;计算机网络
授课教师：刘轶
E-mail: yi.liu@buaa.edu.cn&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;考核方式&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;平时成绩：10%&lt;/li&gt;
  &lt;li&gt;期末考试：90%&lt;/li&gt;
  &lt;li&gt;考试时间在 6 月上旬&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;课本&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;《计算机网络》（第 8 版）谢系仁&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;参考书&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Computer Networks&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;第一章-概述&quot;&gt;第一章 概述&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Host&lt;/strong&gt;: 主机，在网络中的设备
 &lt;strong&gt;AP&lt;/strong&gt;: 进程&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;11-计算机网络的定义与分类&quot;&gt;1.1 计算机网络的定义与分类&lt;/h2&gt;

&lt;h3 id=&quot;一计算机网络的定义&quot;&gt;一、计算机网络的定义&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;计算机网络&lt;/strong&gt; (Computer Network) 是一些&lt;strong&gt;互相连接&lt;/strong&gt;的、&lt;strong&gt;自治&lt;/strong&gt;的计算机的&lt;strong&gt;集合&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;网络的功能
    &lt;ul&gt;
      &lt;li&gt;连通性&lt;/li&gt;
      &lt;li&gt;资源共享&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;计算机网络与&lt;strong&gt;分布式系统&lt;/strong&gt; (distributed system)
    &lt;ul&gt;
      &lt;li&gt;建立在网络基础上，一组独立的计算机展现给用户的是一个独立的整体。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二计算机网络的分类&quot;&gt;二、计算机网络的分类&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;按作用范围（或覆盖范围）分类
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;广域网&lt;/strong&gt; WAN (Wide Area Network)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;局域网&lt;/strong&gt; LAN (Local Area Network)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;城域网&lt;/strong&gt; MAN (Metropolitan Area Network)
        &lt;ul&gt;
          &lt;li&gt;作用范围通常为一座城市&lt;/li&gt;
          &lt;li&gt;采用局域网技术建立&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;个人区域网&lt;/strong&gt; PAN (Personal Area Network)
        &lt;ul&gt;
          &lt;li&gt;在个人区域内实现各种设备互联的网络，如蓝牙&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;按网络的使用者进行分类
    &lt;ul&gt;
      &lt;li&gt;公用网 (public network)&lt;/li&gt;
      &lt;li&gt;专用网 (private network)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;12-计算机网络与-internet-发展概述&quot;&gt;1.2 计算机网络与 Internet 发展概述&lt;/h2&gt;

&lt;h3 id=&quot;一计算机网络发展的三个阶段&quot;&gt;一、计算机网络发展的三个阶段&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;主机-终端时代&lt;/strong&gt; (20 世纪 50-60 年代)
    &lt;ul&gt;
      &lt;li&gt;计算机以大型主机的形式存在&lt;/li&gt;
      &lt;li&gt;终端通过专用线路或通信网络链接到主机上，实现多用户远程共享主机计算资源&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;主机互联时代&lt;/strong&gt; (20 世纪 60-70 年代)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;网络时代&lt;/strong&gt; (20 世纪 70 年代之后)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二internet-发展概述&quot;&gt;二、Internet 发展概述&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;第一阶段：ARPANET $\rightarrow$ 网际互联发展
    &lt;ul&gt;
      &lt;li&gt;军事产物&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;第二阶段：建成三级结构的 Internet
    &lt;ul&gt;
      &lt;li&gt;网络分为主干网、地区网和校园网（或企业网）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;第三阶段：形成多层次 ISP 结构的 Internet
    &lt;ul&gt;
      &lt;li&gt;商业化极大推动 Internet 发展&lt;/li&gt;
      &lt;li&gt;IP 地址、域名管理等均交由专门企业运营&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Internet 特指现在的互联网（又称因特网），internet 指多个网络互联形成的网络。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;13-计算机网络的性能&quot;&gt;1.3 计算机网络的性能&lt;/h2&gt;

&lt;h3 id=&quot;一性能指标&quot;&gt;一、性能指标&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;速率&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;传送数据的速率，即数据速率 (data rate) 或比特率 (bit rate)&lt;/li&gt;
      &lt;li&gt;单位：b/s，也写为 bps (bit per second), kb/s, Mb/s, Gb/s, …&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;带宽&lt;/strong&gt; (bandwidth)
    &lt;ul&gt;
      &lt;li&gt;指通信线路传送数据的能力，即&lt;strong&gt;最高&lt;/strong&gt;数据率&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;吞吐量&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;时延&lt;/strong&gt; (delay, latency)
    &lt;ul&gt;
      &lt;li&gt;网络从一端传到另一端的时间&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;时延带宽积&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;时延带宽积&lt;/strong&gt; = 传播时延 $\times$ 带宽&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;往返时间&lt;/strong&gt; (RTT, Round Trip Time)
    &lt;ul&gt;
      &lt;li&gt;从发送方发出数据到收到接收方应答所经历的时间。$\not ={2\times delay}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;利用率&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;包括信道利用率和网络利用率&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二非性能指标&quot;&gt;二、非性能指标&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;费用&lt;/li&gt;
  &lt;li&gt;质量&lt;/li&gt;
  &lt;li&gt;标准化&lt;/li&gt;
  &lt;li&gt;可靠性&lt;/li&gt;
  &lt;li&gt;可扩展性和可升级性&lt;/li&gt;
  &lt;li&gt;易于管理和维护&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;14-计算机网络体系结构&quot;&gt;1.4 计算机网络体系结构&lt;/h2&gt;

&lt;h3 id=&quot;一网络体系结构概述&quot;&gt;一、网络体系结构概述&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;计算机网络体系结构 (architecture) 是&lt;strong&gt;计算机网络的各层及其协议的集合&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;OSI 体系结构&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二具有七层和五层协议的体系结构&quot;&gt;二、具有七层和五层协议的体系结构&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;OSI 体系结构（从上到下）
    &lt;ul&gt;
      &lt;li&gt;应用层 (application layer)&lt;/li&gt;
      &lt;li&gt;表示层 (presentation layer)&lt;/li&gt;
      &lt;li&gt;会话层 (session layer)&lt;/li&gt;
      &lt;li&gt;传输层 (transport layer)&lt;/li&gt;
      &lt;li&gt;网络层 (network layer)&lt;/li&gt;
      &lt;li&gt;数据链路层 (data link layer)&lt;/li&gt;
      &lt;li&gt;物理层 (physical layer)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TCP / IP 体系结构（从上到下）
    &lt;ul&gt;
      &lt;li&gt;应用层（包含应用层、表示层和会话层）&lt;/li&gt;
      &lt;li&gt;传输层&lt;/li&gt;
      &lt;li&gt;网际层&lt;/li&gt;
      &lt;li&gt;网络接口层&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;五层体系结构（从上到下， 现实世界中没有相关标准，但方便讲解）
    &lt;ul&gt;
      &lt;li&gt;应用层（包含应用层、表示层和会话层）&lt;/li&gt;
      &lt;li&gt;传输层&lt;/li&gt;
      &lt;li&gt;网际层&lt;/li&gt;
      &lt;li&gt;数据链路层&lt;/li&gt;
      &lt;li&gt;物理层&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;协议数据单元 (PDU, Protocol Data Unit)：对等层次之间传送的数据单位&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三实体协议服务和服务访问点&quot;&gt;三、实体、协议、服务和服务访问点&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;若干概念
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;实体&lt;/strong&gt; (entity)：任何可发送或接受信息的硬件或软件进程&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;协议&lt;/strong&gt; (protocol)：控制两个对等实体进行通信的规则的集合&lt;/li&gt;
      &lt;li&gt;在协议的控制下，两个对等实体间的通信使得本层能够向上一层提供&lt;strong&gt;服务&lt;/strong&gt; (service)&lt;/li&gt;
      &lt;li&gt;…… ==TODO==&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;协议的设计还需要考虑异常情况&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;四tcp--ip&quot;&gt;四、TCP / IP&lt;/h3&gt;

&lt;h2 id=&quot;15-网络标准化&quot;&gt;1.5 网络标准化&lt;/h2&gt;

&lt;h3 id=&quot;一概述&quot;&gt;一、概述&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;标准化对于计算机网络至关重要&lt;/li&gt;
  &lt;li&gt;标准的分类
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;法定标准&lt;/strong&gt;：由权威机构制定的、正式的、合法的标准&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;事实标准&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三标注化组织&quot;&gt;三、标注化组织&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;ITU-T&lt;/li&gt;
  &lt;li&gt;ISO
    &lt;ul&gt;
      &lt;li&gt;国际标准化组织&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;IEEE&lt;/li&gt;
  &lt;li&gt;IETF&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;第二章-物理层&quot;&gt;第二章 物理层&lt;/h1&gt;

&lt;h2 id=&quot;21-物理层的基本概念&quot;&gt;2.1 物理层的基本概念&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;物理层的主要任务
在传输介质上传输比特流&lt;/li&gt;
  &lt;li&gt;物理层涉及的四个特性
    &lt;ul&gt;
      &lt;li&gt;机械特性（e.g. 接口形状）&lt;/li&gt;
      &lt;li&gt;电气特性（e.g. 电压范围）&lt;/li&gt;
      &lt;li&gt;功能特性（e.g. 不同电平的电压表示何种意义）&lt;/li&gt;
      &lt;li&gt;过程特性（e.g. 不同功能的各种可能事件的出现顺序）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;22-数据通信的基础知识&quot;&gt;2.2 数据通信的基础知识&lt;/h2&gt;

&lt;h3 id=&quot;一数据通信系统的模型&quot;&gt;一、数据通信系统的模型&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;调制解调器&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;数据通信系统包含&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;信源&lt;/li&gt;
  &lt;li&gt;发送器&lt;/li&gt;
  &lt;li&gt;传输系统&lt;/li&gt;
  &lt;li&gt;接收器&lt;/li&gt;
  &lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二若干术语和概念&quot;&gt;二、若干术语和概念&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;信道&lt;/strong&gt;一般表示向某一方向传送信息的介质&lt;/li&gt;
  &lt;li&gt;通信的目的是为了传送&lt;strong&gt;消息&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;消息的实体是&lt;strong&gt;数据&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;信号&lt;/strong&gt;是数据的电气或电磁的表示&lt;/li&gt;
  &lt;li&gt;在使用时间域的波形表示数字信号时，代表不同离散数值的基本波形称为&lt;strong&gt;码元&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;码元速率：单位时间内通过信道的码元个数&lt;/li&gt;
      &lt;li&gt;数据速率：单位时间内通过信道的信息量（比特数）&lt;/li&gt;
      &lt;li&gt;希望一个码元尽可能携带多个比特&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;通信双方的交互方式
    &lt;ul&gt;
      &lt;li&gt;单向通信（单工通信，simplex）
        &lt;ul&gt;
          &lt;li&gt;只有一个方向可以发送信息&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;双向交替通信（半双工通信，half-duplex）√
        &lt;ul&gt;
          &lt;li&gt;双方都能发送信息，但不能同时发送信息&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;双向通信（双工通信，duplex）
        &lt;ul&gt;
          &lt;li&gt;双方可以同时发送和接受信息&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;基带 (baseband) 信号和带通 (band pass) 信号
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;基带信号&lt;/strong&gt;，即基本频带信号&lt;/li&gt;
      &lt;li&gt;基带信号是来自信源的信号，常常包含较多的低频成分，且可能为直流&lt;/li&gt;
      &lt;li&gt;必须对基带信号进行&lt;strong&gt;调制&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;带通信号&lt;/strong&gt;是基带信号经过调制后的信号&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;最基本的二元制调制方法
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;调幅&lt;/strong&gt; (AM)：载波的振幅随基带数字信号而变化&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;调频&lt;/strong&gt; (FM)：载波的频率随基带数字信号而变化&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;调相&lt;/strong&gt; (PM)：载波的相位随基带数字信号而变化&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;经常采用多元制混合的调制方法，如振幅和相位相结合的正交振幅调制（QAM）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三信道的极限容量&quot;&gt;三、信道的极限容量&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;信号的失真问题&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;信号能够通过的频率范围&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;奈奎斯特定理&lt;/strong&gt; (Nyquist)
        &lt;ul&gt;
          &lt;li&gt;理想低通信道最大数据传输率 = $2H\log_2 V$ (bps)
            &lt;ul&gt;
              &lt;li&gt;H：信道带宽&lt;/li&gt;
              &lt;li&gt;V：信号电平的级数（信号的状态数）&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;信噪比&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;信号的平均功率与噪声的平均功率之比，常记为：S/N。以分贝 (dB) 为计量单位&lt;/li&gt;
      &lt;li&gt;信噪比 = $10\log_{10}(S/N)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;香农公式&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;信道的极限信息传输速率 C（有噪声）&lt;/li&gt;
      &lt;li&gt;$C = W\log_2(1+S/N)$ b/s
        &lt;ul&gt;
          &lt;li&gt;W：信道带宽（单位：Hz）&lt;/li&gt;
          &lt;li&gt;S：信道内所传信号的平均功率&lt;/li&gt;
          &lt;li&gt;N：信道内部的高频噪声功率&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;信噪比越大，信息极限传输速率越高&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;23-物理层下面的传输介质&quot;&gt;2.3 物理层下面的传输介质&lt;/h2&gt;

&lt;p&gt;介质 media&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;传输介质，又称为传输媒体或传输媒介，指数据传输系统中发送器与接收器之间的物理通路&lt;/li&gt;
  &lt;li&gt;分类
    &lt;ul&gt;
      &lt;li&gt;导引型传输介质&lt;/li&gt;
      &lt;li&gt;非导引型传输介质&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;一导引型传输介质&quot;&gt;一、导引型传输介质&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;双绞线&lt;/strong&gt;：通过两根绝缘线绞合，减少相互干扰
    &lt;ul&gt;
      &lt;li&gt;分类
        &lt;ul&gt;
          &lt;li&gt;屏蔽双绞线 STP（外面带有铜网）&lt;/li&gt;
          &lt;li&gt;无屏蔽双绞线 UTP（外面无铜网）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;价格便宜，便于安装使用，传输距离较短&lt;/li&gt;
      &lt;li&gt;局域网布线系统常用&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同轴电缆&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;光纤&lt;/strong&gt; (fiber optics)
    &lt;ul&gt;
      &lt;li&gt;由非常透明的石英玻璃拉成的细丝，由纤芯包层构成双层通信圆柱体&lt;/li&gt;
      &lt;li&gt;分类
        &lt;ul&gt;
          &lt;li&gt;多模光纤&lt;/li&gt;
          &lt;li&gt;单模光纤：适用于长距离传输&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二非导引型传输介质&quot;&gt;二、非导引型传输介质&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;非导引型传输介质指可传播无线电波的自由空间&lt;/li&gt;
  &lt;li&gt;无线电波适用于
    &lt;ul&gt;
      &lt;li&gt;偏远地区通信&lt;/li&gt;
      &lt;li&gt;城市中布线较为困难的场合&lt;/li&gt;
      &lt;li&gt;移动设备&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;主要分类
    &lt;ul&gt;
      &lt;li&gt;短波通信&lt;/li&gt;
      &lt;li&gt;微波通信和卫星通信&lt;/li&gt;
      &lt;li&gt;地面微波通信&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;关于无线频谱政策
    &lt;ul&gt;
      &lt;li&gt;多数无线频段由政府管理和分配，需获得许可才能使用&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>ericaaaaaaaa</name></author><category term="Internet" /><category term="note" /><category term="internet" /><summary type="html">计算机网络 授课教师：刘轶 E-mail: yi.liu@buaa.edu.cn</summary></entry><entry><title type="html">特征工程</title><link href="http://localhost:4000/machinelearning/2022/02/25/FeatureEngineering.html" rel="alternate" type="text/html" title="特征工程" /><published>2022-02-25T00:00:00+08:00</published><updated>2022-02-25T00:00:00+08:00</updated><id>http://localhost:4000/machinelearning/2022/02/25/FeatureEngineering</id><content type="html" xml:base="http://localhost:4000/machinelearning/2022/02/25/FeatureEngineering.html">&lt;p&gt;利用领域知识和现有数据，创造出新的特征，用于机器学习算法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。”&lt;/p&gt;

  &lt;p&gt;参考链接：&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/jasonfreak/p/5448385.html&quot;&gt;使用 sklearn 做单机特征工程&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000024522693&quot;&gt;一文读懂特征工程&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;特征工程是什么&quot;&gt;特征工程是什么&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/927391/201604/927391-20160430145122660-830141495.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;数据预处理&quot;&gt;数据预处理&lt;/h2&gt;

&lt;h3 id=&quot;特征理解&quot;&gt;特征理解&lt;/h3&gt;

&lt;h4 id=&quot;结构化数据--非结构化数据&quot;&gt;结构化数据 &amp;amp; 非结构化数据&lt;/h4&gt;

&lt;p&gt;以表格形式存储的数据称为结构化数据，不呈现明显结构的数据称为非结构化数据，类似文本、报文、日志等。&lt;/p&gt;

&lt;h4 id=&quot;定量--定性数据&quot;&gt;定量 &amp;amp; 定性数据&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;定量数据&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;定性数据&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ab91b1bce987e33096fa52df1bab44c0_b.png&quot; alt=&quot;&quot; /&gt;)&lt;/p&gt;

&lt;h3 id=&quot;特征清洗&quot;&gt;特征清洗&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bdd10e10aa307015f0cb7a0378753738_b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;数据对齐&quot;&gt;数据对齐&lt;/h4&gt;

&lt;h5 id=&quot;时间&quot;&gt;时间&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;格式不一致&lt;/li&gt;
  &lt;li&gt;时间戳单位不一致&lt;/li&gt;
  &lt;li&gt;使用无效时间表示&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;字段&quot;&gt;字段&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;填写错误&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;量纲&quot;&gt;量纲&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;量纲不统一&lt;/li&gt;
  &lt;li&gt;数值类型不统一&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;缺失值处理&quot;&gt;缺失值处理&lt;/h4&gt;

&lt;p&gt;主要包括&lt;strong&gt;少量缺失&lt;/strong&gt;的情况下，考虑&lt;strong&gt;不处理&lt;/strong&gt;或&lt;strong&gt;删除缺失数据&lt;/strong&gt;或者&lt;strong&gt;采用均值、中位数、众数、同类均值填充。&lt;/strong&gt;
当缺失值对模型影响比较大，存在比较多的不缺失数据的情况下，可以采用&lt;strong&gt;模型预测&lt;/strong&gt;或者&lt;strong&gt;插值&lt;/strong&gt;的方式。当缺失值过多时，可以对&lt;strong&gt;缺失值&lt;/strong&gt;进行编码操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-44cfe5bed189f76aa8d6c4a45c03bd12_b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;删除&quot;&gt;删除&lt;/h5&gt;

&lt;h5 id=&quot;均值中位数众数同类均值&quot;&gt;均值、中位数、众数、同类均值&lt;/h5&gt;

&lt;h5 id=&quot;建模预测插值&quot;&gt;建模预测、插值&lt;/h5&gt;

&lt;h5 id=&quot;缺失编码&quot;&gt;缺失编码&lt;/h5&gt;

&lt;h4 id=&quot;异常值处理&quot;&gt;异常值处理&lt;/h4&gt;

&lt;h5 id=&quot;异常值识别&quot;&gt;异常值识别&lt;/h5&gt;

&lt;h6 id=&quot;箱线法&quot;&gt;箱线法&lt;/h6&gt;

&lt;h6 id=&quot;正态分布&quot;&gt;正态分布&lt;/h6&gt;

&lt;h6 id=&quot;异常值检测算法&quot;&gt;异常值检测算法&lt;/h6&gt;

&lt;h5 id=&quot;处理方法&quot;&gt;处理方法&lt;/h5&gt;

&lt;h6 id=&quot;模型预测插值&quot;&gt;模型预测、插值&lt;/h6&gt;

&lt;h6 id=&quot;删除-1&quot;&gt;删除&lt;/h6&gt;

&lt;h6 id=&quot;分位数截断&quot;&gt;分位数截断&lt;/h6&gt;

&lt;h6 id=&quot;模型预测删除&quot;&gt;模型预测删除&lt;/h6&gt;

&lt;h4 id=&quot;数据转化&quot;&gt;数据转化&lt;/h4&gt;

&lt;h5 id=&quot;文本转数值&quot;&gt;文本转数值&lt;/h5&gt;

&lt;h5 id=&quot;图像转数值&quot;&gt;图像转数值&lt;/h5&gt;

&lt;h5 id=&quot;标记符号转换&quot;&gt;标记符号转换&lt;/h5&gt;

&lt;h5 id=&quot;特殊数据转换&quot;&gt;特殊数据转换&lt;/h5&gt;

&lt;h2 id=&quot;特征选择&quot;&gt;特征选择&lt;/h2&gt;

&lt;p&gt;当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。&lt;/li&gt;
  &lt;li&gt;特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，本文介绍的其他方法均从相关性考虑。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据特征选择的形式又可以将特征选择方法分为3种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。&lt;/li&gt;
  &lt;li&gt;Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。&lt;/li&gt;
  &lt;li&gt;Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们使用sklearn中的feature_selection库来进行特征选择。&lt;/p&gt;

&lt;h3 id=&quot;filter&quot;&gt;Filter&lt;/h3&gt;

&lt;h4 id=&quot;方差选择法&quot;&gt;方差选择法&lt;/h4&gt;

&lt;p&gt;使用方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。使用 feature_selection 库的 VarianceThreshold 类来选择特征。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VarianceThreshold&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;相关系数法&quot;&gt;相关系数法&lt;/h4&gt;

&lt;p&gt;使用相关系数法，先要计算各个特征对目标值的相关系数以及相关系数的P值。用 feature_selection 库的 SelectKBest 类结合相关系数来选择特征。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.feature_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SelectKBest&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pearsonr&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;降维&quot;&gt;降维&lt;/h2&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;</content><author><name>ericaaaaaaaa</name></author><category term="MachineLearning" /><category term="book-report" /><category term="artificial-intelligence" /><category term="machine-learning" /><summary type="html">利用领域知识和现有数据，创造出新的特征，用于机器学习算法。</summary></entry><entry><title type="html">The Internet</title><link href="http://localhost:4000/internet/2022/02/24/TheInternet.html" rel="alternate" type="text/html" title="The Internet" /><published>2022-02-24T00:00:00+08:00</published><updated>2022-02-24T00:00:00+08:00</updated><id>http://localhost:4000/internet/2022/02/24/TheInternet</id><content type="html" xml:base="http://localhost:4000/internet/2022/02/24/TheInternet.html">&lt;center&gt;&lt;h1&gt;The Internet&lt;/h1&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;A notebook created by $Ericaaaaaaaa$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;h3 id=&quot;the-ingredients-of-the-internet&quot;&gt;The Ingredients of the Internet&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Internet&lt;/strong&gt; is a global network of computing devices communicating with each other in some way, whether they’re sending emails, downloading files, or sharing websites.&lt;/p&gt;

&lt;p&gt;The Internet is an &lt;strong&gt;open&lt;/strong&gt; network: any computing device can join as long as they follow the rules of the game. In networking, the rules are known as &lt;strong&gt;protocols&lt;/strong&gt; and they define how each other must communicate with each other. The Internet is powered by many layers of protocols.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Components&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Wires &amp;amp; wireless&lt;/strong&gt;: Physical connections between devices, plus protocols for converting electromagnetic signals into binary data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;IP&lt;/strong&gt;: A protocol that uniquely identify devices using IP addresses and provides a routing strategy to send data to destination IP address.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TCP / UDP&lt;/strong&gt;: Protocols that can transport packets of data from one device to another and check for errors along the way.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TLS&lt;/strong&gt;: A secure protocol for sending encrypted data so that attackers can’t view private information.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;HTTP &amp;amp; DNS&lt;/strong&gt;: The protocols powering the World Wide Web, what the browser uses every time you load a webpage.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;connecting-networks&quot;&gt;Connecting Networks&lt;/h2&gt;

&lt;h3 id=&quot;computer-networks&quot;&gt;Computer Networks&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;computer network&lt;/strong&gt; is any group of interconnected computing devices capable of sending or receiving data.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;computing device&lt;/strong&gt; is any device that can run a program.&lt;/p&gt;

&lt;h4 id=&quot;building-a-network&quot;&gt;Building a network&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Network topology&lt;/strong&gt;: ways of connecting computing devices in a network, including ring, mesh, star, bus, and tree.&lt;/p&gt;

&lt;h4 id=&quot;types-of-networks&quot;&gt;Types of networks&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local Area Network (LAN)&lt;/strong&gt;: A network that covers a limited area.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Wide Area Network (WAN)&lt;/strong&gt;: A network that extends over a large geographic area and is composed of many LANs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Center Network (DCN)&lt;/strong&gt;: A network used in data centers where data must be exchanged with very little delay.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;networking-protocols&quot;&gt;Networking protocols&lt;/h4&gt;

&lt;h3 id=&quot;physical-network-connections&quot;&gt;Physical Network Connections&lt;/h3&gt;

&lt;h4 id=&quot;copper-cables&quot;&gt;Copper cables&lt;/h4&gt;

&lt;p&gt;A type of &lt;strong&gt;twisted pair cable&lt;/strong&gt; that’s designed for use in computer networks.&lt;/p&gt;

&lt;p&gt;Transmitting pulses of electricity that represent binary data.&lt;/p&gt;

&lt;p&gt;Follow &lt;strong&gt;Ethernet&lt;/strong&gt; standards, also known as Ethernet cables.&lt;/p&gt;

&lt;p&gt;Used both in networks as small as a company office (a LAN) or as large as an entire country (a WAN).&lt;/p&gt;

&lt;h4 id=&quot;fiber-optic-cables&quot;&gt;Fiber-optic cables&lt;/h4&gt;

&lt;p&gt;A fiber-optic cable contains an optical fiber that can carry light (instead of electricity). The fiber is coated with plastic layers and sheathed in a protective tube to protect it from the environment.&lt;/p&gt;

&lt;p&gt;Sending pulses of light that represent binary data.&lt;/p&gt;

&lt;p&gt;Follow &lt;strong&gt;Ethernet&lt;/strong&gt; standards.&lt;/p&gt;

&lt;p&gt;Are capable of transmitting much more data per second than copper cables.&lt;/p&gt;

&lt;p&gt;Often used to connect networks across oceans so that data can travel quickly around the world.&lt;/p&gt;

&lt;h4 id=&quot;wireless&quot;&gt;Wireless&lt;/h4&gt;

&lt;p&gt;A wireless card inside the computer turns binary data into radio waves and transmits them through the air.&lt;/p&gt;

&lt;p&gt;The radio waves can’t travel very far.&lt;/p&gt;

&lt;h4 id=&quot;all-together-now&quot;&gt;All together now&lt;/h4&gt;

&lt;p&gt;Our Internet connection might be using a combination of those technologies.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Sends&lt;/th&gt;
      &lt;th&gt;Distance&lt;/th&gt;
      &lt;th&gt;Bandwidth&lt;/th&gt;
      &lt;th&gt;Issues&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Wireless&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Radio&lt;/td&gt;
      &lt;td&gt;100 ft&lt;/td&gt;
      &lt;td&gt;1.3 Gbps&lt;/td&gt;
      &lt;td&gt;Slower in reality&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Twisted pair copper cables&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Electricity&lt;/td&gt;
      &lt;td&gt;330 ft&lt;/td&gt;
      &lt;td&gt;1 Gbps&lt;/td&gt;
      &lt;td&gt;Susceptible to interference&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Fiber-optic cable&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Light&lt;/td&gt;
      &lt;td&gt;50 miles&lt;/td&gt;
      &lt;td&gt;26 Tbps&lt;/td&gt;
      &lt;td&gt;Expensive&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;bit-rate--bandwidth-and-latency&quot;&gt;Bit Rate , Bandwidth, and Latency&lt;/h3&gt;

&lt;h4 id=&quot;sending-streams-of-1s-and-0s&quot;&gt;Sending streams of 1s and 0s&lt;/h4&gt;

&lt;p&gt;The process of turning binary data into a time-based signal is known as &lt;strong&gt;line coding&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;bit-rate&quot;&gt;Bit Rate&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Bit rate&lt;/strong&gt;: the number of data that are sent each second. Used to measure the speed of data-transmitting.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;bps&lt;/strong&gt;: bits per second&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;mbps&lt;/strong&gt;: megabits per second&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Unit&lt;/th&gt;
      &lt;th&gt;Number of bits&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;kilobit&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$1000$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;megabit&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$1000^2$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;gigabit&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$1000^3$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;terabit&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$1000^4$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;petabit&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$1000^5$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;bandwidth&quot;&gt;Bandwidth&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Bandwidth&lt;/strong&gt;: the maximum bit rate of a system.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Boardband Internet”: A connection with a minimum bandwidth of 256 Kbps.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;latency&quot;&gt;Latency&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; means how late the bits arrive. Latency is the time between the sending of a data message and the receive of that message, measured in milliseconds.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;depends on&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the type of connections&lt;/li&gt;
  &lt;li&gt;the distance from the sender to the receiver&lt;/li&gt;
  &lt;li&gt;the congestion in the network (how many requests is waiting in line)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;major limitation&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the speed of light&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;internet-speed&quot;&gt;Internet Speed&lt;/h4&gt;

&lt;p&gt;Speed is a combination of bandwidth and latency.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Internet providers often support a much faster download speed than upload speed.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;addressing-the-internet&quot;&gt;Addressing the Internet&lt;/h2&gt;

&lt;h3 id=&quot;ip-address&quot;&gt;IP Address&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Internet Protocol (IP)&lt;/strong&gt; is one of the core protocols in the layers of the Internet.&lt;/p&gt;

&lt;p&gt;The protocol describes the use of &lt;strong&gt;IP address&lt;/strong&gt; to uniquely identify Internet connected devices.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;IPv4&lt;/strong&gt;: the first version ever used on the Internet&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;IPv6&lt;/strong&gt;: a backwards-compatible successor&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ipv4-addresses&quot;&gt;IPv4 addresses&lt;/h4&gt;

&lt;p&gt;Two versions of the Internet protocol in use today.&lt;/p&gt;

&lt;p&gt;Each IP address is split into $4$ numbers, and each of those numbers can range from $0$ to $255$:&lt;/p&gt;

&lt;p&gt;[0-255].[0-255].[0-255].[0-255]&lt;/p&gt;

&lt;h4 id=&quot;ipv6-address&quot;&gt;IPv6 address&lt;/h4&gt;

&lt;p&gt;There are $8$ hexadecimal numbers, and each number is 4 digits long&lt;/p&gt;

&lt;p&gt;The IP address can change dynamically–&lt;strong&gt;dynamic IP address&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Each Wi-Fi provider has its own range of addresses that it can give out.&lt;/p&gt;

&lt;p&gt;Computers that act as servers often have &lt;strong&gt;static&lt;/strong&gt; IP address.&lt;/p&gt;

&lt;h3 id=&quot;ip-address-hierarchy&quot;&gt;IP Address Hierarchy&lt;/h3&gt;

&lt;p&gt;IP addresses has &lt;strong&gt;hierarchy&lt;/strong&gt; that makes it easier to route data around the Internet.&lt;/p&gt;

&lt;h4 id=&quot;ipv4-address-hierarchy&quot;&gt;IPv4 address hierarchy&lt;/h4&gt;

&lt;p&gt;The first two octets (16 bits) identifies a network administered by the Internet Service Provider.&lt;/p&gt;

&lt;p&gt;The last two octets (the final 16 bits) identifies a home computer on that Comcast network.&lt;/p&gt;

&lt;h4 id=&quot;subnets&quot;&gt;Subnets&lt;/h4&gt;

&lt;p&gt;Network administrators can break IP address into further subnetworks (subnets) as needed.&lt;/p&gt;

&lt;h4 id=&quot;splitting-octets&quot;&gt;Splitting Octets&lt;/h4&gt;

&lt;p&gt;In actuality, IP addresses are often split in the middle of the octets.&lt;/p&gt;

&lt;h4 id=&quot;ipv7-address-hierarchy&quot;&gt;IPv7 address hierarchy&lt;/h4&gt;

&lt;h2 id=&quot;routing-with-redundancy&quot;&gt;Routing with Redundancy&lt;/h2&gt;

&lt;h3 id=&quot;ip-packets&quot;&gt;IP Packets&lt;/h3&gt;

&lt;p&gt;The network protocols split each message into multiple small &lt;strong&gt;packets&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Each IP packet contains both a header (20 or 24 bytes long) and data (variable length).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The header Includes the IP addresses of the source and destination, plus other fields that help to route the packet.&lt;/li&gt;
  &lt;li&gt;The data is the actual content.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;internet-routing-protocol&quot;&gt;Internet Routing Protocol&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;router&lt;/strong&gt; is a type of computing device used in computer networks that helps move the packets along.&lt;/p&gt;

&lt;p&gt;In the Internet Protocol (IP), computers split messages into packets and those packets hop from router to router on the way to their destination.&lt;/p&gt;

&lt;h4 id=&quot;step-1-send-packet-to-router&quot;&gt;Step 1: Send packet to router&lt;/h4&gt;

&lt;p&gt;Computer send the first packet to the nearest router.&lt;/p&gt;

&lt;h4 id=&quot;step-2-router-receives-packet&quot;&gt;Step 2: Router receives packet&lt;/h4&gt;

&lt;h4 id=&quot;step-3router-forwards-packet&quot;&gt;Step 3：Router forwards packet&lt;/h4&gt;

&lt;p&gt;The goal of the router is to send the packet to a router that’s closer to its final destination.&lt;/p&gt;

&lt;p&gt;The router has a &lt;strong&gt;forwarding table&lt;/strong&gt; that helps it pick the next path based in the destination IP address. (IP address prefixes)&lt;/p&gt;

&lt;h4 id=&quot;step-4-final-router-forwards-message&quot;&gt;Step 4: Final router forwards message&lt;/h4&gt;

&lt;h3 id=&quot;redundancy-and-fault-tolerance&quot;&gt;Redundancy and Fault Tolerance&lt;/h3&gt;

&lt;h4 id=&quot;redundancy-in-routing&quot;&gt;Redundancy in routing&lt;/h4&gt;

&lt;p&gt;The availability of multiple paths increases the &lt;strong&gt;redundancy&lt;/strong&gt; of the network.&lt;/p&gt;

&lt;h4 id=&quot;fault-tolerance&quot;&gt;Fault tolerance&lt;/h4&gt;

&lt;p&gt;A &lt;strong&gt;fault-tolerant&lt;/strong&gt; system is one that experience failure (or multiple failure) in  its components, but still continue operating properly.&lt;/p&gt;

&lt;h2 id=&quot;transporting-packets&quot;&gt;Transporting Packets&lt;/h2&gt;

&lt;h3 id=&quot;the-problem-with-packets&quot;&gt;The Problem With Packets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;multiple messages&lt;/li&gt;
  &lt;li&gt;message out of order&lt;/li&gt;
  &lt;li&gt;package corruption&lt;/li&gt;
  &lt;li&gt;package lost&lt;/li&gt;
  &lt;li&gt;package duplication&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Transmission Control Protocol (TCP)&lt;/strong&gt; is the data transport protocol that’s most commonly used on top of IP and it includes strategies for packet ordering, retransmission, and data integrity.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Using Datagram Protocol (UCP)&lt;/strong&gt; is an alternative protocol that solves fewer problems but offer faster data transport.&lt;/p&gt;

&lt;h3 id=&quot;user-datagram-protocol-udp&quot;&gt;User Datagram Protocol (UDP)&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;User Datagram Protocol (UDP)&lt;/strong&gt; is a lightweight data transport protocol that works on top of IP.&lt;/p&gt;

&lt;p&gt;UDP is known as the &lt;strong&gt;Unreliable Data Protocol&lt;/strong&gt; because it only provides a mechanism to detect corrupt data in packets, but it does not attempt to solve other problems that arise with packets.&lt;/p&gt;

&lt;p&gt;When sending packets using UDP over IP, the data portion of each IP packet is formatted as a &lt;strong&gt;UDP segment&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Each UDP segment contains &lt;strong&gt;8-byte header&lt;/strong&gt; and &lt;strong&gt;variable length data&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;port-number&quot;&gt;Port number&lt;/h4&gt;

&lt;p&gt;The first four bytes of the UDP header store the port numbers for the source and destination.&lt;/p&gt;

&lt;p&gt;A networked device can receive messages on different virtual ports.&lt;/p&gt;

&lt;h4 id=&quot;segment-length&quot;&gt;Segment Length&lt;/h4&gt;

&lt;p&gt;The next two bytes of the UDP header store the length (in bytes) of the segment (including the header).&lt;/p&gt;

&lt;h4 id=&quot;checksum&quot;&gt;Checksum&lt;/h4&gt;

&lt;p&gt;The final two bytes of the UDP header is the checksum, a field that’s used by the sender and receiver to check for data corruption.&lt;/p&gt;

&lt;p&gt;Before sending off the segment, the sender:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Computes the checksum based on the data in the segment.&lt;/li&gt;
  &lt;li&gt;Stores the computed checksum in the field.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Upon receiving the segment, the recipient:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Computes the checksum based on the received segment.&lt;/li&gt;
  &lt;li&gt;Compares the checksums to each other. If the checksums aren’t equal, it knows the data was corrupted.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;transmission-control-protocol-tcp&quot;&gt;Transmission Control Protocol (TCP)&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Transmission Control Protocol (TCP)&lt;/strong&gt; is a transport protocol that is used on top of the IP to ensure reliable transmission of packages.&lt;/p&gt;

&lt;p&gt;TCP includes mechanisms to solve many of the problems that arise from packet-based-messaging.&lt;/p&gt;

&lt;h4 id=&quot;tcpip&quot;&gt;TCP/IP&lt;/h4&gt;

&lt;p&gt;Since TCP is the protocol used most commonly on top of IP, the Internet protocol stack is sometimes referred to as &lt;strong&gt;TCP/IP&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;packet-format&quot;&gt;Packet format&lt;/h4&gt;

&lt;p&gt;When sending packets using TCP/IP, the data portion of each IP packet is formatted as a &lt;strong&gt;TCP segment&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Each TCP segment contains a header and data. The TCP header contains many more fields than the UDP header and can range in size from 20 to 60 bytes, depending on the size of the options field.&lt;/p&gt;

&lt;p&gt;The TCP header shares some fields with UDP header: source port number, destination port number, and checksum.&lt;/p&gt;

&lt;h4 id=&quot;from-start-to-finish&quot;&gt;From start to finish&lt;/h4&gt;

&lt;h5 id=&quot;step-1-establish-connection&quot;&gt;Step 1: Establish connection&lt;/h5&gt;

&lt;p&gt;When two computers want to send data to each other over TCP, they need to establish a connection using a &lt;strong&gt;three-way-handshake&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The first computer sends a packet with the SYN (synchronize?) bit set to 1.&lt;/li&gt;
  &lt;li&gt;The second computer sends back a packet with the ACK (acknowledge!) bit set to 1.&lt;/li&gt;
  &lt;li&gt;The first computer replies back with an ACK.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;The SYN and ACK bits are both part of the TCP header.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;step-2-send-packets-of-data&quot;&gt;Step 2: Send packets of data&lt;/h5&gt;

&lt;p&gt;The sequence and acknowledgement numbers are part of the TCP header.&lt;/p&gt;

&lt;h5 id=&quot;step-3-close-the-connection&quot;&gt;Step 3: Close the connection&lt;/h5&gt;

&lt;p&gt;Either computer can close the connection when they no longer want to send or receive data.&lt;/p&gt;

&lt;p&gt;A computer initiates closing the connection by sending a packets with the FIN bit set to 1 (FIN = finish). The other computer replies with an ACK and another FIN. After one more ACK from the initiating computer, the connection is closed.&lt;/p&gt;

&lt;h4 id=&quot;detecting-lost-packets&quot;&gt;Detecting lost packets&lt;/h4&gt;

&lt;p&gt;TCP connection can detect lost packets using a timeout.&lt;/p&gt;

&lt;p&gt;After sending off a packet, the sender starts a timer and puts the packet in a retransmission queue. If the timer runs out and the sender has not yet received an ACK from the recipient, it sends the packet again.&lt;/p&gt;

&lt;p&gt;Files may be duplicated because of sending delay.&lt;/p&gt;

&lt;h4 id=&quot;handling-out-of-order-packets&quot;&gt;Handling out of order packets&lt;/h4&gt;

&lt;p&gt;TCP connections can detect out of order packets by using the sequence and acknowledgement numbers.&lt;/p&gt;

&lt;p&gt;The recipient can use the sequence number to reassemble the packet data in the correct order.&lt;/p&gt;

&lt;h2 id=&quot;web-protocols&quot;&gt;Web Protocols&lt;/h2&gt;

&lt;h3 id=&quot;the-world-wide-web&quot;&gt;The World Wide Web&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;World Wide Web(WWW, Web)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The Web is a massive network of webpages, programs, and files that are accessible via URLs.&lt;/p&gt;

&lt;h4 id=&quot;powered-by-protocols&quot;&gt;Powered by protocols&lt;/h4&gt;

&lt;p&gt;A web browser loads a webpage using various protocols:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It uses &lt;strong&gt;Domain Name System (DNS) protocol&lt;/strong&gt; to convert a domain name into a IP address.&lt;/li&gt;
  &lt;li&gt;It uses &lt;strong&gt;HyperText Transfer Protocol (HTTP)&lt;/strong&gt; to request the webpage contents from that IP address.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It may also use the &lt;strong&gt;Transport Layer Security (TLS) protocol&lt;/strong&gt; to serve the website over a secure, encrypted connection.&lt;/p&gt;

&lt;p&gt;The web browser uses these protocols on top of the Internet protocols, so every HTTP request also uses TCP and IP.&lt;/p&gt;

&lt;h3 id=&quot;domain-name-system-dns&quot;&gt;Domain Name System (DNS)&lt;/h3&gt;

&lt;p&gt;IP addresses are how computers identify other computers on the Internet.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Domain Name System (DNS)&lt;/strong&gt; gives us humans an easy way to identify where we want to go on the Internet.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;domain name&lt;/strong&gt; is a human-friendly address for a website, something that’s easy for us to remember and type in.&lt;/p&gt;

&lt;h4 id=&quot;anatomy-of-a-domain-name&quot;&gt;Anatomy of a domain name&lt;/h4&gt;

&lt;p&gt;Each domain name is made up of parts:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[third-level-domain].[second-level-domain]-[top-level-domain]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are a limited set of &lt;em&gt;top level domains&lt;/em&gt; (TLDs), and many websites use the most common TLDs, “.com”, “.org”, and “.edu”.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;second level&lt;/em&gt; domain is unique to the company or organization that registers it.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;third level&lt;/em&gt; domain is also called &lt;strong&gt;subdomain&lt;/strong&gt;, because it’s owned by the same group and that URL often directs you to a subset of the website.&lt;/p&gt;

&lt;h4 id=&quot;domains-leftrightarrow-ip-address&quot;&gt;Domains $\leftrightarrow$ IP address&lt;/h4&gt;

&lt;p&gt;Each domain name maps to an IP address.&lt;/p&gt;

&lt;h4 id=&quot;step-1-check-the-local-cache&quot;&gt;Step 1: Check the local cache&lt;/h4&gt;

&lt;p&gt;The computers keep a local cache of domain name to IP mappings.&lt;/p&gt;

&lt;h4 id=&quot;step-2-ask-the-isp-cache&quot;&gt;Step 2: Ask the ISP cache&lt;/h4&gt;

&lt;p&gt;Every ISP (Internet Service Provider) provides a domain name resolving service and keeps its own cache.&lt;/p&gt;

&lt;h4 id=&quot;step-3-ask-the-name-servers&quot;&gt;Step 3: Ask the name servers&lt;/h4&gt;

&lt;p&gt;There are domain name servers scattered around the world that are responsible for keeping track of a subset of the millions of domain names.&lt;/p&gt;

&lt;p&gt;The servers are ordered in a hierarchy:&lt;/p&gt;

&lt;p&gt;Root name servers $\rightarrow$ TLD name  servers $\rightarrow$ Host name servers&lt;/p&gt;

&lt;h3 id=&quot;hypertext-transfer-protocol-http&quot;&gt;Hypertext Transfer Protocol (HTTP)&lt;/h3&gt;

&lt;h4 id=&quot;step-1-direct-browser-to-url&quot;&gt;Step 1: Direct browser to URL&lt;/h4&gt;

&lt;p&gt;The url starts with “http” signal the browser that it needs to use HTTP to fetch the document for that URL.&lt;/p&gt;

&lt;h4 id=&quot;step-2-browser-looks-up-ip&quot;&gt;Step 2: Browser looks up IP&lt;/h4&gt;

&lt;p&gt;The browser uses a DNS resolver to map the domain to an IP address.&lt;/p&gt;

&lt;h4 id=&quot;step-3-browser-sends-http-request&quot;&gt;Step 3: Browser sends HTTP request&lt;/h4&gt;

&lt;p&gt;Once the browser identifies the IP address of the computer hosting the request URL, it sends an &lt;strong&gt;HTTP request&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The HTTP request contains:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An action: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GET&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;The path&lt;/li&gt;
  &lt;li&gt;The protocol and it’s version&lt;/li&gt;
  &lt;li&gt;The domain of the requested URL.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;step-4-host-sends-back-http-response&quot;&gt;Step 4: Host sends back HTTP response&lt;/h4&gt;

&lt;p&gt;contains:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The protocol and it’s version&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;http status code&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;200: ok&lt;/li&gt;
      &lt;li&gt;404: file not found&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;headers&lt;/strong&gt;: give the browser additional details and help the browser additional details and help the browser to render the content.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Content-Type&lt;/strong&gt;: tells the browser what type of document it’s sending back.&lt;/p&gt;

        &lt;p&gt;e.g. text/html, image/png, video/mpeg, application/javascript&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Content-Length&lt;/strong&gt;: the length of the document in bytes, which helps the browser know how long a file will take to download.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The actual document requested.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;step-5-the-browser-renders-the-response&quot;&gt;Step 5: The browser renders the response&lt;/h4&gt;

&lt;h4 id=&quot;http-and-tcp--ip&quot;&gt;HTTP and TCP / IP&lt;/h4&gt;

&lt;p&gt;HTTP is a protocol that’s built &lt;em&gt;on top of&lt;/em&gt; the TCP/IP protocols.&lt;/p&gt;

&lt;h2 id=&quot;scalable-systems&quot;&gt;Scalable Systems&lt;/h2&gt;

&lt;h3 id=&quot;scalable-systems-1&quot;&gt;Scalable Systems&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;scalable&lt;/strong&gt; system is one that can continue functioning well even as it experiences higher usage.&lt;/p&gt;

&lt;h4 id=&quot;internet-scalability&quot;&gt;Internet scalability&lt;/h4&gt;

&lt;p&gt;Features that increases the scalability of the Internet:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Any computing device can send data around the Internet if it follows the protocols. There is no bureaucratic process that blocks a device from joining or prevents a programmer from learning how the protocols work.&lt;/li&gt;
  &lt;li&gt;The IPv6 addressing system can uniquely address a &lt;em&gt;trillion trillion&lt;/em&gt; times the amount of devices currently connected to the Internet.&lt;/li&gt;
  &lt;li&gt;Routing is dynamic, so new routers can join a network at any time and help to move data packets around the Internet.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Features that threatens the scalability of the Internet:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Network connections have limited bandwidth.&lt;/li&gt;
  &lt;li&gt;Routers have limited throughput (the amount of data they can forward per second).&lt;/li&gt;
  &lt;li&gt;Wireless routers often have a limitation in the number of devices that can be connected to them.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;web-application-scalability&quot;&gt;Web application scalability&lt;/h4&gt;

&lt;h4 id=&quot;load-testing&quot;&gt;Load testing&lt;/h4&gt;

&lt;p&gt;Engineering teams can prepare for spikes in usage by doing &lt;strong&gt;load testing&lt;/strong&gt;: simulating high amounts of traffic in a short period of time to see if the system buckles under the load. Load testing can uncover bottlenecks or hardcoded limits in the system.&lt;/p&gt;

&lt;h4 id=&quot;the-spectrum-of-scalability&quot;&gt;The spectrum of scalability&lt;/h4&gt;

&lt;h2 id=&quot;the-internet-protocol-suite&quot;&gt;The Internet Protocol Suite&lt;/h2&gt;

&lt;h3 id=&quot;the-internet-protocol-suite-1&quot;&gt;The Internet Protocol Suite&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.kastatic.org/ka-perseus-images/6a0cd3a5b7e709c2f637c959ba98705ad21e4e3c.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;layer-by-layer&quot;&gt;Layer by layer&lt;/h4&gt;

&lt;p&gt;At the &lt;strong&gt;bottom&lt;/strong&gt; layer, two computing devices need a physical mechanism to send digital data to each other. They send electromagnetic signals either over a &lt;strong&gt;wired&lt;/strong&gt; or &lt;strong&gt;wireless connection&lt;/strong&gt; and interpret the signal as bits. The type of physical connection affects the &lt;strong&gt;bit rate&lt;/strong&gt; and &lt;strong&gt;bandwidth&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Every node on the Internet is identified with an &lt;strong&gt;IP address&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The data must pass from router to router until it finally reaches its destination, a strategy that comes from the &lt;strong&gt;Internet routing protocol&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Data needs to be broken up into small packets, which are then reassembled at the destination. The &lt;strong&gt;Transmission Control Protocol (TCP)&lt;/strong&gt; is used to ensure reliable transport of those packets, with sequencing, acknowledgement, and retries. A faster but less reliable transport protocol is the &lt;strong&gt;User Diagram Protocol (UDP)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The most common use of the Internet is the &lt;strong&gt;World Wide Web (WWW)&lt;/strong&gt;, with its millions of publicly viewable websites, all made possible due to the &lt;strong&gt;HyperText Transfer Protocols (HTTP)&lt;/strong&gt;. We can visit a website by typing a domain name in the browser address bar, since the browser knows how to return the domain into an IP address using the &lt;strong&gt;Domain Name System (DNS)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;When the data contains private information, it needs to be transported securely from the sender to the destination. The &lt;strong&gt;Transport Layer Security (TLS) protocol&lt;/strong&gt; uses algorithms to encrypt the data, while &lt;strong&gt;certificate authorities&lt;/strong&gt; help users trust the encryption.&lt;/p&gt;

&lt;h4 id=&quot;a-protocol-stack&quot;&gt;A protocol stack&lt;/h4&gt;

&lt;p&gt;This stack of protocols is used when a DNS request is sent through the Internet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.kastatic.org/ka-perseus-images/918dc8144c8813382ea3ffbbf76db1535d97421a.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This protocol stack is used when an HTTP request is sent through the Internet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.kastatic.org/ka-perseus-images/49e49dd1e8744a2422215288147e00443fc0916c.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This stack of protocols includes multiple protocols at the application layer (both HTTP and TLS).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.kastatic.org/ka-perseus-images/de452773728c35833566ddae2f78289ecae61340.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;open-protocol-development&quot;&gt;Open Protocol Development&lt;/h2&gt;

&lt;h3 id=&quot;open-protocol-development-1&quot;&gt;Open Protocol Development&lt;/h3&gt;

&lt;h4 id=&quot;the-need-for-standardization&quot;&gt;The need for standardization&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Standardization&lt;/strong&gt; allows the computing device to communicate with each other correctly and effectively. Once the protocol is written up in a document and other network administrators agree that it is sensible protocol, that protocol is considered as a &lt;strong&gt;standard&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;the-importance-of-being-open&quot;&gt;The importance of being open&lt;/h4&gt;

&lt;p&gt;An &lt;strong&gt;open (nonproprietary)&lt;/strong&gt; protocol is one that is not owned by any particular company and &lt;em&gt;not&lt;/em&gt; limited to a particular company’s products.&lt;/p&gt;

&lt;h4 id=&quot;open-standard-specifications&quot;&gt;Open standard specifications&lt;/h4&gt;

&lt;p&gt;The specifications for the Internet protocols are maintained by the Internet Engineering Task Force (IETF),&lt;/p&gt;

&lt;p&gt;The HTML living standard is maintained by the WhatWG community.&lt;/p&gt;

&lt;p&gt;CSS has many specifications and is maintained by the W3C.&lt;/p&gt;

&lt;p&gt;JavaScript is based on the ECMAScript standard.&lt;/p&gt;

&lt;h2 id=&quot;the-digital-divide&quot;&gt;The Digital Divide&lt;/h2&gt;

&lt;h3 id=&quot;the-global-digital-divide&quot;&gt;The global digital divide&lt;/h3&gt;

&lt;p&gt;The difference in access to computing devices and the Internet is referred to as &lt;strong&gt;the digital divide&lt;/strong&gt; and is often due to socioeconomic, geographic, or demographic factors.&lt;/p&gt;

&lt;h4 id=&quot;the-statistics&quot;&gt;The statistics&lt;/h4&gt;

&lt;h3 id=&quot;the-geographic-digital-divide&quot;&gt;The geographic digital divide&lt;/h3&gt;

&lt;h3 id=&quot;the-socioeconomic-digital-divide&quot;&gt;The socioeconomic digital divide&lt;/h3&gt;

&lt;h3 id=&quot;the-digital-use-divide&quot;&gt;The digital use divide&lt;/h3&gt;</content><author><name>ericaaaaaaaa</name></author><category term="Internet" /><category term="note" /><category term="internet" /><summary type="html">The Internet</summary></entry><entry><title type="html">神经网络的可解释性</title><link href="http://localhost:4000/machinelearning/2022/02/21/Explanation.html" rel="alternate" type="text/html" title="神经网络的可解释性" /><published>2022-02-21T00:00:00+08:00</published><updated>2022-02-21T00:00:00+08:00</updated><id>http://localhost:4000/machinelearning/2022/02/21/Explanation</id><content type="html" xml:base="http://localhost:4000/machinelearning/2022/02/21/Explanation.html">&lt;center&gt;&lt;h1&gt;神经网络的可解释性&lt;/h1&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;参考博客：https://jishuin.proginn.com/p/763bfbd3b58c&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;cnn-可解释化&quot;&gt;CNN 可解释化&lt;/h2&gt;

&lt;h3 id=&quot;特征图可视化方法&quot;&gt;特征图可视化方法&lt;/h3&gt;

&lt;p&gt;特征图可视化有两类方法，一类是直接将某一层的 feature map 映射到 0-255 的范围，变成图像。另一类是使用一个反卷积网络（反卷积、反池化）将 feature map 变成图像，从而达到可视化 feature map 的目的。&lt;/p&gt;

&lt;h4 id=&quot;直接可视化&quot;&gt;直接可视化&lt;/h4&gt;

&lt;p&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;torchvision.utils.make_grid()&lt;/code&gt; 函数实现归一化，将 feature map 标准化到 0-255 范围内。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;make_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale_each&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60753993&quot;&gt;参考链接&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;反卷积网络-deconvnet&quot;&gt;反卷积网络 (deconvnet)&lt;/h4&gt;

&lt;p&gt;图像像素经过神经网络映射到特征空间，而反卷积网络可以将 feature map 映射回像素空间。&lt;/p&gt;

&lt;h5 id=&quot;反池化-unpooling&quot;&gt;反池化 (unpooling)&lt;/h5&gt;

&lt;p&gt;将最大值放在原位置，其它位置直接置为 0。&lt;/p&gt;

&lt;h5 id=&quot;修正-rectification&quot;&gt;修正 (Rectification)&lt;/h5&gt;

&lt;p&gt;使用 ReLU 使得 unpooling 后的值都是正的。&lt;/p&gt;

&lt;h5 id=&quot;反卷积-filtering&quot;&gt;反卷积 (Filtering)&lt;/h5&gt;

&lt;p&gt;使用原网络的卷积核的转置作为卷积核，对 Rectification 后的输出进行卷积。&lt;/p&gt;

&lt;h5 id=&quot;导向反向传播-guided-backpropagation&quot;&gt;导向反向传播 (Guided-backpropagation)&lt;/h5&gt;

&lt;p&gt;导向反向传播与反卷积网络的区别在于对 ReLU 的处理方式。在反卷积网络中使用 ReLU 处理梯度，只回传梯度大于 0 的位置，而在普通反向传播中只回传 feature map 中大于 0 的位置，在导向反向传播中结合这两者，只回传输入和梯度都大于 0 的位置，这相当于在普通反向传播的基础上增加了来自更高层的额外的指导信号，这阻止了负梯度的反传流动，梯度小于 0 的神经元降低了正对应更高层单元中我们想要可视化的区域的激活值。&lt;/p&gt;

&lt;h3 id=&quot;卷积核可视化&quot;&gt;卷积核可视化&lt;/h3&gt;

&lt;h4 id=&quot;卷积核可视化原理&quot;&gt;卷积核可视化原理&lt;/h4&gt;

&lt;p&gt;随机初始化生成一张图（指的是对像素值随机取值，不是数据集中随机选一张图），然后经过前向传播到该层，我们希望这个随机生成的图在经过这一层卷积核时，它的响应值能尽可能的大，换句话说，响应值比较大的图像是这个卷积核比较认可的，是与识别任务更相关的。然后不断调整图像像素值，直到响应值足够大，我们就可以认为此时的图像就是这个卷积核所认可的，从而达到可视化该卷积核的目的。&lt;/p&gt;

&lt;h3 id=&quot;类可视化&quot;&gt;类可视化&lt;/h3&gt;

&lt;p&gt;这个主要用于确定图像哪些区域对识别某个类起主要作用。如常见的热力图（Heat Map），在识别猫时，热力图可直观看出图像中每个区域对识别猫的作用大小。这个目前主要用的方法有CAM系列（CAM、Grad-CAM、Grad-CAM++）。&lt;/p&gt;

&lt;h4 id=&quot;cam&quot;&gt;CAM&lt;/h4&gt;

&lt;p&gt;CAM 的结构由 CNN 特征提取网络，全局平均池化 GAP，全连接层和 Softmax 组成。&lt;/p&gt;

&lt;p&gt;实现原理：一张图片在经过 CNN 特征提取网络后得到 feature maps, 再对每一个 feature map 进行全局平均池化，变成一维向量，再经过全连接层与 softmax 得到类的概率。&lt;/p&gt;

&lt;p&gt;假定在 GAP 前是 n 个通道，则经过 GAP 后得到的是一个长度为 1x n 的向量，假定类别数为 m，则全连接层的权值为一个 n x m 的张量。（注：这里先忽视 batch-size）&lt;/p&gt;

&lt;p&gt;对于某一个类别 C, 现在想要可视化这个模型对于识别类别 C，原图像的哪些区域起主要作用，换句话说模型是根据哪些信息得到该图像就是类别 C。&lt;/p&gt;

&lt;p&gt;做法是取出全连接层中得到类别 C 的概率的那一维权值，用 W 表示，即上图的下半部分。然后对 GAP 前的 feature map 进行加权求和，由于此时 feature map 不是原图像大小，在加权求和后还需要进行上采样，即可得到 Class Activation Map。
\(M_c(x, y) = \sum_kw_k^cf_k(x, y)\)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;CAM 有个很致命的缺陷，它的结构是由 CNN + GAP + FC + Softmax 组成，也就是说如果想要可视化某个现有的模型，但大部分现有的模型没有 GAP 这个操作，此时想要可视化便需要修改原模型结构，并重新训练，相当麻烦，且如果模型很大，在修改后重新训练不一定能达到原效果，可视化也就没有意义了。&lt;/p&gt;

  &lt;p&gt;因此，针对这个缺陷，其后续有了改进版 Grad-CAM。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;grad-cam&quot;&gt;Grad-CAM&lt;/h4&gt;

&lt;p&gt;原理：同样是处理 CNN 特征提取网络的最后一层 feature maps。Grad-CAM 对于想要可视化的类别 C，使最后输出的类别 C 的概率值通过反向传播到最后一层 feature maps，得到类别 C 对该 feature maps 的每个像素的梯度值，对每个像素的梯度值取全局平均池化，即可得到对 feature maps 的加权系数 alpha，论文中提到这样获取的加权系数跟 CAM 中的系数几乎是等价的。接下来对特征图加权求和，使用 ReLU 进行修正，再进行上采样。&lt;/p&gt;

&lt;p&gt;使用 ReLU 的原因是对于那些负值，可认为与识别类别 C 无关，这些负值可能是与其他类别有关，而正值才是对识别 C 有正面影响的。&lt;/p&gt;

&lt;p&gt;用公式表示如下：
\(\alpha_k^c=\frac{1}{Z}\sum_i\sum_j\frac{\part y^c}{\part A_{ij}^k}\\
L_{Grad-CAM}^c=ReLU(\sum_k\alpha_k^cA^k)\)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Grad-CAM后续还有改进版Grad-CAM++，其主要的改进效果是定位更准确，更适合同类多目标的情况，所谓同类多目标是指一张图像中对于某个类出现多个目标，例如七八个人。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;参考链接&quot;&gt;参考链接&lt;/h4&gt;

&lt;p&gt;CAM: arxiv.org/pdf/1512.0415&lt;/p&gt;

&lt;p&gt;Grad-CAM: arxiv.org/pdf/1610.0239&lt;/p&gt;

&lt;p&gt;Grad-CAM++: arxiv.org/pdf/1710.1106&lt;/p&gt;

&lt;h3 id=&quot;可视化工程与项目&quot;&gt;可视化工程与项目&lt;/h3&gt;

&lt;p&gt;通过一些研究人员开源出来的工具可视化CNN模型某一层。&lt;/p&gt;

&lt;h4 id=&quot;cnn-explainer&quot;&gt;CNN-Explainer&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;这是一个中国博士发布的名叫CNN解释器的在线交互可视化工具。主要对于那些初学深度学习的小白们 理解关于神经网络是如何工作很有帮助，如卷积过程，ReLU过程，平均池化过程，中间每一层的特征图的样子，都可以看到，相当于给了一个显微镜，可以随意对任意一层，任何一项操作的前后变化，观察得清清楚楚。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;https://github.com/poloclub/cnn-explainer&lt;/p&gt;

&lt;h4 id=&quot;一些可视化特征图卷积核热力图的代码&quot;&gt;一些可视化特征图、卷积核、热力图的代码&lt;/h4&gt;

&lt;p&gt;可视化特征图&lt;/p&gt;

&lt;p&gt;https://github.com/waallf/Viusal-feature-map&lt;/p&gt;

&lt;p&gt;可视化卷积核&lt;/p&gt;

&lt;p&gt;https://keras.io/examples/vision/visualizing_what_convnets_learn/&lt;/p&gt;

&lt;p&gt;https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html&lt;/p&gt;

&lt;p&gt;Grad-CAM&lt;/p&gt;

&lt;p&gt;https://github.com/ramprs/grad-cam&lt;/p&gt;

&lt;p&gt;热力图&lt;/p&gt;

&lt;p&gt;https://github.com/heuritech/convnets-keras&lt;/p&gt;

&lt;p&gt;下面这个项目是同时包含特征图可视化，卷积核可视化和热力图的一个链接：&lt;/p&gt;

&lt;p&gt;https://github.com/raghakot/keras-vis&lt;/p&gt;

&lt;h4 id=&quot;结构可视化工具&quot;&gt;结构可视化工具&lt;/h4&gt;

&lt;h5 id=&quot;netscope&quot;&gt;Netscope&lt;/h5&gt;

&lt;p&gt;用于可视化模型结构的在线工具，仅支持caffe的prototxt文件可视化。需要自己写prototxt格式的文件。&lt;/p&gt;

&lt;p&gt;项目地址：https://github.com/ethereon/netscope&lt;/p&gt;

&lt;h5 id=&quot;convnetdraw&quot;&gt;ConvNetDraw&lt;/h5&gt;

&lt;p&gt;项目地址：https://github.com/cbovar/ConvNetDraw&lt;/p&gt;

&lt;h5 id=&quot;plotneuralnet&quot;&gt;PlotNeuralNet&lt;/h5&gt;

&lt;p&gt;项目地址：https://github.com/HarisIqbal88/PlotNeuralNet&lt;/p&gt;

&lt;h3 id=&quot;网络结构手动画图工具&quot;&gt;网络结构手动画图工具&lt;/h3&gt;

&lt;p&gt;PPT, VISIO，NN-SVG（在线工具）&lt;/p&gt;

&lt;p&gt;项目地址：http://alexlenail.me/NN-SVG/&lt;/p&gt;

&lt;h2 id=&quot;参考论文&quot;&gt;参考论文&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;《Visualizing and Understanding Convolutional Networks》&lt;/li&gt;
  &lt;li&gt;《Striving for Simplicity：The All Convolutional Net》&lt;/li&gt;
  &lt;li&gt;Learning Deep Features for Discriminative Localization&lt;/li&gt;
  &lt;li&gt;Grad-CAM: Why did you say that?Visual Explanations from Deep Networks via Gradient-based Localization&lt;/li&gt;
  &lt;li&gt;Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks&lt;/li&gt;
&lt;/ol&gt;</content><author><name>ericaaaaaaaa</name></author><category term="MachineLearning" /><category term="book-report" /><category term="artificial-intelligence" /><category term="machine-learning" /><summary type="html">神经网络的可解释性</summary></entry><entry><title type="html">概率论与数理统计</title><link href="http://localhost:4000/statistics/2022/02/17/Statistics.html" rel="alternate" type="text/html" title="概率论与数理统计" /><published>2022-02-17T00:00:00+08:00</published><updated>2022-02-17T00:00:00+08:00</updated><id>http://localhost:4000/statistics/2022/02/17/Statistics</id><content type="html" xml:base="http://localhost:4000/statistics/2022/02/17/Statistics.html">&lt;h1 id=&quot;样本空间与概率&quot;&gt;样本空间与概率&lt;/h1&gt;

&lt;h2 id=&quot;集合&quot;&gt;集合&lt;/h2&gt;

&lt;h3 id=&quot;集合运算&quot;&gt;集合运算&lt;/h3&gt;

&lt;h3 id=&quot;集合的代数&quot;&gt;集合的代数&lt;/h3&gt;

&lt;h2 id=&quot;概率模型&quot;&gt;概率模型&lt;/h2&gt;

&lt;h3 id=&quot;样本空间和事件&quot;&gt;样本空间和事件&lt;/h3&gt;

&lt;h3 id=&quot;选择适当的样本空间&quot;&gt;选择适当的样本空间&lt;/h3&gt;

&lt;h3 id=&quot;序贯模型&quot;&gt;序贯模型&lt;/h3&gt;

&lt;h3 id=&quot;概率律&quot;&gt;概率律&lt;/h3&gt;

&lt;h3 id=&quot;离散模型&quot;&gt;离散模型&lt;/h3&gt;

&lt;h3 id=&quot;连续模型&quot;&gt;连续模型&lt;/h3&gt;

&lt;h3 id=&quot;概率律的性质&quot;&gt;概率律的性质&lt;/h3&gt;

&lt;h3 id=&quot;模型和现实&quot;&gt;模型和现实&lt;/h3&gt;

&lt;h2 id=&quot;条件概率&quot;&gt;条件概率&lt;/h2&gt;

&lt;h3 id=&quot;条件概率是一个概率律&quot;&gt;条件概率是一个概率律&lt;/h3&gt;

&lt;h3 id=&quot;利用条件概率定义概率模型&quot;&gt;利用条件概率定义概率模型&lt;/h3&gt;

&lt;h2 id=&quot;全概率定义和贝叶斯准则&quot;&gt;全概率定义和贝叶斯准则&lt;/h2&gt;

&lt;h2 id=&quot;独立性&quot;&gt;独立性&lt;/h2&gt;

&lt;h3 id=&quot;条件独立&quot;&gt;条件独立&lt;/h3&gt;

&lt;h3 id=&quot;一组事件的独立性&quot;&gt;一组事件的独立性&lt;/h3&gt;

&lt;h3 id=&quot;可靠性&quot;&gt;可靠性&lt;/h3&gt;

&lt;h3 id=&quot;独立试验和二项概率&quot;&gt;独立试验和二项概率&lt;/h3&gt;

&lt;h2 id=&quot;计数法&quot;&gt;计数法&lt;/h2&gt;

&lt;h3 id=&quot;计数准则&quot;&gt;计数准则&lt;/h3&gt;

&lt;h3 id=&quot;n-选-k-排列&quot;&gt;n 选 k 排列&lt;/h3&gt;

&lt;h3 id=&quot;组合&quot;&gt;组合&lt;/h3&gt;

&lt;h3 id=&quot;分割&quot;&gt;分割&lt;/h3&gt;

&lt;h1 id=&quot;离散随机变量&quot;&gt;离散随机变量&lt;/h1&gt;

&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;与随机变量有关的主要概念&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;随机变量&lt;/strong&gt;是试验结果的实值函数。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;注意：随机变量需要有数学取值（随机变量的取值），而不能是一个序列或其它无明显取值的量。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;随机变量的函数&lt;/strong&gt;定义了另一个随机变量。&lt;/li&gt;
  &lt;li&gt;对于一个随机变量，可以定义一些平均量，如&lt;strong&gt;均值&lt;/strong&gt;和&lt;strong&gt;方差&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;可以在某事件或随机变量的&lt;strong&gt;条件&lt;/strong&gt;之下定义一个随机变量。&lt;/li&gt;
  &lt;li&gt;存在一个随机变量与某事件或某随机变量相互&lt;strong&gt;独立&lt;/strong&gt;的概念。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;随机变量的分类&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;离散随机变量&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;连续随机变量&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;与离散随机变量相关的概念&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;离散随机变量&lt;/strong&gt;是试验结果的一个实值函数，但是它的取值范围只能是有限多个值或可数无限多个值。&lt;/li&gt;
  &lt;li&gt;一个随机变量有一个&lt;strong&gt;分布列&lt;/strong&gt;，它对于随机变量的每一个取值，给出一个概率。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;离散随机变量函数&lt;/strong&gt;也是一个离散随机变量，它的分布列可以从原随机变量的分布列得到。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;分布列&quot;&gt;分布列&lt;/h2&gt;

&lt;p&gt;用&lt;strong&gt;分布列&lt;/strong&gt;表示离散随机变量的取值概率的特征。用 $p_X$ 表示随机变量 $X$ 的分布列。设 $x$ 是随机变量 $X$ 的取值，则 $X$ 取值为 $x$ 的概率定义为事件 ${X=x}$ 的概率，即所有与 $x$ 对应的试验结果所组成的事件的概率，用 $p_X(x)$ 表示。&lt;/p&gt;

\[p_X(x) = P(\{X=x\})\]

&lt;blockquote&gt;
  &lt;p&gt;约定：用大写字母表示随机变量，用小写字母表示实数。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;分布列的性质&lt;/strong&gt;：&lt;/p&gt;

\[\sum_x p_X(x) = 1\\
P(X\in S) = \sum_{x\in S}p_X(x)\]

&lt;h3 id=&quot;伯努利随机变量&quot;&gt;伯努利随机变量&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;背景：抛掷一枚硬币，正面向上的概率为 $p$，反面向上的概率为 $1-p$。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;伯努利随机变量呈 0-1 分布，其分布列为：&lt;/p&gt;

\[p_X(k) =
\left\{
    \begin{array}{l}
        p &amp;amp; 若 k=1\\
        1-p &amp;amp; 若 k=0
    \end{array}
\right.\]

&lt;h3 id=&quot;二项随机变量&quot;&gt;二项随机变量&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;背景：将一枚硬币抛掷 $n$ 次，每次抛掷，正面出现的概率为 $p$，反面出现的概率为 $1-p$，而且各次抛掷是相互独立的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;分布列：&lt;/p&gt;

\[p_X(k) =
\left(
    \begin{array}{l}
        n \\
        k
    \end{array}
\right)
p^k(1-p)^{n-k}\]

&lt;h3 id=&quot;几何随机变量&quot;&gt;几何随机变量&lt;/h3&gt;

&lt;h3 id=&quot;泊松随机变量&quot;&gt;泊松随机变量&lt;/h3&gt;

&lt;h2 id=&quot;随机变量的函数&quot;&gt;随机变量的函数&lt;/h2&gt;

&lt;h2 id=&quot;期望均值和方差&quot;&gt;期望、均值和方差&lt;/h2&gt;

&lt;h3 id=&quot;方差矩和随机变量的函数的期望规则&quot;&gt;方差、矩和随机变量的函数的期望规则&lt;/h3&gt;

&lt;h3 id=&quot;均值和方差的性质&quot;&gt;均值和方差的性质&lt;/h3&gt;

&lt;h3 id=&quot;某些常用的随机变量的均值和方差&quot;&gt;某些常用的随机变量的均值和方差&lt;/h3&gt;

&lt;h3 id=&quot;利用期望值进行决策&quot;&gt;利用期望值进行决策&lt;/h3&gt;

&lt;h2 id=&quot;多个随机变量的联合分布列&quot;&gt;多个随机变量的联合分布列&lt;/h2&gt;

&lt;h3 id=&quot;多个随机变量的函数&quot;&gt;多个随机变量的函数&lt;/h3&gt;

&lt;h3 id=&quot;多于两个随机变量的情况&quot;&gt;多于两个随机变量的情况&lt;/h3&gt;

&lt;h2 id=&quot;条件&quot;&gt;条件&lt;/h2&gt;

&lt;h3 id=&quot;某个事件发生的条件下的随机变量&quot;&gt;某个事件发生的条件下的随机变量&lt;/h3&gt;

&lt;h3 id=&quot;给定另一个随机变量的值的条件下的随机变量&quot;&gt;给定另一个随机变量的值的条件下的随机变量&lt;/h3&gt;

&lt;h3 id=&quot;条件期望&quot;&gt;条件期望&lt;/h3&gt;

&lt;h2 id=&quot;独立性-1&quot;&gt;独立性&lt;/h2&gt;

&lt;h3 id=&quot;随机变量与事件的相互独立性&quot;&gt;随机变量与事件的相互独立性&lt;/h3&gt;

&lt;h3 id=&quot;随机变量之间的相互独立性&quot;&gt;随机变量之间的相互独立性&lt;/h3&gt;

&lt;h3 id=&quot;几个随机变量的相互独立性&quot;&gt;几个随机变量的相互独立性&lt;/h3&gt;

&lt;h3 id=&quot;若干个相互毒瘤的随机变量的和的方差&quot;&gt;若干个相互毒瘤的随机变量的和的方差&lt;/h3&gt;

&lt;h1 id=&quot;一般随机变量&quot;&gt;一般随机变量&lt;/h1&gt;

&lt;h2 id=&quot;连续随机变量和概率密度函数&quot;&gt;连续随机变量和概率密度函数&lt;/h2&gt;

&lt;h1 id=&quot;经典统计推断&quot;&gt;经典统计推断&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;本章中认为未知参数 $\theta$ 是确定（非随机）的，而取值未知。观测 $X$ 是随机的，根据 $\theta$ 取值的不同，服从 $p_X(x;\theta)$（若 $X$ 是离散的）或 $f_X(x;\theta)$（若 $X$ 是连续的）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;本章的主要术语、问题和方法&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;经典估计&lt;/strong&gt;是将未知参数看作是待确定的常数。对于未知参数的每个可能取值都假设一个单独的概率模型。&lt;/li&gt;
  &lt;li&gt;在&lt;strong&gt;参数估计&lt;/strong&gt;中，希望找到在未知参数取任何可能值的情况下都基本正确的估计。&lt;/li&gt;
  &lt;li&gt;在&lt;strong&gt;假设检验&lt;/strong&gt;中，未知参数对应于对立假设取有限的 $m(m\ge 2)$ 个值，想要选择一个假设，使得在任何可能的假设下错误的概率最小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;本章主要的经典推断方法&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;最大似然估计&lt;/strong&gt;：选择参数使得被观测到的数据“最有可能”出现，比如使获得当前数据的概率最大。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;线性回归&lt;/strong&gt;：在这样的意义下找出一组成对数据之间最合适的线性关系：这种线性关系使得模型与真实数据之间的差值的平方和最小&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;似然比检验&lt;/strong&gt;：给定两个假设，根据它们发生“可能性”的比值选择其一，使得犯错的概率适当小。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;显著性检验&lt;/strong&gt;：给定一个假设，当且仅当观测数据落在某个拒绝域的时候拒绝该假设，特别设计的拒绝域使得错误的概率低于某个给定阈值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;经典参数估计&quot;&gt;经典参数估计&lt;/h2&gt;

&lt;p&gt;将参数 $\theta$ 看作未知常数，而不是随机变量。&lt;/p&gt;

&lt;h3 id=&quot;估计量的性质&quot;&gt;估计量的性质&lt;/h3&gt;

&lt;p&gt;给定观测 $X=(X_1, …, X_n)$，&lt;strong&gt;估计量&lt;/strong&gt;是指形式为 $\hat{\Theta}=g(X)$ 的随机变量。注意，由于 $X$ 的分布依赖于 $\theta$，因而 $\hat{\theta}$ 的分布也一样。估计量 $\theta$ 的取值称为&lt;strong&gt;估计值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;估计量的相关术语&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$\hat{\Theta}$ 是未知参数 $\theta$ 的一个&lt;strong&gt;估计量&lt;/strong&gt;，也即关于 $n$ 个观测 $X_1, …, X_n$（服从依赖参数 $\theta$ 的分布）的一个函数。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;估计误差&lt;/strong&gt;，记为 $\tilde{\Theta}_n$，定义为 $\tilde{\Theta}_n=\hat{\Theta}_n-\theta$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;估计量的偏差&lt;/strong&gt;，记为 $b_\theta(\hat{\Theta}_n)$，是估计误差的期望值
\(b_\theta(\hat{\Theta}_n) = \textnormal{E}_\theta[\hat{\Theta}_n]-\theta\)&lt;/li&gt;
  &lt;li&gt;$\hat{\Theta}$ 的期望值、方差和偏差都依赖于 $\theta$，而估计误差同时还依赖于观测 $X_1, …, X_n$&lt;/li&gt;
  &lt;li&gt;称 $\hat{\Theta}&lt;em&gt;n$ &lt;strong&gt;无偏&lt;/strong&gt;，若 $\textnormal{E}&lt;/em&gt;\theta[\hat{\Theta}_n] = \theta$ 对于 $\theta$ 所有可能的取值都成立。&lt;/li&gt;
  &lt;li&gt;称 $\hat{\Theta}&lt;em&gt;n$ &lt;strong&gt;渐近无偏&lt;/strong&gt;，若 $\lim&lt;/em&gt;{n\rightarrow\infty}\textnormal{E}_\theta[\hat{\Theta}_n] = \theta$ 对于所有可能的取值都成立。&lt;/li&gt;
  &lt;li&gt;称 $\hat{\Theta}_n$ 为 $\theta$ 的&lt;strong&gt;相合&lt;/strong&gt;估计序列，如果对于 $\theta$ 所有可能的取值，序列 $\hat{\Theta}_n$ 依概率收敛到参数 $\theta$ 的真值。&lt;/li&gt;
&lt;/ul&gt;

\[\textnormal{E}_\theta[\tilde{\Theta}_n^2]=b_\theta^2(\hat{\Theta}_n)+\textnormal{var}_\theta(\hat{\Theta}_n)\]

&lt;h3 id=&quot;最大似然估计&quot;&gt;最大似然估计&lt;/h3&gt;

&lt;p&gt;设观测向量 $X=(X_1,…,X_n)$ 的联合分布列为 $p_X(x;\theta)=p_X(x_1, …, x_n;\theta)$（$\theta$ 可为向量或数量），其中 $X = (X_1, …, X_n)$ 为 $X$ 的观测值。那么，&lt;strong&gt;最大似然估计&lt;/strong&gt;是使（$\theta$ 的）数值函数 $p_X=(x_1, …, x_n;\theta)$ 达到最大的参数值：&lt;/p&gt;

\[\hat{\theta}_n=\underset{\theta}{\argmax} p_X(x_1, ..., x_n;\theta)\]

&lt;p&gt;当 $X$ 为连续型随机变量时，可将同样的方法用于联合概率密度函数 $f_X(x;\theta)$&lt;/p&gt;

\[\hat{\theta}_n=\underset{\theta}{\argmax} f_X(x_1, ..., x_n;\theta)\]

&lt;p&gt;称 $p_X(x;\theta)$（或 $f_X(x;\theta)$，若 $X$ 为连续型随机变量）为&lt;strong&gt;似然函数&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;对于已知 $X$ 的观测值 $x$，$p_X(x;\theta)$ 不是未知参数等于 $\theta$ 的概率，而是当参数取值为 $\theta$ 时，观测值 $x$ 可能出现的概率。
为取定 $\theta$ 的估计值时，会考虑基于已知的观测，$\theta$ 取什么值可使观测值最可能出现，这就是“似然”的本意。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;很多应用中都假设观测 $X_i$ 独立，从而对于每个 $i$，$X_i$ 是离散的随机变量，似然函数的形式为&lt;/p&gt;

\[p_X(x_1,...,x_n;\theta)=\prod_{i=1}^n p_{X_i}(x_i;\theta)\]

&lt;p&gt;在这种情况下，为了分析和计算的方便可让其对数达到最大，下面的式子称为&lt;strong&gt;对数似然函数&lt;/strong&gt;。&lt;/p&gt;

\[\ln p_X(x_1,...,x_n;\theta) =\ln \prod_{i=1}^n p_{X_i}(x_i;\theta) = \sum_{i=1}^n\ln p_{X_i}(x_i;\theta)\]

&lt;p&gt;当 $X$ 为连续型随机变量时，类似的用概率密度函数取代分布列：&lt;/p&gt;

\[\ln f_X(x_1,...,x_n;\theta) =\ln \prod_{i=1}^n f_{X_i}(x_i;\theta) = \sum_{i=1}^n\ln f_{X_i}(x_i;\theta)\]

&lt;h3 id=&quot;随机变量均值和方差的估计&quot;&gt;随机变量均值和方差的估计&lt;/h3&gt;

&lt;h3 id=&quot;置信区间&quot;&gt;置信区间&lt;/h3&gt;

&lt;h3 id=&quot;基于方差近似估计量的置信区间&quot;&gt;基于方差近似估计量的置信区间&lt;/h3&gt;

&lt;h2 id=&quot;线性回归&quot;&gt;线性回归&lt;/h2&gt;

&lt;h3 id=&quot;最小二乘公式的合理性&quot;&gt;最小二乘公式的合理性&lt;/h3&gt;

&lt;h3 id=&quot;贝叶斯线性回归&quot;&gt;贝叶斯线性回归&lt;/h3&gt;

&lt;h3 id=&quot;非线性回归&quot;&gt;非线性回归&lt;/h3&gt;

&lt;h2 id=&quot;简单假设检验&quot;&gt;简单假设检验&lt;/h2&gt;

&lt;h3 id=&quot;假设检验的基本思想与概念&quot;&gt;假设检验的基本思想与概念&lt;/h3&gt;

&lt;h4 id=&quot;假设检验问题&quot;&gt;假设检验问题&lt;/h4&gt;

&lt;p&gt;假如试验结果与假设 H 发生矛盾就拒绝原假设 H，否则就接受原假设。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;假设&lt;/strong&gt;：如 $\theta\in\Theta_0$ 或 $\theta\in\Theta_1$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;检验&lt;/strong&gt;或&lt;strong&gt;检验法则&lt;/strong&gt;：通过样本对一个假设作出“对”或“不对”的具体判断的规则称为该假设的一个检验或检验法则。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;检验的结果若是肯定该命题，则接受这个假设，否则就拒绝该假设。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;参数假设检验问题&lt;/strong&gt; &amp;amp; &lt;strong&gt;非参数假设检验问题&lt;/strong&gt;：若假设可用一个参数的集合表示，该假设问题称为&lt;strong&gt;参数假设检验问题&lt;/strong&gt;，否则称为&lt;strong&gt;非参数假设检验问题&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;假设检验的基本步骤&quot;&gt;假设检验的基本步骤&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;一般情况下，寻找某对假设的显著性检验的步骤如下：&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;根据实际问题，建立统计假设 $H_0$ vs $H_1$&lt;/li&gt;
    &lt;li&gt;选取一个合适的检验统计量 $T(X)$，使得当 $H_0$ 成立时（或 $H_0$ 中某个具体参数下），$T$ 的分布完全已知，并根据 $H_0$ 及 $H_1$ 的特点，确定拒绝域 $W$ 的形状&lt;/li&gt;
    &lt;li&gt;确定显著性水平 $\alpha$，确定具体的拒绝域 $W$&lt;/li&gt;
    &lt;li&gt;由样本观测值 $x_1,x_2,…,x_n$，计算检验统计量的 $T(x_1,…,x_n)$，由 $T(x_1,…,x_n)$ 是否属于 $W$，做出最终判断。&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;一建立假设&quot;&gt;一、建立假设&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;背景：
设有来自某一个参数分布族 ${F(x,\theta)|\theta\in\Theta}$ 的样本 $x_1, x_2,…,x_n$，其中 $\Theta$ 为&lt;strong&gt;参数空间&lt;/strong&gt;，设 $\Theta_0\subset \Theta$，且 $\Theta_0\not ={\emptyset}$，则命题 $H_0:\theta\in\Theta_0$ 称为一个假设或&lt;strong&gt;原假设&lt;/strong&gt;或&lt;strong&gt;零假设&lt;/strong&gt; (null hypothesis)，若有另一个 $\Theta_1(\Theta_1\subset\Theta$，$\Theta_1\Theta_0=\emptyset$，常见的一种情况是 $\Theta_1=\Theta-\Theta_0)$，则命题 $H_1:\theta\in\Theta_1$ 称为 $H_0$ 的&lt;strong&gt;对立假设&lt;/strong&gt;或&lt;strong&gt;备择假设&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;$H_0:\theta\in\Theta_0\qquad vs\qquad H_1:\theta\in\Theta_1$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;简单原假设&lt;/strong&gt;与&lt;strong&gt;复杂原假设&lt;/strong&gt;：如果 $\Theta_0$ 只含一个点，我们称之为&lt;strong&gt;简单原假设&lt;/strong&gt;，否则称之为&lt;strong&gt;复杂&lt;/strong&gt;或&lt;strong&gt;复合&lt;/strong&gt;原假设。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;双侧假设&lt;/strong&gt;或&lt;strong&gt;双边假设&lt;/strong&gt;：备择假设分散在原假设两侧，如 $H_1’:\theta\not ={\theta_0}$，$H_1’’:\theta&amp;lt;\theta_0$……&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;单侧假设&lt;/strong&gt;或&lt;strong&gt;单边假设&lt;/strong&gt;：备择假设位于原假设的一侧&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;二选择检验统计量给出拒绝域形式&quot;&gt;二、选择检验统计量，给出拒绝域形式&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;假设的检验&lt;/strong&gt;：对于假设的&lt;strong&gt;检验&lt;/strong&gt;是指这样的一个法则：当有了具体的样本后，按该法则就可以决定是接受 $H_0$ 还是拒绝 $H_0$，即检验就等于把样本空间划分为两个互不相交的部分 $W$ 和 $\overline{W}$，当样本属于 $W$ 时，拒绝 $H_0$；否则接受 $H_0$。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;拒绝域&lt;/strong&gt;与&lt;strong&gt;接受域&lt;/strong&gt;：称 $W$ 为该假设的&lt;strong&gt;拒绝域&lt;/strong&gt;，而 $\overline{W}$ 称为&lt;strong&gt;接受域&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;检验统计量&lt;/strong&gt;：由样本对原假设进行检验通过的统计量。&lt;/li&gt;
  &lt;li&gt;检验的&lt;strong&gt;判断准则&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;若 $(x_1,…,x_n)\in W$，则拒绝 $H_0$&lt;/li&gt;
      &lt;li&gt;若 $(x_1,…,x_n)\in \overline{W}$，则接受 $H_0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;三选择显著性水平&quot;&gt;三、选择显著性水平&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;第一类错误&lt;/strong&gt;与&lt;strong&gt;第二类错误&lt;/strong&gt;
| 观测数据情况 | $H_0$ 为真 | $H_1$ 为真 |
| — | — | — |
| $(x_1, x_2,…, x_n)\in W$ | 犯第一类错误 | 正确 |
} $(x_1, x_2,…, x_n)\in \overline{W}$ | 正确 | 犯第二类错误 |
    &lt;ul&gt;
      &lt;li&gt;称第一类错误为&lt;strong&gt;拒真错误&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;称第二类错误为&lt;strong&gt;取伪错误&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$\alpha$：犯第一类错误的概率：$\alpha=P_\theta{X\in W},\theta\in\Theta_0$，也记为 $P{X\in W&lt;/td&gt;
          &lt;td&gt;H_0}$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$\beta$：犯第二类错误的概率：$\beta=P_\theta{X\in\overline{W}&lt;/td&gt;
          &lt;td&gt;H_1}$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;势函数&lt;/strong&gt;或&lt;strong&gt;功效函数&lt;/strong&gt; (power function)
设检验问题 $H_0:\theta\in\Theta_0\qquad vs\qquad H_1:\theta\in\Theta_1$ 的拒绝域为 $W$，则样本观测值 $X$ 落在拒绝域 $W$ 内的概率称为该检验的&lt;strong&gt;势函数&lt;/strong&gt;，记为 $g(\theta)=P_\theta(X\in W)$，$\theta\in\Theta=\Theta_0\cup\Theta_1$&lt;/li&gt;
&lt;/ul&gt;

\[g(\theta) = 
\left\{
  \begin{array}
    \alpha(\theta) &amp;amp; \theta\in\Theta_0\\
    1-\beta(\theta) &amp;amp; \theta\in\Theta_1
  \end{array}
\right.\]

&lt;p&gt;或&lt;/p&gt;

\[g(\theta) = 
\left\{
  \begin{array}
    \alpha(\theta) = g(\theta) &amp;amp; \theta\in\Theta_0 \\
    \beta(\theta) = 1-g(\theta) &amp;amp; \theta\in\Theta_1
  \end{array}
\right.\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;显著性水平为 $\alpha$ 的显著性检验&lt;/strong&gt;：对检验问题 $H_0:\theta\in\Theta_0\qquad vs\qquad H_1:\theta\in\Theta_1$，如果一个检验满足对任意的$\theta\in\Theta_0$，都有 $g(\theta)\le\alpha$，则称该检验是显著性水平为 $\alpha$ 的显著性检验。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;常用的选择是 $\alpha = 0.05$，有时也可以选择 $\alpha=0.10$ 或 $\alpha=0.01$&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;四给出拒绝域&quot;&gt;四、给出拒绝域&lt;/h5&gt;

&lt;h5 id=&quot;五做出判断&quot;&gt;五、做出判断&lt;/h5&gt;

&lt;h4 id=&quot;检验的-p-值&quot;&gt;检验的 p 值&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;检验的 p 值&lt;/strong&gt;：再一个假设检验问题中，利用样本观测能够做出拒绝原假设的最小显著性水平称为检验的 p 值。
    &lt;ul&gt;
      &lt;li&gt;如果 $\alpha \ge p$，则再显著性水平 $\alpha$ 下拒绝 $H_0$&lt;/li&gt;
      &lt;li&gt;如果 $\alpha &amp;lt; p$，则在显著性水平 $\alpha$ 下接受 $H_0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;正态总体参数假设检验&quot;&gt;正态总体参数假设检验&lt;/h2&gt;

&lt;h3 id=&quot;单个正态总体均值的检验&quot;&gt;单个正态总体均值的检验&lt;/h3&gt;

&lt;p&gt;设 $x_1, …, x_n$ 是来自 $N(\mu,\sigma^2)$ 的样本，考虑如下三种关于 $\mu$ 的检验问题：&lt;/p&gt;

\[I\qquad H_0:\mu\le \mu_0 \qquad vs \qquad H_1:\mu&amp;gt;\mu_0\\
II\qquad H_0:\mu\ge\mu_0\qquad vs\qquad H_1:\mu&amp;lt;\mu_0 \\
III\qquad H_0:\mu = \mu_0\qquad vs\qquad H_1:\mu\not ={\mu_0}\]

&lt;p&gt;其中 $\mu_0$ 是已知常数。&lt;/p&gt;

&lt;h4 id=&quot;一sigma-已知时的-u-检验&quot;&gt;一、$\sigma$ 已知时的 $u$ 检验&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;检验统计量&lt;/strong&gt; $u = \frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}$
    &lt;ul&gt;
      &lt;li&gt;由于 $\mu$ 的点估计是 $\overline{x}$，且 $\overline{x}\sim N(\mu, \sigma^2/n)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;拒绝域&lt;/strong&gt; $W_1={(x_1,…,x_n):u\ge c}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;显著性检验&quot;&gt;显著性检验&lt;/h2&gt;

&lt;h3 id=&quot;一般方法&quot;&gt;一般方法&lt;/h3&gt;

&lt;h3 id=&quot;广义似然比和拟合优度检验&quot;&gt;广义似然比和拟合优度检验&lt;/h3&gt;</content><author><name>ericaaaaaaaa</name></author><category term="Statistics" /><category term="note" /><category term="statistics" /><category term="math" /><summary type="html">样本空间与概率</summary></entry><entry><title type="html">机器学习</title><link href="http://localhost:4000/machinelearning/2022/02/13/WatermelonBook.html" rel="alternate" type="text/html" title="机器学习" /><published>2022-02-13T00:00:00+08:00</published><updated>2022-02-13T00:00:00+08:00</updated><id>http://localhost:4000/machinelearning/2022/02/13/WatermelonBook</id><content type="html" xml:base="http://localhost:4000/machinelearning/2022/02/13/WatermelonBook.html">&lt;h1 id=&quot;概念&quot;&gt;概念&lt;/h1&gt;

&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;

&lt;h3 id=&quot;机器学习&quot;&gt;机器学习&lt;/h3&gt;

&lt;h3 id=&quot;数据&quot;&gt;数据&lt;/h3&gt;

&lt;h4 id=&quot;训练集&quot;&gt;训练集&lt;/h4&gt;

&lt;h4 id=&quot;验证集&quot;&gt;验证集&lt;/h4&gt;

&lt;h4 id=&quot;测试集&quot;&gt;测试集&lt;/h4&gt;

&lt;h2 id=&quot;模型评估&quot;&gt;模型评估&lt;/h2&gt;

&lt;h3 id=&quot;错误率-error-rate&quot;&gt;错误率 (error rate)&lt;/h3&gt;

&lt;p&gt;分类&lt;strong&gt;错误&lt;/strong&gt;的样本数占样本总数的比例称为“错误率”。&lt;/p&gt;

&lt;h3 id=&quot;精度-accuracy&quot;&gt;精度 (accuracy)&lt;/h3&gt;

&lt;p&gt;分类&lt;strong&gt;正确&lt;/strong&gt;的样本数占样本总数的比例称为“精度”。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;精度 = 1 - 错误率&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;误差-error&quot;&gt;误差 (error)&lt;/h3&gt;

&lt;p&gt;把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”。&lt;/p&gt;

&lt;h4 id=&quot;训练误差-training-error--经验误差-empirical-error&quot;&gt;训练误差 (training error) / 经验误差 (empirical error)&lt;/h4&gt;

&lt;p&gt;学习器再训练集上的误差。&lt;/p&gt;

&lt;h4 id=&quot;泛化误差-generalization-error&quot;&gt;泛化误差 (generalization error)&lt;/h4&gt;

&lt;p&gt;学习器在新样本上的误差。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;目标：得到泛化误差最小的学习器。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;拟合&quot;&gt;拟合&lt;/h3&gt;

&lt;h4 id=&quot;欠拟合-underfitting&quot;&gt;欠拟合 (underfitting)&lt;/h4&gt;

&lt;h4 id=&quot;过拟合-overfitting&quot;&gt;过拟合 (overfitting)&lt;/h4&gt;

&lt;h3 id=&quot;模型参数&quot;&gt;模型参数&lt;/h3&gt;

&lt;h4 id=&quot;超参数&quot;&gt;超参数&lt;/h4&gt;

&lt;p&gt;算法的参数，一般数量较少。&lt;/p&gt;

&lt;h4 id=&quot;其它参数&quot;&gt;其它参数&lt;/h4&gt;

&lt;p&gt;模型的参数，一般数量较多。&lt;/p&gt;

&lt;h2 id=&quot;模型&quot;&gt;模型&lt;/h2&gt;

&lt;h3 id=&quot;线性模型-linear-model&quot;&gt;线性模型 (linear model)&lt;/h3&gt;

&lt;h4 id=&quot;概念-1&quot;&gt;概念&lt;/h4&gt;

&lt;p&gt;线性模型试图学得一个通过属性的线性组合来进行预测的函数，即&lt;/p&gt;

\[f(x) = w_1x_1+w_2x_2+...+w_dx_d+b\]

&lt;p&gt;一般用向量形式写成&lt;/p&gt;

\[f(x) = w^Tx+b\]

&lt;p&gt;其中 $w=(w_1;w_2;…;2_d$。 $w$ 和 $b$ 学得之后，模型就得以确定。&lt;/p&gt;

&lt;h4 id=&quot;优缺点&quot;&gt;优缺点&lt;/h4&gt;

&lt;h3 id=&quot;非线性模型&quot;&gt;非线性模型&lt;/h3&gt;

&lt;h1 id=&quot;方法&quot;&gt;方法&lt;/h1&gt;

&lt;h2 id=&quot;模型评估-1&quot;&gt;模型评估&lt;/h2&gt;

&lt;h3 id=&quot;留出法-hold-out&quot;&gt;留出法 (hold-out)&lt;/h3&gt;

&lt;p&gt;将数据集 $D$ 划分为两个互斥的集合，其中一个作为训练集 $S$，另一个作为测试集 $T$，即 $D=S\cup T$, $S\cap T=\empty$，在$S$ 上训练出模型后，用 $T$ 来评估其测试误差，作为对泛化误差的估计。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要注意的是，训练 / 测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程中引入额外的偏差而对最终结果产生映像。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;由于存在多种划分方式对初始数据集 $D$ 进行分割，因此单次使用留出法的估计结果往往不够稳定可靠，在使用留出法时，一般采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;常见的做法是将大约 $2/3\sim 4/5$ 的样本用于训练、剩余样本用于测试。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;交叉验证法-cross-validation&quot;&gt;交叉验证法 (cross validation)&lt;/h3&gt;

&lt;p&gt;先将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集，即 $D=D_1\cup D_2\cup…\cup D_k$, $D_i\cap D_j=\empty (i\not= j)$，每个子集 $D_i$ 都尽可能保持数据分布的一致性，即从 $D$ 中通过分层采样得到。然后每次用 $k-1$ 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可以获得 $k$ 组训练 / 测试集，从而可以进行 $k$ 次训练 / 测试，最终返回的是这 $k$ 个测试结果的均值。&lt;/p&gt;

&lt;p&gt;交叉验证法评估结果的稳定性和保真性很大程度上取决于 $k$ 的取值，通常把交叉验证法称为&lt;strong&gt;k 折交叉验证&lt;/strong&gt; (k-fold cross validation)。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$k$ 最常用的取值是 10。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;将数据集 $D$ 划分为 $k$ 个子集，随机使用不同的划分重复 $p$ 次，最终的评估结果是这 $p$ 次 $k$ 折交叉验证结果的均值，称为 $p$ 次 $k$ 折交叉验证。&lt;/p&gt;

&lt;h4 id=&quot;留一法-leave-one-out-loo&quot;&gt;留一法 (Leave-One-Out, LOO)&lt;/h4&gt;

&lt;p&gt;假定数据集 $D$ 中包含 $m$ 个样本，若令 $k=m$，则得到交叉验证法的一个特例——留一法。&lt;/p&gt;

&lt;p&gt;由于留一法不受随机样本划分方式的映像，因此在绝大多数情况下，留一法中被实际评估的模型与期望评估的用 $D$ 训练出来的模型很相似。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;留一法的评估结果往往被认为比较准确。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;留一法在数据集较大的情况下的开销是巨大的。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;自助法-bootstrapping&quot;&gt;自助法 (bootstrapping)&lt;/h3&gt;

&lt;p&gt;自助法直接以自助采样法 (bootstrapping sampling) 为基础。给定包含 $m$ 个样本的数据集 $D$，对它进行采样产生数据集 $D’$。每次随机从 $D$ 中挑选一个样本，将其拷贝放入 $D’$，然后再将该样本放回初始数据集 $D$ 中，使得该样本在下次采样时仍有可能被采到。上述过程重复执行 $m$ 次后，得到包含 $m$ 个样本的数据集 $D’$，这就是自助采样的结果。&lt;/p&gt;

&lt;p&gt;$D$ 中有一部分样本会在 $D’$ 中多次出现，而另一部分样本不出现。估计样本在 $m$ 次采样中始终不被采到的概率是 $(1-\frac{1}{m})^m$，取极限得到
\(\lim_{m\rightarrow \infty}(1-\frac{1}{m})^m = \frac{1}{e}\approx 0.368\)
由上式可得，通过自助采样，初始数据集 $D$ 中约有 36.8% 的样本未出现在采样数据集 $D’$ 中。将 $D’$ 用作训练集，$D/D’$ 用作测试集；这样，实际评估的模型与期望评估的模型都使用 $m$ 个训练样本，而我们仍有数据总量约 $1/3$ 的，没在训练集中出现过的样本用于测试，这样的测试结果，亦称为“&lt;strong&gt;包外估计&lt;/strong&gt;” (out-of-bag estimate)。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;自助法在数据集较小、难以有效划分训练 / 测试集时很有用。&lt;/li&gt;
      &lt;li&gt;自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大好处。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;自助法产生的数据集改变了初始数据集的分布，会引入估计偏差。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;调参与最终模型&quot;&gt;调参与最终模型&lt;/h3&gt;

&lt;h2 id=&quot;性能度量-performance-measure&quot;&gt;性能度量 (performance measure)&lt;/h2&gt;

&lt;p&gt;衡量模型泛化能力的评价标准。&lt;/p&gt;

&lt;p&gt;不同的任务需求会有不同的性能度量方式。&lt;/p&gt;

&lt;h3 id=&quot;分类任务&quot;&gt;分类任务&lt;/h3&gt;

&lt;h4 id=&quot;错误率与精度&quot;&gt;错误率与精度&lt;/h4&gt;

&lt;h5 id=&quot;错误率&quot;&gt;错误率&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;错误率&lt;/strong&gt;是分类错误的样本数占样本总数的比例。&lt;/p&gt;

&lt;p&gt;对于样例集 $D$，错误率 $E$ 定义为：
\(E(f;D)=\frac{1}{m}\sum_{i=l}^{m}\mathbb{I}(f(x_i)\not= y_i)\)&lt;/p&gt;

&lt;h5 id=&quot;精度&quot;&gt;精度&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;精度&lt;/strong&gt;是分类正确的样本数占样本总数的比例。&lt;/p&gt;

&lt;p&gt;对于样例集 $D$，精度 $acc$ 定义为：
\(acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_i)=y_i)=1-E(f;D)\)
更一般的，对于数据分布 $D$ 和概率密度函数 $p(\cdot)$，错误率和精度可以分别描述为
\(E(f;D)=\int_{x\sim D}\mathbb{I}(f(x)\not= y)p(x)dx\\
acc(f;D)=\int_{x\sim D}\mathbb{I}(f(x)= y)p(x)dx = 1-E(f;D)\)&lt;/p&gt;

&lt;h4 id=&quot;查准率查全率与-f1&quot;&gt;查准率、查全率与 F1&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;真实情况 \ 预测结果&lt;/th&gt;
      &lt;th&gt;正例&lt;/th&gt;
      &lt;th&gt;反例&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;正例&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$TP$ （真正例）&lt;/td&gt;
      &lt;td&gt;$FN$（假反例）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;反例&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;$FP$（假正例）&lt;/td&gt;
      &lt;td&gt;$TN$（真反例）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;查准率-precision&quot;&gt;查准率 (precision)&lt;/h5&gt;

&lt;p&gt;预测正例中真实正例的占比。
\(P = \frac{TP}{TP+FP}\)&lt;/p&gt;

&lt;h5 id=&quot;查全率-recall&quot;&gt;查全率 (recall)&lt;/h5&gt;

&lt;p&gt;真实正例中预测正例的占比。
\(P = \frac{TP}{TP+FN}\)
查准率和查全率是一对矛盾的变量，查准率高时，查全率往往偏低。&lt;/p&gt;

&lt;h5 id=&quot;p-r-曲线查准率-查全率曲线&quot;&gt;P-R 曲线（查准率-查全率曲线）&lt;/h5&gt;

&lt;p&gt;根据学习器的预测结果对样例进行排序，从最有可能为正例的样本开始，到最不可能为正例的样本，按此顺序逐一将样本作为正例进行预测，每次可以计算出当前的查全率、查准率。以查准率为纵轴，以查全率为横轴作图，得到查准率-查全率曲线，简称“P-R 曲线”，显示该曲线的图称为“P-R 图”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.geeksforgeeks.org/wp-content/uploads/20190611002050/pr_roc.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;P-R 曲线越靠外，模型效果越好。&lt;/p&gt;

&lt;h6 id=&quot;度量&quot;&gt;度量&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;平衡点&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;”&lt;strong&gt;平衡点&lt;/strong&gt;“ (Break-Even Point, BEP) 是查准率和查全率的一个性能度量，它是”&lt;strong&gt;查准率 = 查全率&lt;/strong&gt;“时的取值。平衡点值越高，可以认为模型越优。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;$F1$ 度量&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;F1 基于查准率与查全率的调和平均 (harmonic mean) 定义：
\(\frac{1}{F1} = \frac{1}{2} \cdot (\frac{1}{P} + \frac{1}{R}) \\
F1 = \frac{2\times P\times R}{P+R} = \frac{2\times TP}{样例总数+TP-TN}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;$F_\beta$ 度量&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;在一些任务中，对查准率和查全率的重视程度有所不同，因此引入 $F1$ 度量的一般形式——$F_\beta$，它能够表达出对查准率 / 查全率的不同偏好，定义为查准率和查全率的加权调和平均：
\(\frac{1}{F_\beta} = \frac{1}{1+\beta^2} \cdot (\frac{1}{P} + \frac{\beta^2
}{R}) \\
F_\beta = \frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}\)
其中 $\beta&amp;gt;0$ 度量了查全率对查准率的相对重要性，$\beta=1$ 时退化为标准的 $F1$；$\beta&amp;gt;1$ 时查全率有更大影响；$0&amp;lt;\beta&amp;lt;1$ 时查准率有更大影响。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;全局&quot;&gt;全局&lt;/h6&gt;

&lt;p&gt;先在各混淆矩阵上分别计算出查准率和查全率，记为 $(P_1, R_1),(P_2,R_2),…,(P_n,R_n)$，再计算平均值，这样就得到“宏查准率” (macro-P)，“宏查全率” (“macro-R”)，以及相应的“宏-$F1$” (macro-$F1$)
\(macro{\textit-}P= \frac{1}{n}\sum_{i=1}^n P_i\\
macro{\textit-}R = \frac{1}{n}\sum_{i=1}^n R_i\\
macro{\textit-}F1 = \frac{2\times macro{\textit-}P\times macro{\textit-}R}{macro{\textit-}P+macro{\textit-}R}\)&lt;/p&gt;

&lt;h6 id=&quot;局部&quot;&gt;局部&lt;/h6&gt;

&lt;p&gt;先将各混淆矩阵的对应元素进行平均，得到 $TP$、$FP$、$TN$、$FN$ 的平均值，分别记为 $\overline{TP}$、$\overline{FP}$、$\overline{TN}$、$\overline{FN}$，再基于这些平均值计算出“微查准率” ($micro{\textit-}P$)、“微查全率” ($micro{\textit-}R$) 和“微 $F1$” ($micro{\textit-}F1$)：
\(micro{\textit-}P = \frac{\overline{TP}}{\overline{TP}+\overline{FP}}\\
micro{\textit-}R = \frac{\overline{TP}}{\overline{TP}+\overline{FN}}\\
micro{\textit-}F1 = \frac{2\timesmicro{\textit-}P\timesmicro{\textit-}R}{micro{\textit-}P+micro{\textit-}R}\)&lt;/p&gt;

&lt;h4 id=&quot;roc-与-auc&quot;&gt;ROC 与 AUC&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;很多学习器是测试样本产生一个实值或概率预测，然后将这个预测值与一个分类域值 (threshold) 进行比较，若大于域值则分正类，否则为反类。这个分类域值直接决定了学习器的泛化能力。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ROC 的全称是“受试者工作特征”（Receiver Operating Characteristic）曲线。其&lt;strong&gt;以“真正例率 (True Positive Rate, TPR)” 为纵轴&lt;/strong&gt;，&lt;strong&gt;以“假正例率 (False Positive Rate, FPR)” 为横轴&lt;/strong&gt;。&lt;/p&gt;

\[TPR = \frac{TP}{TP+TN}\\
FPR = \frac{FP}{TN+FP}\]

&lt;p&gt;显示 ROC 曲线的图称为“ROC”图。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;图像分析&lt;/strong&gt;：ROC 图中对角线对应于“随机猜测”模型，而点 (0,1) 对应将所有正例排在所有反例之前的“理想模型”。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;绘图过程&lt;/strong&gt;：给定 $m^+$ 个正例和 $m^-$ 个反例，根据学习器预测结果对样例进行排序，然后把分类域值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为 0，在坐标 (0, 0) 处标记一个点。然后，将分类域值依次设置为每个样例的预测值，即依次将每个样例划分为正例，设前一个标记点坐标为 (x, y)，当前若为真正例，则对应标记点的坐标为 (x, y+$\frac{1}{m^+}$)，当前若为假正例，则对应标记点的坐标为 (x+$\frac{1}{m^-}$, y)，然后用线段连接相应点即得。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;学习器比较&lt;/strong&gt;：比较 ROC 曲线下的面积，即 &lt;strong&gt;AUC(Area Under ROC Curve)&lt;/strong&gt;，AUC 越大，则学习器效果越好。
\(AUC = \frac{1}{2}+\sum_{i=1}^{m-1}(x_{i+1}-x_i)\cdot(y_i+y_{i+1})\)
定义排序“损失” (loss) 为：
\(l_{rank} = \frac{1}{m^+m^-}\sum_{x^+\in D^+}\sum_{x^-\in D^-}(\mathbb{I}(f(x^+)&amp;lt;f(x^-))+\frac{1}{2}\mathbb{I}(f(x^+)=f(x^-)))\)
从几何意义上看，$l_{rank}$ 对应的是 ROC 曲线之上的面积，故有：
\(AUC + l_{rank} = 1\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;代价敏感错误率与代价曲线&quot;&gt;代价敏感错误率与代价曲线&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;在现实任务中，不同类型的错误所造成的后果不同。，为权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价” (unequal cost)。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;根据任务的领域知识设定一个“代价矩阵” (cost matrix)，其中 $cost_{ij}$ 表示将第 $i$ 类样本预测为第 $j$ 类样本的代价。一般来说，$cost_{ii}=0$&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;一般情况下，重要的是 $cost$ 之间的&lt;em&gt;比值&lt;/em&gt;而非&lt;em&gt;绝对值&lt;/em&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;目标：最小化“总体代价” (total cost)。&lt;/p&gt;

&lt;p&gt;以二分类为例，将第 0 类作为正类，第 1 类作为反类，$D^+$ 与 $D^-$ 分别代表样例集 $D$ 的正例子集和反例子集，则“代价敏感” (cost-sensitive) 错误率为：&lt;/p&gt;

\[E(f;D;cost) = \frac{1}{m}(\sum_{x_i\in D^+}\mathbb{I}(f(x_i)\not ={y_i})\times cost_{01} +
                          \sum_{x_i\in D^-}\mathbb{I}(f(x_i)\not ={y_i})\times cost_{10})\]

&lt;p&gt;在非均等代价下，ROC 曲线不能直接反映出学习器的期望总体代价，而“代价曲线” (cost curve) 则可以达到该目的，代价曲线图的横轴是取值为 [0, 1] 的正例概率代价&lt;/p&gt;

\[p(+)cost = \frac{\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}\]

&lt;p&gt;其中 $p$ 的样例为正例的概率；纵轴是取值为 [0, 1] 的归一化代价。&lt;/p&gt;

\[cost_{norm} = \frac{FNR\times p\times cost_{01}+FPR\times(1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}\]

&lt;h3 id=&quot;聚类任务&quot;&gt;聚类任务&lt;/h3&gt;

&lt;h2 id=&quot;比较检验&quot;&gt;比较检验&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;统计假设检验&lt;/strong&gt; (hypothesis test) 为我们的学习器性能提供了重要依据。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在下述部分以错误率为性能度量，用 $\epsilon$ 表示。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;假设检验&quot;&gt;假设检验&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;假设检验中的“假设”是对学习器泛化错误率分布的某种判断或猜想。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;可根据测试错误率估推出泛化错误率的分布。&lt;/p&gt;

&lt;p&gt;泛化错误率为 $\epsilon$ 的学习器在一个样本上犯错的概率是 $\epsilon$；测试错误率 $\hat{\epsilon}$ 意味着在 $m$ 个测试样本中恰有  $\hat{\epsilon}\times m$ 个被误分类。假定测试样本是从样本总体分布中独立采样而得，那么泛化错误率为 $\epsilon$ 的学习器将其中 $m’$ 的样本误分类、其余样本全部分类正确的概率为 $\left(\begin{array}{l}m\m’\end{array}\right)\epsilon^{m’}(1-\epsilon)^{m- m’}$ ；由此可估算出其恰好将 $\hat{\epsilon}\times m$ 个样本误分类的概率如下式所示，这也表达了在 $m$ 个样本集的测试集上，泛化错误率为 $\epsilon$ 的学习器被测得测试错误率为 $\hat{\epsilon}$ 的概率：&lt;/p&gt;

\[P(\hat{\epsilon};\epsilon) = 
\left(
  \begin{array}{l}
  m\\
  \hat{\epsilon}\times m  \end{array}
\right)
\epsilon^{\hat{\epsilon}\times m}(1-\epsilon)^{m- \hat{\epsilon}\times m}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;给定测试错误率，则解 $\partial P(\hat{\epsilon};\epsilon)/\partial\epsilon$ 可知，$P(\hat{\epsilon};\epsilon)$ 在 $\epsilon=\hat{\epsilon}$ 时最大，$&lt;/td&gt;
      &lt;td&gt;\epsilon-\hat{\epsilon}&lt;/td&gt;
      &lt;td&gt;$ 增大时 $P(\hat{\epsilon}, \epsilon)$ 减小。这符合&lt;strong&gt;二项分布 (binomial)&lt;/strong&gt; 分布。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;考虑假设 “$\epsilon\le\hat{\epsilon}$”，则在 $1-\alpha$ 的概率内所能观测到的最大错误率如下：&lt;/p&gt;

\[\overline{\epsilon} = \min\epsilon\qquad s.t.\qquad \sum_{i=\epsilon_0\times m+1}^{m}
\left(
\begin{array}{c}
  m\\
  i
\end{array}
\right)\epsilon^i(1-\epsilon)^{m-i}\alpha\]

&lt;p&gt;其中 $1-\alpha$ 反映了结论的“置信度” (confidence)。&lt;/p&gt;

&lt;p&gt;此时若测试错误率 $\hat{\epsilon}$ 小于临界值 $\overline{\epsilon}$，则根据二项检验可得出结论：在 $\alpha$ 的显著度下，假设 “$\epsilon\le\epsilon_0$” 不能被拒绝，即能以 $1-\alpha$ 的置信度认为，学习器的泛化错误率不大于 $\epsilon_0$；否则该假设可被拒绝，即在 $\alpha$ 的显著度下可认为学习器的泛化错误率大于 $\epsilon_0$。&lt;/p&gt;

&lt;p&gt;在很多时候我们并非仅做一次留出法估计，而是通过多次重复留出法或是交叉验证法等进行多次训练 / 测试，这样会得到多个测试错误率，此时可使用 “t-检验” (t-testr)。假定我们得到了 $k$ 个测试错误率，$\hat{\epsilon}_1$，$\hat{\epsilon}_2$，…，$\hat{\epsilon}_k$，则平均测试错误率 $\mu$ 和方差 $\sigma^2$ 为&lt;/p&gt;

\[\mu = \frac{1}{k}\sum_{i=1}^{k}\hat{\epsilon}_i\\
\sigma^2 = \frac{1}{k-1}\sum_{i=1}^{k}(\hat{\epsilon_i}-\mu)^2\]

&lt;p&gt;可以考虑到这 $k$ 个测试错误率可看作泛化错误率 $\epsilon_0$ 的独立采样，则变量&lt;/p&gt;

\[\tau_t = \frac{\sqrt{k}(\mu-\epsilon_0)}{\sigma}\]

&lt;p&gt;服从自由度为 $k-1$ 的 $t$ 分布。&lt;/p&gt;

&lt;h3 id=&quot;交叉验证-t-检验&quot;&gt;交叉验证 t 检验&lt;/h3&gt;

&lt;p&gt;对两个学习器 $A$ 和 $B$,若我们使用 $k$ 折交叉验证法得到的错误率分别为 $\epsilon_1^A,\epsilon_2^A,…,\epsilon_k^A$ 和 $\epsilon_1^B,\epsilon_2^B,…,\epsilon_k^B$。可用 $k$ 折交叉验证“成对 t 检验” (paired-tests) 来进行比较检验。这里的基本思想是若两个学习器的性能相同，则它们使用相同训练 / 测试集得到的测试错误率应相同，即 $\epsilon_i^A=\epsilon_i^B$。&lt;/p&gt;

&lt;p&gt;具体的来说，对 $k$ 折交叉验证所产生的 $k$ 对测试错误率：先对每对结果求差，$\delta_i=\epsilon_i^A-\epsilon_i^B$；若两个学习器性能相同，则差值均值应为 0.因此，可根据差值 $\delta_1,\delta_2,…,\delta_k$ 来对“学习器 $A$ 与 $B$ 性能相同”这个假设做 $t$ 检验，计算出差值的均值 $\mu$ 和方差 $\sigma^2$，在显著度 $\alpha$ 下，若变量&lt;/p&gt;

&lt;h3 id=&quot;mcnemar-检验&quot;&gt;McNemar 检验&lt;/h3&gt;

&lt;h3 id=&quot;friedman-检验与-nemenyi-后续检验&quot;&gt;Friedman 检验与 Nemenyi 后续检验&lt;/h3&gt;

&lt;h2 id=&quot;偏差与方差&quot;&gt;偏差与方差&lt;/h2&gt;

&lt;h1 id=&quot;线性模型&quot;&gt;线性模型&lt;/h1&gt;</content><author><name>ericaaaaaaaa</name></author><category term="MachineLearning" /><category term="book-report" /><category term="artificial-intelligence" /><category term="machine-learning" /><summary type="html">概念</summary></entry><entry><title type="html">Machine Learning</title><link href="http://localhost:4000/artificialintelligence/2022/01/28/MachineLearning.html" rel="alternate" type="text/html" title="Machine Learning" /><published>2022-01-28T00:00:00+08:00</published><updated>2022-01-28T00:00:00+08:00</updated><id>http://localhost:4000/artificialintelligence/2022/01/28/MachineLearning</id><content type="html" xml:base="http://localhost:4000/artificialintelligence/2022/01/28/MachineLearning.html">&lt;center&gt;&lt;h1&gt;Machine Learning&lt;/h1&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tutor: $\mathscr{Andrew Ng}$&lt;/p&gt;

  &lt;p&gt;Author of the notebook: $\mathscr{ericaaaaaaaa}$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Machine Learning&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;A computer program is said to &lt;i&gt;learn&lt;/i&gt; from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.&lt;/div&gt;
&lt;div&gt;Category&lt;ul&gt;&lt;li&gt;Supervised Learning&lt;/li&gt;&lt;li&gt;Unsupervised Learning&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;

&lt;h2 id=&quot;categories&quot;&gt;Categories&lt;/h2&gt;

&lt;h3 id=&quot;supervised--unsupervised&quot;&gt;Supervised &amp;amp; Unsupervised&lt;/h3&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Supervised Learning&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;&quot;right answers&quot; given&lt;/div&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Unsupervised Learning&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;no &quot;right answers&quot; given&lt;/div&gt;

&lt;h3 id=&quot;regression--classification&quot;&gt;Regression &amp;amp; Classification&lt;/h3&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Regression Problem&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;Predict &lt;b&gt;continuous&lt;/b&gt; valued output.&lt;/div&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Classification Problem&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;Predict &lt;b&gt;discrete&lt;/b&gt; valued output.&lt;/div&gt;

&lt;h2 id=&quot;notations&quot;&gt;Notations&lt;/h2&gt;

&lt;div style=&quot;background-color: #E9F8D6;&quot;&gt;&lt;b&gt;&lt;h4&gt;Notations&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;
&lt;li&gt;&lt;b&gt;m&lt;/b&gt; = Number of training examples&lt;/li&gt;
&lt;li&gt;&lt;b&gt;x&lt;/b&gt; = input variables / features&lt;/li&gt;
&lt;li&gt;&lt;b&gt;y&lt;/b&gt; = output variable / features&lt;/li&gt;
&lt;li&gt;&lt;b&gt;h&lt;/b&gt; = hypothesis &lt;/li&gt;
&lt;li&gt;&lt;b&gt;(x, y)&lt;/b&gt; = one training example&lt;/li&gt;
&lt;li&gt;&lt;b&gt;(x&lt;sup&gt;i&lt;/sup&gt;, y&lt;sup&gt;i&lt;/sup&gt;)&lt;/b&gt; = i&lt;sup&gt;th&lt;/sup&gt; training example&lt;/li&gt;
&lt;/div&gt;

&lt;p&gt;The learning algorithm uses the training set to find the best hypothesis h which maps from x to y.&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Linear Regression&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;Predict Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. A linear regression line has an equation of the form &lt;b&gt;Y = a + bX&lt;/b&gt;, where X is the explanatory variable and Y is the dependent variable.&lt;/div&gt;

&lt;h2 id=&quot;loss-function-cost-function&quot;&gt;Loss Function (Cost Function)&lt;/h2&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Loss Function&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;A loss function is a function that maps an event or values of one or more variables onto a real number intuitively representing some &quot;cost&quot; asspcoated with the event.&lt;/div&gt;
&lt;div&gt;An optimization problem seeks to &lt;b&gt;minimize&lt;/b&gt; a loss function.&lt;/div&gt;

&lt;center&gt;&lt;h2&gt;Part I. Linear Regression&lt;/h2&gt;&lt;/center&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;h3 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h3&gt;

&lt;p&gt;Start with some initial $\theta$, and repeatedly performs the update to minimize $J(\theta)$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\alpha$: &lt;strong&gt;learning rate&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;$\theta$: parameter(s)&lt;/li&gt;
  &lt;li&gt;$J(\theta)$: cost function&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;lms-update-rule&quot;&gt;LMS Update Rule&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;LMS&lt;/strong&gt; stands for &lt;strong&gt;least mean squares&lt;/strong&gt;.
\(J(\theta) = \frac{1}{2}\sum_{i=1}^{n}(h_\theta(x^{(i)})-y^{(i)})^2 \\
\theta_j\gets \theta_j - \alpha \frac{\part}{\part\theta_j}J(\theta) 
\gets \theta_j + \alpha (y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}\)&lt;/p&gt;

&lt;h4 id=&quot;classification&quot;&gt;Classification&lt;/h4&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Batch Gradient Descent (Batch GD)&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;Looks at every example in the &lt;b&gt;entire training set&lt;/b&gt; on every step.&lt;/div&gt;

\[\theta_j\gets \theta_j - \alpha \frac{\part}{\part\theta_j}J(\theta)\]

&lt;ul&gt;
  &lt;li&gt;Computationally Expensive&lt;/li&gt;
  &lt;li&gt;Great for convex or relatively smooth error manifolds&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;Stochastic Gradient Descent (SGD) (Incremental Gradient Descent)&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;Repeatedly run through the training set, and each time we encounter a training example, we update the parameters according to the gradient of the error with respect to that &lt;b&gt;single training example only&lt;/b&gt;.&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;doesn’t settle at global minimum (can be solved by reducing learning rate)&lt;/li&gt;
  &lt;li&gt;faster and less computationally expensive&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-normal-equations&quot;&gt;The Normal Equations&lt;/h3&gt;

&lt;h4 id=&quot;matrix-derivatives&quot;&gt;Matrix Derivatives&lt;/h4&gt;

&lt;p&gt;For a function $f$: $\R^{n\times d}\rightarrow \R$ mapping from n-by-d matrices to the real numbers, we define the derivative of $f$ with respect to $A$ be:
\(\triangledown_A f(A) = 
\begin{bmatrix}
\frac{\part f}{\part A_{11}} &amp;amp; ... &amp;amp; \frac{\part f}{\part A_{1d}} \\
... &amp;amp; ... &amp;amp; ...\\
\frac{\part f}{\part A_{n1}} &amp;amp; ... &amp;amp; \frac{\part f}{\part A_{nd}}
\end{bmatrix}\)&lt;/p&gt;

&lt;h4 id=&quot;least-squares-revisited&quot;&gt;Least squares revisited&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;define the matrix X to be the n-by-d matrix that contains the training examples’ input values in its rows.
\(X = \begin{bmatrix}(x^{(1)})^T\\ (x^{(2)})^T\\ ...\\ (x^{(n)})^T\end{bmatrix}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;define $\overrightarrow{y}$ to be the n-dimensional vector containing all the target values from the training set.
\(\overrightarrow{y} = \begin{bmatrix}y^{(1)}\\ y^{(2)}\\ ...\\ y^{(n)}\end{bmatrix}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The loss function $J$ can be represented by
\(J(\theta) = \frac{1}{2}(X_\theta-\overrightarrow{y})^T(X_\theta-\overrightarrow{y})\)
To minimize $J$, we set its derivatives to zero, and obtain the &lt;strong&gt;normal equations&lt;/strong&gt;:
\(X^TX\theta = X^T\overrightarrow{y}\)
Minimize $J(\theta)$ by explicitly taking its derivatives with respect to the $\theta_j$’s, and setting them to zero.
\(\theta = (X^TX)^{-1}X^T\overrightarrow{y}^3\)&lt;/p&gt;

&lt;h3 id=&quot;probabilistic-interpretation&quot;&gt;Probabilistic Interpretation&lt;/h3&gt;

&lt;p&gt;Give a set of probabilistic assumptions&lt;/p&gt;

&lt;p&gt;Under he previous probabilistic assumptions on the data. least-squares regression corresponds to finding the maximum likelihood estimate of $\theta$.&lt;/p&gt;

&lt;p&gt;Assume that the target variables and the inputs are related via the equation $y^{(i)}=\theta^Tx^{(i)}+\varepsilon^{(i)}$.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$\varepsilon^{(i)}$ is an error term that captures either unmodeled effects or random noise. Assume that $\varepsilon^{(i)}$ are distributed according to the Gaussian distribution with mean zero and some variance $\sigma^2$, namely $\varepsilon^{(i)}\sim N(0, \sigma^2)$&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/720px-Normal_Distribution_PDF.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

  &lt;p&gt;$p(\varepsilon^{(i)})=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(\varepsilon^{(i)})^2}{2\sigma^2})$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The principle of &lt;strong&gt;maximum likelihood&lt;/strong&gt; says that we should choose $\theta$ to maximize $L(\theta)$.&lt;/p&gt;

&lt;p&gt;Instead of maximizing $l(\theta)$, we can also maximize any strictly increasing function of $L(\theta)$. In particular, the derivations will be simpler if we instead maximize the &lt;strong&gt;log likelihood&lt;/strong&gt; $\mathscr{l}(\theta) = \log L(\theta) = n\log \frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{\sigma^2}\cdot\frac{1}{2}\sum_{i=1}^{n}(y^{(i)}-\theta^Tx^{(i)})^2$.&lt;/p&gt;

&lt;h3 id=&quot;locally-weighted-linear-regression-lwr&quot;&gt;Locally Weighted Linear Regression (LWR)&lt;/h3&gt;

&lt;p&gt;Is a kind of &lt;strong&gt;non-parametric&lt;/strong&gt; algorithm.&lt;/p&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;non-parametric algorithm&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;Algorithms that do not make strong assimptions about the form of the mapping function. By not making assumptions, they are free to learn any functional form from the training data.&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;: capable of fitting a large number of functional forms&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Power&lt;/strong&gt;: No assumptions (or weak assumptions) about the underlying function&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: Can result in higher performance models for prediction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;More data&lt;/strong&gt;: require a lot more training data to estimate the mapping function&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Slower&lt;/strong&gt;: A lot slower to train as they often have a far more parameters to train&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt;: More of a risk to overfit the training data and it is harder to explain why specific predictions are made.&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;parametric algorithm&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;AS learning model that summarizes the data with a set of parameters of fixed size.&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;Select a form for the function.&lt;/li&gt;
  &lt;li&gt;Learn the coefficients for the function from the training data.&lt;/li&gt;
&lt;/ol&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;underfitting&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;The model cannot capture the underlying trend of the data&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;cause&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;too few data&lt;/li&gt;
      &lt;li&gt;the learning model is too easy and flexible&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;solution&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Increase model complexity.&lt;/li&gt;
      &lt;li&gt;Increase the number of features, performing feature engineering.&lt;/li&gt;
      &lt;li&gt;remove noise from the data.&lt;/li&gt;
      &lt;li&gt;Increase the number of epochs or increase the duration of training to get better results.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;background-color: #D6EAF8;&quot;&gt;&lt;b&gt;&lt;h4&gt;overfitting&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;
&lt;div&gt;The model contains too many detail and noise&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;cause&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;non-parametric and non-linear methods&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;solution&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Increase training data&lt;/li&gt;
      &lt;li&gt;Reduce model complexity&lt;/li&gt;
      &lt;li&gt;Early stopping during the training phase&lt;/li&gt;
      &lt;li&gt;Ridge Regularization and Lasso Regularization&lt;/li&gt;
      &lt;li&gt;Use dropout for neural networks to tackle overfitting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;procedure-of-lwr&quot;&gt;Procedure of LWR&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Fit $\theta$ to minimize $\sum_i\bold{w^{(i)}}(y^{(i)}-\theta^Tx^{(i)})^2$&lt;/li&gt;
  &lt;li&gt;Output of $\theta^Tx$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The $w^{(i)}$’s are non-negative valued &lt;strong&gt;weights&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A fairly standard choice for the weight is $w^{(i)}=\exp{(-\frac{(x^{(i)}-x)^2}{2\tau^2})}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\tau$: The &lt;strong&gt;bandwidth&lt;/strong&gt; parameter&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;h2&gt;Part II. Classification and Logistic Regression&lt;/h2&gt;&lt;/center&gt;

&lt;h2 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h2&gt;

&lt;div style=&quot;background-color: #E9F8D6;&quot;&gt;&lt;b&gt;&lt;h4&gt;Logistic Function (Sigmoid Function)&lt;/h4&gt;&lt;/b&gt;&lt;/div&gt;

\[g(z) = \frac{1}{1+e^{-z}}\]

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Squeeze the input into range  [0, 1)&lt;/p&gt;

&lt;h2 id=&quot;digression-the-perceptron-learning-algorithm&quot;&gt;Digression: The perceptron learning algorithm&lt;/h2&gt;

\[g(z)\left\{\begin{array}{l} 1 &amp;amp; if\ z\ge 0\\ 0 &amp;amp; if\ z &amp;lt; 0\end{array}\right.\\
h_\theta(x)=g(\theta^T x)\in\{0,1\}\\
\theta_j\gets \theta_j + \alpha(y^{(i)}-h_\theta(x)^{(i)})x_j^{(i)}\]

&lt;ul&gt;
  &lt;li&gt;$\alpha$: learning rate&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Usage: 0-1 Classification Problem&lt;/p&gt;

&lt;h2 id=&quot;another-algorithm-for-maximizing-mathscrltheta&quot;&gt;Another Algorithm for Maximizing $\mathscr{l}(\theta)$&lt;/h2&gt;

&lt;p&gt;Using Newton’s method to find the maximum of $\mathscr{l}(\theta)$.&lt;/p&gt;

&lt;center&gt;&lt;h2&gt;Part III. Generalized Linear Models&lt;/h2&gt;&lt;/center&gt;

&lt;h2 id=&quot;the-exponential-family&quot;&gt;The Exponential Family&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Exponential_probability_density.svg/360px-Exponential_probability_density.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A class of distributions is in the exponential family if it can be written in the form: (probability distribution function)
\(p(y;\eta)=b(y)\frac{\exp{(\eta^TT(y))}}{\exp({\alpha(\eta)})}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$y$: data&lt;/li&gt;
  &lt;li&gt;$b(y)$: base measure&lt;/li&gt;
  &lt;li&gt;$\eta$: natural parameter (canonical parameter)&lt;/li&gt;
  &lt;li&gt;$T(y)$: sufficient statistic (in this example, T(y) == y)&lt;/li&gt;
  &lt;li&gt;$\alpha(\eta)$: log partition function&lt;/li&gt;
  &lt;li&gt;$e^{-\alpha(\eta)}$: normalization constant&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-bernoulli-distributions&quot;&gt;The Bernoulli Distributions&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bernoulli Distributions: a distribution over $y\in{0,1}$&lt;/p&gt;
&lt;/blockquote&gt;

\[\left\{
\begin{array}{l}
p(y=1;\phi) = \phi\\
p(y=0;\phi) = 1-\phi
\end{array}
\right.\\
p(y;\phi) = \exp((\log(\frac{\phi}{1-\phi}))y+\log(1-\phi))\]

&lt;p&gt;where
\(\eta = \log{(\frac{\phi}{1-\phi})} \\
T(y)=y\\
\alpha(\eta)=-\log(1-\phi)=\log(1+e^\eta)\\
b(y)=1\)&lt;/p&gt;

&lt;h3 id=&quot;the-gaussian-distributions&quot;&gt;The Gaussian Distributions&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/720px-Normal_Distribution_PDF.svg.png&quot; alt=&quot;&quot; /&gt;
\(p(y;u)=\frac{1}{\sqrt{2\pi}}\exp{(-\frac{1}{2}y^2)}\cdot\exp(\mu y-\frac{1}{2}\mu^2)\)
where
\(\eta = \mu\\
T(y) = y\\
\alpha(\eta) = \mu^2/2 = \eta^2/2\\
b(y) = (1/\sqrt{2\pi})\exp{(-y^2/2)}\)&lt;/p&gt;

&lt;h2 id=&quot;constructing-glms-generalized-linear-model&quot;&gt;Constructing GLMs (Generalized Linear Model)&lt;/h2&gt;

&lt;h3 id=&quot;assumptions&quot;&gt;Assumptions&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$y&lt;/td&gt;
          &lt;td&gt;x;\theta\sim$ ExponentialFamily($\eta$). I.e., given $x$ and $\theta$, the distribution of $y$ follows some exponential family distribution, with parameter $\eta$.&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Given $x$, our goal is to predict the expected value of $T(y)$.&lt;/li&gt;
  &lt;li&gt;The natural parameter $\eta$ and the inputs $x$ are related linearly: $\eta=\theta^T x$.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The target variable $y$ (also called &lt;strong&gt;response variable&lt;/strong&gt; in GLM terminology) is continuous&lt;/li&gt;
  &lt;li&gt;The conditional distribution of $y$ given $x$ as a Gaussian $N(\mu,\sigma^2)$&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$h_\theta(x)=E[y&lt;/td&gt;
      &lt;td&gt;x;\theta]=\mu=\eta=\theta^Tx$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;logistic-regression-1&quot;&gt;Logistic Regression&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Binary classification, $y\in{0,1}$&lt;/li&gt;
  &lt;li&gt;Bernoulli distrubution&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$h_\theta(x)=E[y&lt;/td&gt;
      &lt;td&gt;x;\theta]=\phi=1/(1+e^{-\eta})=1/(1+e^{-\theta^Tx})$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Canonical Response Function&lt;/strong&gt;: the function $g$ giving the distribution’s mean as a function of the natural parameter&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Canonical Link Function&lt;/strong&gt;: the inverse of $g$, namely $g^{-1}$&lt;/p&gt;

&lt;h3 id=&quot;softmax-regression&quot;&gt;Softmax Regression&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;$y\in{1,2,…,k}$&lt;/li&gt;
&lt;/ul&gt;

\[p(y;\phi)=b(y)\exp{(\eta^T(y)-\alpha(\eta))}\]

&lt;p&gt;where
\(T(1)=
\left[
	\begin{array}{c}
	1\\0\\0\\...\\0
	\end{array}
\right]\quad
T(2)=
\left[
	\begin{array}{c}
	0\\1\\0\\...\\0
	\end{array}
\right]\quad
...\quad
T(k-1)=
\left[
	\begin{array}{c}
	0\\0\\0\\...\\1
	\end{array}
\right]\quad
T(k)=
\left[
	\begin{array}{c}
	0\\0\\0\\...\\0
	\end{array}
\right]
\\
\eta=
\left[
	\begin{array}{c}
	\log{(\phi_1/\phi_k)}\\
	\log{(\phi_2/\phi_k)}\\
	...\\
	\log{(\phi_{k-1}/\phi_k)}
	\end{array}
\right]\\
\alpha(\eta) = -\log{(\phi_k)}\\
b(y)=1\)
The log-likelihood
\(\mathscr{l}(\theta) = \sum_{i=1}^{n}\log\prod_{l=1}^k(\frac{e^{\theta_l^Tx^{(i)}}}{\sum_{j=1}^{k}e^{\theta_j^Tx^{(i)}}})^{1\{y^{(i)}=l\}}\)&lt;/p&gt;

&lt;center&gt;&lt;h2&gt;Part IV. Generative Learning Algorithms&lt;/h2&gt;&lt;/center&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Discriminative Algorithm&lt;/strong&gt;: Learn mapping directly from the space of inputs $\chi$ to the labels ${0, 1}$. (learn $p(y&lt;/td&gt;
      &lt;td&gt;x)$)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Generative Algorithm&lt;/strong&gt;: Distinguish different classes by training different model for different classes. (learn $p(x&lt;/td&gt;
      &lt;td&gt;y)$ and $p(y)$)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;The $p(y)$ can be called as &lt;strong&gt;class priors&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

\[p(y|x)=\frac{p(x|y)p(y)}{p(x)}\]

&lt;h2 id=&quot;gaussian-discriminant-analysis-gda&quot;&gt;Gaussian Discriminant Analysis (GDA)&lt;/h2&gt;

&lt;p&gt;GDA – Gaussian Discriminant Analysis&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Suppose $x\in\R^n$&lt;/p&gt;

  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;Assume that $p(x&lt;/td&gt;
        &lt;td&gt;y)$ is distributed according to a multivariate normal distribution.&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;the-multivariate-normal-distribution&quot;&gt;The multivariate Normal Distribution&lt;/h3&gt;

&lt;p&gt;The multivariate normal distribution in $d$-dimensions, also called the multivariate Gaussian distribution, is parameterized by a &lt;strong&gt;mean  vector&lt;/strong&gt; $\mu\in\R^d$ and a &lt;strong&gt;covariance matrix&lt;/strong&gt; $\sum\in\R^{d\times d}$, where $\sum\ge 0$ is symmetric and positive semi-definite.
\(p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}\exp{(-\frac{1}{2}(x-\mu )^T\Sigma^{-1}(x-\mu))}\)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;$&lt;/td&gt;
        &lt;td&gt;\Sigma&lt;/td&gt;
        &lt;td&gt;$ denotes the determinant of matrix $\Sigma$.&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;A Gaussian with zero mean and identity covariance is also called the &lt;strong&gt;standard normal distribution&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;the-gaussian-discriminant-analysis-model&quot;&gt;The Gaussian Discriminant Analysis Model&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A classification problem in which the input features $x$ are continuous-valued random variables, we can then use the Gaussian Discriminant Analysis (GDA) model, which models $p(x&lt;/td&gt;
      &lt;td&gt;y)$ using a multivariate normal distribution.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The model is:
\(y\sim Bernoulli(\phi)\\
x|y=0\sim N(\mu_0,\Sigma)\\
x|y=1\sim N(\mu_1, \Sigma)\)
the distribution:
\(p(y)=\phi^y(1-\phi)^{1-y}\\
p(x|y=0)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}\exp{(-\frac{1}{2}(x-\mu_0 )^T\Sigma^{-1}(x-\mu_0))}\\
p(x|y=1)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}\exp{(-\frac{1}{2}(x-\mu_1 )^T\Sigma^{-1}(x-\mu_1))}\)
The parameters of our model are $\phi$, $\Sigma$, $\mu_0$, and $\mu_1$.&lt;/p&gt;

&lt;p&gt;The likelihood of the data is given by:
\(l(\phi, \mu_0, \mu_1, \Sigma)=\log{\prod^n_{i=1}p(x^{(i)}|y^{(i)};\mu_0,\mu_1,\Sigma)p(y^{(i)};\phi)}\)
By maximizing $l$ with respect to the parameters, we find the maximum likelihood estimate of the parameters to be:
\(\phi=\frac{1}{n}\sum_{i=1}^{n}1\{y^{(i)}=1\}\\
\mu_0=\frac{\sum_{i=1}^n 1\{y^{(i)}=0\}x^{(i)}}{\sum_{i=1}^n 1\{y^{(i)}=0\}}\\
\mu_1=\frac{\sum_{i=1}^n 1\{y^{(i)}=1\}x^{(i)}}{\sum_{i=1}^n 1\{y^{(i)}=1\}}\\
\Sigma=\frac{1}{n}\sum_{i=1}^n(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T\)&lt;/p&gt;

&lt;h3 id=&quot;discussion-gda-and-logistic-regression&quot;&gt;Discussion: GDA and logistic regression&lt;/h3&gt;

&lt;p&gt;GDA makes &lt;em&gt;stronger&lt;/em&gt; modeling assumptions about the data than does logistic regression.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;Specifically, when $p(x&lt;/td&gt;
        &lt;td&gt;y)$ is indeed gaussian (with shared $\Sigma$), then GDA is &lt;strong&gt;asymptotically efficient&lt;/strong&gt;.&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;Logistic regression is more &lt;em&gt;robust&lt;/em&gt; and less sensitive to incorrect modeling assumptions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Summarization&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GDA makes stronger modeling assumptions, and is more data efficient (i.e. requires less training data to learn “well”) when the modeling assumptions are correct or at least approximately correct.&lt;/li&gt;
  &lt;li&gt;Logistic regression makes weaker assumptions, and is significantly more robust to deviations from modeling assumptions.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;naive-bayes&quot;&gt;Naive Bayes&lt;/h3&gt;

&lt;p&gt;The problem in which $x_j$’s are discrete-valued.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Naive Bayes (NB) assumption&lt;/strong&gt;: assume that the $x_i$’s are conditionally independent given $y$. The resulting algorithm is called &lt;strong&gt;Naive Bayes classifier&lt;/strong&gt;.
\(p(x_1,...,x_d|y)=\prod_{j=1}^d p(x_j|y)\)
Given a training set ${(x^{(i)},y^{(i)});i=1,…,n}$, the joint likelihood of the data is:
\(L(\phi_y,\phi_{j|y=0},\phi_{j|y=1})=\prod_{i=1}^{n}p(x^{(i)},y^{(i)})\)
The maximum likelihood estimates:
\(\phi_{j|y=0}=\frac{\sum_{i=1}^n 1\{x_j^{(i)}=1\wedge y^{(i)}=0\}}{\sum_{i=1}^n 1\{y^{(i)}=0\}}\\
\phi_{j|y=1}=\frac{\sum_{i=1}^n 1\{x_j^{(i)}=1\wedge y^{(i)}=1\}}{\sum_{i=1}^n 1\{y^{(i)}=1\}}\\
\phi_y=\frac{\sum_{i=1}^n 1\{y^{(i)}=1\}}{n}\)&lt;/p&gt;

&lt;h3 id=&quot;laplace-smoothing&quot;&gt;Laplace Smoothing&lt;/h3&gt;

&lt;p&gt;It is statistically a bad idea to estimate the probability of some event to zero just because you haven’t seen it before in your finite training set. &lt;strong&gt;Laplace smoothing&lt;/strong&gt; (also called additive smoothing) is a technique used to smooth categorical data.&lt;/p&gt;

&lt;p&gt;Defining the problem:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;mission: estimating the mean of multinomial random variable $z$ taking values in ${1,…,k}$&lt;/li&gt;
  &lt;li&gt;parameterize the multinomial with $\phi_j=p(z=j)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;No laplace smoothing:
\(\phi_j = \frac{\sum_{i=1}^n 1\{z^{(i)}=j\}}{n}\)
With laplace smoothing:
\(\phi_j = \frac{1+\sum_{i=1}^n 1\{z^{(i)}=j\}}{k+n}\)&lt;/p&gt;

&lt;h3 id=&quot;event-models-for-text-classification&quot;&gt;Event Models for Text Classification&lt;/h3&gt;

&lt;p&gt;A different model, called the &lt;strong&gt;Multinomial event model&lt;/strong&gt;.&lt;/p&gt;

&lt;center&gt;&lt;h2&gt;Part V. Kernel Moethods&lt;/h2&gt;&lt;/center&gt;

&lt;h2 id=&quot;feature-maps&quot;&gt;Feature Maps&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The input &lt;strong&gt;attributes&lt;/strong&gt; of a problem: the “original” input value, e.g. $x$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;featured&lt;/strong&gt; variables, e.g. $x^0$, $x^1$, …&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;featured&lt;/strong&gt; maps $\phi(x)$
\(\phi(x) = 
\left[
\begin{array}{l}
1 \\ x \\ ... \\ x^n
\end{array}
\right]\in \R^n\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lms-least-mean-squares-with-features&quot;&gt;LMS (least mean squares) with features&lt;/h2&gt;

&lt;p&gt;Batch gradient descent update rule:
\(\theta \gets \theta + \alpha\sum_{i=1}^n (y^{(i)}-\theta^T\phi(x^{(i)}))\phi(x^{(i)})\)
Stochastic gradient descent update rule:
\(\theta \gets \theta + \alpha (y^{(i)}-\theta^T\phi(x^{(i)}))\phi(x^{(i)})\)&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\phi: \R^d\rightarrow \R^p$: a feature map that maps attributes $x$ (in $\R^d$) to the features $\phi(x)$ in $\R^p$.&lt;/li&gt;
  &lt;li&gt;$\theta$: a vector in $\R^p$&lt;/li&gt;
  &lt;li&gt;$\alpha$: learning rate&lt;/li&gt;
  &lt;li&gt;goal: fit to the function $\theta^T\phi(x)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lms-with-the-kernel-trick&quot;&gt;LMS with the kernel trick&lt;/h2&gt;

&lt;p&gt;The gradient descent update, whether it is batch or stochastic becomes computationally expensive when the features $\phi(x)$ is high-dimensional.&lt;/p&gt;</content><author><name>ericaaaaaaaa</name></author><category term="ArtificialIntelligence" /><category term="note" /><category term="machine-learning" /><category term="artificial-intelligence" /><category term="book-report" /><summary type="html">Machine Learning</summary></entry><entry><title type="html">Algorithm</title><link href="http://localhost:4000/algorithms/2022/01/11/Algorithm.html" rel="alternate" type="text/html" title="Algorithm" /><published>2022-01-11T00:00:00+08:00</published><updated>2022-01-11T00:00:00+08:00</updated><id>http://localhost:4000/algorithms/2022/01/11/Algorithm</id><content type="html" xml:base="http://localhost:4000/algorithms/2022/01/11/Algorithm.html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;h3 id=&quot;problem-instance&quot;&gt;Problem Instance&lt;/h3&gt;

&lt;p&gt;A problem instance is any valid input to the problem.&lt;/p&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;

&lt;p&gt;An &lt;strong&gt;algorithm&lt;/strong&gt; is a well defined &lt;strong&gt;computational procedure&lt;/strong&gt; that transforms inputs into outputs, achieving the desired input-output relationship.&lt;/p&gt;

&lt;h3 id=&quot;correct-algorithm&quot;&gt;Correct Algorithm&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;correct algorithm&lt;/strong&gt; &lt;strong&gt;halts&lt;/strong&gt; with the correct output for every input instance. We can then say that the algorithm &lt;strong&gt;solves&lt;/strong&gt; the problem.&lt;/p&gt;

&lt;h2 id=&quot;analyzing-algorithms&quot;&gt;Analyzing Algorithms&lt;/h2&gt;

&lt;h4 id=&quot;predict-resource-utilization&quot;&gt;Predict Resource Utilization&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Memory&lt;/strong&gt; (space complexity)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Running time&lt;/strong&gt; (time complexity)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;depends on the speed of the computer&lt;/li&gt;
      &lt;li&gt;depends on the implementation details&lt;/li&gt;
      &lt;li&gt;depends on the input, especially on the size of the input&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Measure the running time as the number of &lt;strong&gt;primitive operations&lt;/strong&gt; used by the algorithm. (mathematically elegant and machine-independent)&lt;/p&gt;

    &lt;p&gt;Measure the running time as &lt;strong&gt;a function of the input size&lt;/strong&gt;. Let &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; denote the input size and let &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T(n)&lt;/code&gt; denote the running time for input of size n.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;three-kinds-of-analysis&quot;&gt;Three Kinds of Analysis&lt;/h3&gt;

&lt;h4 id=&quot;worst-case&quot;&gt;Worst Case&lt;/h4&gt;

&lt;p&gt;Commonly used&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Running time guarantee&lt;/li&gt;
  &lt;li&gt;Fair comparison&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;average-case&quot;&gt;Average Case&lt;/h4&gt;

&lt;p&gt;Used sometimes&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Need to assume distribution&lt;/li&gt;
  &lt;li&gt;Analysis is complicated&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;best-case&quot;&gt;Best Case&lt;/h4&gt;

&lt;p&gt;useless&lt;/p&gt;

&lt;h3 id=&quot;comparing-time-complexity&quot;&gt;Comparing Time Complexity&lt;/h3&gt;

&lt;h4 id=&quot;o-notation-upper-bounds&quot;&gt;$O$-notation (Upper bounds)&lt;/h4&gt;

&lt;p&gt;$f(n)=O(g(n))$: There exists constant $c&amp;gt;0$ and $n_0$ such that $f(n)\le c\cdot g(n)$ for $n\ge n_0$&lt;/p&gt;

&lt;h4 id=&quot;omega-notation-lower-bounds&quot;&gt;$\Omega$-notation (Lower bounds)&lt;/h4&gt;

&lt;p&gt;$f(n)=\Omega(g(n))$: There exists constant $c&amp;gt;0$ and $n_0$ such that $f(n)\ge c\cdot g(n)$ for $n\ge n_0$&lt;/p&gt;

&lt;h4 id=&quot;theta-notation-tight-bounds&quot;&gt;$\Theta$-notation (Tight bounds)&lt;/h4&gt;

&lt;p&gt;$f(n)=\Theta(g(n))$: $f(n)=O(g(n))$ and $f(n)=\Omega(g(n))$&lt;/p&gt;

&lt;h4 id=&quot;examples&quot;&gt;Examples&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;$\sum_{i=1}^{n}i = \frac{n(n+1)}{2}$&lt;/li&gt;
  &lt;li&gt;$\sum_{i=1}^{n}i^2 = \frac{n(n+1)(2n+1)}{6}$&lt;/li&gt;
  &lt;li&gt;$\sum_{i=1}^{n}\frac{1}{n}=O(\log n)$ (Harmonic Series，调和级数)&lt;/li&gt;
  &lt;li&gt;$\log(n!)=\log(n) + \log(n-1) + …+\log(1)=O(n\log n)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;递归分析主定理法&quot;&gt;递归分析：主定理法&lt;/h3&gt;

\[T(n) = 
\left\{
\begin{array}{l}
\Theta(f(n)) &amp;amp; if\ f(n)=\Omega(n^{\log_ba+\varepsilon})\\
\Theta(n^{\log_ba}\log n) &amp;amp; if\ f(n)=\Theta(n^{\log_b a}) \\
\Theta(n^{\log_ba}) &amp;amp; if\ f(n)=O(n^{\log_ba-\varepsilon})
\end{array}
\right.\]

&lt;h1 id=&quot;divide-and-conquer-algorithms&quot;&gt;Divide and Conquer Algorithms&lt;/h1&gt;

&lt;h2 id=&quot;step&quot;&gt;Step&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;分而治之&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;分解&lt;/strong&gt;原问题&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;解决&lt;/strong&gt;子问题&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;合并&lt;/strong&gt;问题解&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;merge-sort-归并排序&quot;&gt;Merge Sort 归并排序&lt;/h2&gt;

&lt;p&gt;归并排序：分解数组，递归求解，合并排序&lt;/p&gt;

&lt;h3 id=&quot;算法流程&quot;&gt;算法流程&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;将数组 A[1, n] 排序问题&lt;strong&gt;分解&lt;/strong&gt;为 A[1, [n/2]] 和 A[[n/2]+1, n] 排序问题&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;递归解决&lt;/strong&gt;子问题得到两个有序的子数组&lt;/li&gt;
  &lt;li&gt;将两个有序子数组&lt;strong&gt;合并&lt;/strong&gt;为一个有序数组&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;伪代码&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/merge_sort.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/merge.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;复杂度分析&quot;&gt;复杂度分析&lt;/h3&gt;

&lt;p&gt;$T(n) = O(n\log n)$&lt;/p&gt;

&lt;h2 id=&quot;maximum-contiguous-subarray-problem-最大子数组&quot;&gt;Maximum Contiguous Subarray Problem 最大子数组&lt;/h2&gt;

&lt;h3 id=&quot;伪代码-1&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/MCS.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/find_max.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;复杂度&quot;&gt;复杂度&lt;/h3&gt;

&lt;p&gt;$f(n)=O(n\log n)$&lt;/p&gt;

&lt;h2 id=&quot;counting-inversions-逆序计数&quot;&gt;Counting Inversions 逆序计数&lt;/h2&gt;

&lt;h3 id=&quot;问题介绍&quot;&gt;问题介绍&lt;/h3&gt;

&lt;p&gt;The total number of inversions in $\sum_{1\le i\le j\le n}$, namely
\(X_{i, j} = 
\left\{
\begin{array}{rcl}
1 &amp;amp; A[i]&amp;gt;A[j]\\
0 &amp;amp; A[i]\le A[j]
\end{array}
\right.\)&lt;/p&gt;

&lt;h3 id=&quot;伪代码-2&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/merge_count.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/sort_count.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;复杂度-1&quot;&gt;复杂度&lt;/h3&gt;

&lt;p&gt;$T(n)=n\log n$&lt;/p&gt;

&lt;h2 id=&quot;polynomial-multiplication-多项式乘法&quot;&gt;Polynomial Multiplication 多项式乘法&lt;/h2&gt;

&lt;h3 id=&quot;description&quot;&gt;Description&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/def.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt;: Assume that the coefficients a$_i$ and b$_i$ are stored in arrays A[0…n] and B[0…m]&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;伪代码-3&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/poly_mult1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/poly_mult2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;quicksort-and-partition-快速排序与划分&quot;&gt;QuickSort and Partition 快速排序与划分&lt;/h2&gt;

&lt;h3 id=&quot;算法思路&quot;&gt;算法思路&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;选取固定位置主元 x （如尾元素）&lt;/li&gt;
  &lt;li&gt;维护两个部分的右端点变量 i, j&lt;/li&gt;
  &lt;li&gt;考察数组 A[j]，只和主元比较
    &lt;ul&gt;
      &lt;li&gt;若 A[j] ≤ x，则交换 A[j] 和 A[i+1]，i, j 右移&lt;/li&gt;
      &lt;li&gt;若 A[j] &amp;gt; x，则 j 右移&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;把主元放在中间作分界线&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/t.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/p.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;伪代码-4&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/partition.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/quick_sort.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;复杂度-2&quot;&gt;复杂度&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;最好情况：$O(n\log n)$&lt;/li&gt;
  &lt;li&gt;最坏情况：$O(n^2)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;优化随机选择主元&quot;&gt;优化——随机选择主元&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/random_partition.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;期望时间复杂度&quot;&gt;期望时间复杂度&lt;/h4&gt;

&lt;p&gt;$O(n\log n)$&lt;/p&gt;

&lt;h2 id=&quot;randomized-selection-随机化选择&quot;&gt;Randomized Selection 随机化选择&lt;/h2&gt;

&lt;h3 id=&quot;次序选择问题&quot;&gt;次序选择问题&lt;/h3&gt;

&lt;h4 id=&quot;形式化定义&quot;&gt;形式化定义&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/k_min.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法思想&quot;&gt;算法思想&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;选取固定位置主元，小于主元的元素个数 q-p
    &lt;ul&gt;
      &lt;li&gt;情况 1：k = q - p + 1，A[q] 为数组第 k 小元素&lt;/li&gt;
      &lt;li&gt;情况 2：k &amp;lt; q - p + 1，在 A[p .. q - 1] 中寻找第 k 小元素&lt;/li&gt;
      &lt;li&gt;情况 3：k &amp;gt; q - p + 1，在 A[q + 1 .. r] 中寻找第 k - (q - p + 1) 小元素&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;伪代码-5&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/partition.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/selection.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;复杂度-3&quot;&gt;复杂度&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;最好情况：$T(n) = O(n)$&lt;/li&gt;
  &lt;li&gt;最差情况：$T(n) = O(n^2)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;优化算法随机选择主元&quot;&gt;优化算法——随机选择主元&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/rp.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/rs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;期望时间复杂度：$O(n)$&lt;/p&gt;

&lt;h2 id=&quot;supplement-topic-of-sorting-排序问题补充主题&quot;&gt;Supplement Topic of Sorting 排序问题补充主题&lt;/h2&gt;

&lt;h3 id=&quot;heapsort-堆排序&quot;&gt;Heapsort 堆排序&lt;/h3&gt;

&lt;h4 id=&quot;heap&quot;&gt;Heap&lt;/h4&gt;

&lt;h5 id=&quot;definition-1&quot;&gt;Definition&lt;/h5&gt;

&lt;p&gt;Heaps are “almost complete binary trees”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;All levels are full except possibly the lowest level&lt;/li&gt;
  &lt;li&gt;If the lowest level is not full, then nodes must packed to the left&lt;/li&gt;
  &lt;li&gt;The values of the node is at least the value of its parent. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A[Parent(i)] &amp;lt;= A[i]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;operation&quot;&gt;Operation&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Insert&lt;/strong&gt; in $O(\log n)$ time&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Extract-Min&lt;/strong&gt; in $O(\log n)$ time&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;properties&quot;&gt;Properties&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;A heap of height h has between $2^h$ to $2^{h+1}-1$ nodes. Thus, an n-element heap has height $\Theta(\log n)$&lt;/li&gt;
  &lt;li&gt;The structure is so regular, it can be represented in an array and no links are necessary&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;array-implementation-of-heap&quot;&gt;Array Implementation of Heap&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;The root is in array position 1&lt;/li&gt;
  &lt;li&gt;For any element in array position i
    &lt;ul&gt;
      &lt;li&gt;The left child is in position 2i&lt;/li&gt;
      &lt;li&gt;The right child is in position 2i+1&lt;/li&gt;
      &lt;li&gt;The parent is in position [i/2]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;heapsort&quot;&gt;Heapsort&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Build a binary heap of n elements
    &lt;ul&gt;
      &lt;li&gt;the minimum element is at the top of the heap&lt;/li&gt;
      &lt;li&gt;insert n elements one by one&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Perform n Extract-Min operations
    &lt;ul&gt;
      &lt;li&gt;the elements are extracted in sorted order&lt;/li&gt;
      &lt;li&gt;each Extract-Min operation takes $O(\log n)$ time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Total time complexity: $O(n\log n)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lower-bound-for-sorting-基于比较的排序下界&quot;&gt;Lower Bound for Sorting 基于比较的排序下界&lt;/h3&gt;

&lt;p&gt;Any comparison-based sorting algorithm requires $\Omega(n\log n)$ comparisons.&lt;/p&gt;

&lt;h4 id=&quot;counting-sort&quot;&gt;Counting-Sort&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/counting_sort.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sorting-in-linear-time-线性时间排序&quot;&gt;Sorting in Linear Time 线性时间排序&lt;/h3&gt;

&lt;h1 id=&quot;dynamic-programming-algorithms&quot;&gt;Dynamic Programming Algorithms&lt;/h1&gt;

&lt;h3 id=&quot;动态规划算法&quot;&gt;动态规划算法&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;问题结构分析&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;给出问题表示，明确原始问题&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;递推关系建立&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;分析最优结构，构造递推公式&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;自底向上计算&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;确定计算顺序，依次求解问题&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;最优方案追踪&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;记录决策过程，输出最优方案&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;0-1-knapsack-0-1-背包问题&quot;&gt;0-1 Knapsack 0-1 背包问题&lt;/h3&gt;

&lt;h4 id=&quot;输入&quot;&gt;输入&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;n 个商品组成集合 0，每个商品有两个属性 $v_i$ 和 $p_i$，分别表示体积和价格&lt;/li&gt;
  &lt;li&gt;背包容量为 $C$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;输出&quot;&gt;输出&lt;/h4&gt;

&lt;p&gt;求解一个商品子集 $S\subseteq 0$，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;优化目标&lt;/strong&gt;：令 $\max \sum_{i\in S}p_i$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;约束条件&lt;/strong&gt;：$\sum_{i\in S}v_i\le C$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;递归函数&quot;&gt;递归函数&lt;/h4&gt;

\[KnapsackSR(h, i, c)=\\ \max\{KnapsackSR(h, i-1, c-v_i)+p_i, KnapsackSR(h, i-1, c)\}\]

&lt;h4 id=&quot;算法复杂度&quot;&gt;算法复杂度&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/0-1knap.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;计算顺序&quot;&gt;计算顺序&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/seq.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/rec.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-6&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/knap.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/knapdp.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/knapdp1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;p&gt;$O(n\cdot C)$&lt;/p&gt;

&lt;h3 id=&quot;maximum-contiguous-subarray-ii-最大连续数组-ii&quot;&gt;Maximum Contiguous Subarray II 最大连续数组 II&lt;/h3&gt;

&lt;h4 id=&quot;问题定义&quot;&gt;问题定义&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/qq1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;问题结构分析&quot;&gt;问题结构分析&lt;/h4&gt;

&lt;p&gt;$D[i]$：以 $X[i]$ 开头的最大子数组和&lt;/p&gt;

&lt;p&gt;原始问题：$S_{max}=\max_{1\le i\le n}{D[i]}$&lt;/p&gt;

&lt;h4 id=&quot;递推关系建立&quot;&gt;递推关系建立&lt;/h4&gt;

\[D[i] = 
\left\{
\begin{array}{l}
X[i] + D[i+1] &amp;amp; if\ D[i+1] &amp;gt; 0\\
X[i] &amp;amp; if\ D[i+1] \le 0
\end{array}
\right.\]

&lt;p&gt;构造追踪数组 $Rec[1..n]$&lt;/p&gt;

&lt;h4 id=&quot;伪代码-7&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mcsdp.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mcsdp1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-1&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;p&gt;$T(n) = O(n)$&lt;/p&gt;

&lt;h3 id=&quot;longest-common-subsequences-最长公共子序列&quot;&gt;Longest Common Subsequences 最长公共子序列&lt;/h3&gt;

&lt;h4 id=&quot;问题描述&quot;&gt;问题描述&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/lcs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;问题表示&quot;&gt;问题表示&lt;/h4&gt;

&lt;p&gt;$C[i, j]$：$X[1..i]$ 和 $Y[1..j]$ 的最长公共子序列长度&lt;/p&gt;

&lt;h4 id=&quot;递推关系建立-1&quot;&gt;递推关系建立&lt;/h4&gt;

\[C[i,j]=
\left\{
\begin{array}{l}
\max\{C[i-1,j], C[i,j-1]\} &amp;amp; x_i\not= y_j\\
C[i-1,j-1]+1 &amp;amp; x_i=y_j
\end{array}
\right.\]

&lt;p&gt;&lt;img src=&quot;/assets/images/post/cls2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/rec1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-8&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/lcs1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/lcs2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/plcs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-2&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;p&gt;$O(n\cdot m)$&lt;/p&gt;

&lt;h3 id=&quot;longest-common-substrings-最长公共子串&quot;&gt;Longest Common Substrings 最长公共子串&lt;/h3&gt;

&lt;h4 id=&quot;问题描述-1&quot;&gt;问题描述&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/lss.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;问题表示-1&quot;&gt;问题表示&lt;/h4&gt;

&lt;p&gt;$C[i,j]$：在 $X[1..i]$ 和 $Y[1..j]$ 中，以 $x_i$ 和 $y_j$ 结尾的最长公共子串 $Z[1..l]$ 的长度&lt;/p&gt;

&lt;h4 id=&quot;递推关系建立-2&quot;&gt;递推关系建立&lt;/h4&gt;

\[C[i,j]=
\left\{
\begin{array}{l}
0 &amp;amp; x_i\not=y_j\\
C[i-1,j-1]+1&amp;amp;x_i=y_j
\end{array}
\right.\]

&lt;p&gt;&lt;img src=&quot;/assets/images/post/sll1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-9&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/sll2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/sll3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/sll4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-3&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;p&gt;$O(n\cdot m)$&lt;/p&gt;

&lt;h3 id=&quot;minimum-edit-distance-最小编辑距离&quot;&gt;Minimum Edit Distance 最小编辑距离&lt;/h3&gt;

&lt;h4 id=&quot;问题描述-2&quot;&gt;问题描述&lt;/h4&gt;

&lt;p&gt;编辑操作&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;删除&lt;/li&gt;
  &lt;li&gt;插入&lt;/li&gt;
  &lt;li&gt;替换&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/med1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;问题表示-2&quot;&gt;问题表示&lt;/h4&gt;

&lt;p&gt;$D[i,j]$：字符串 $s[1..i]$ 变成 $t[1..j]$ 的最小编辑距离
\(D[i,j]=\min
\left\{
\begin{array}{l}
D[i-1,j]+1 &amp;amp; 删除\\
D[i,j-1]+1 &amp;amp; 插入\\
D[i-1,j-1]+
\left\{
\begin{array}{l}
0 &amp;amp; if\ s[i] = t[j]\\
1 &amp;amp; if\ s[i]\not= t[j]
\end{array}
\right.
\end{array}
\right.\)&lt;/p&gt;

&lt;h4 id=&quot;递推关系建立-3&quot;&gt;递推关系建立&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/med2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-10&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/med3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/med4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/med5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-4&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;p&gt;$O(mn)$&lt;/p&gt;

&lt;h3 id=&quot;rod-cutting-钢条切割&quot;&gt;Rod-Cutting 钢条切割&lt;/h3&gt;

&lt;h4 id=&quot;问题描述-3&quot;&gt;问题描述&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/rc1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;问题表示-3&quot;&gt;问题表示&lt;/h4&gt;

&lt;p&gt;$C[j]$：切割长度为 $j$ 的钢条可获得的最大收益&lt;/p&gt;

&lt;p&gt;$rec[j]$：记录长度为 $j$ 钢条的最优切割方案&lt;/p&gt;

&lt;h4 id=&quot;递归结构建立&quot;&gt;递归结构建立&lt;/h4&gt;

\[C[j] = \max_{1\le i\le j-1}\{p[i] + C[j-i],p[j]\}\]

&lt;h4 id=&quot;伪代码-11&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/rc2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/rc3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法复杂度-1&quot;&gt;算法复杂度&lt;/h4&gt;

&lt;p&gt;$O(n^2)$&lt;/p&gt;

&lt;h3 id=&quot;chain-matrix-multiplication-矩阵链乘法&quot;&gt;Chain Matrix Multiplication 矩阵链乘法&lt;/h3&gt;

&lt;h4 id=&quot;问题定义-1&quot;&gt;问题定义&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mm1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;问题描述-4&quot;&gt;问题描述&lt;/h4&gt;

&lt;p&gt;$D[i,j]$：计算矩阵链 $U_{i..j}$ 所需标量乘法的&lt;strong&gt;最小次数&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;递归表达式建立&quot;&gt;递归表达式建立&lt;/h4&gt;

\[D[i,j]=\min_{1\le k&amp;lt;j}(D[i,k]+D[k+1,j+p_{i-1}p_kp_j])\]

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mm2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mm3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/m4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-12&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mm4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mm5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/mm6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-5&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;p&gt;$O(n^3)$&lt;/p&gt;

&lt;h1 id=&quot;greedy-algorithms&quot;&gt;Greedy Algorithms&lt;/h1&gt;

&lt;h2 id=&quot;算法描述&quot;&gt;算法描述&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;提出贪心策略&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;观察问题特征，构造贪心选择&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;证明策略正确&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;假设最优方案，通过替换证明&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;fractional-knapsack-部分背包问题&quot;&gt;Fractional Knapsack 部分背包问题&lt;/h2&gt;

&lt;h3 id=&quot;问题定义-2&quot;&gt;问题定义&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/fkp1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;问题描述-5&quot;&gt;问题描述&lt;/h3&gt;

&lt;h3 id=&quot;伪代码-13&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/fkp2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;算法复杂度-2&quot;&gt;算法复杂度&lt;/h3&gt;

&lt;p&gt;$O(n\log n)$&lt;/p&gt;

&lt;h2 id=&quot;huffman-coding-problem-赫夫曼编码&quot;&gt;Huffman Coding Problem 赫夫曼编码&lt;/h2&gt;

&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;编码树&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;顶点到左结点的边标记为 0，到右节点的边标记 1，通过编码方案构造编码树&lt;/li&gt;
      &lt;li&gt;每条根到叶子的路径对应的每个字符的二进制串&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;问题定义-3&quot;&gt;问题定义&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/hc1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;伪代码-14&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/hc2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;算法复杂度-3&quot;&gt;算法复杂度&lt;/h3&gt;

&lt;p&gt;$O(n\log n)$&lt;/p&gt;

&lt;h2 id=&quot;activity-selection-problem-活动选择问题&quot;&gt;Activity Selection Problem 活动选择问题&lt;/h2&gt;

&lt;h3 id=&quot;无权重&quot;&gt;无权重&lt;/h3&gt;

&lt;h4 id=&quot;问题定义-4&quot;&gt;问题定义&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/asp1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法思路-1&quot;&gt;算法思路&lt;/h4&gt;

&lt;p&gt;选择最早结束的活动，可以给后面的活动留更大的空间。&lt;/p&gt;

&lt;h4 id=&quot;伪代码-15&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/asp2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法复杂度-4&quot;&gt;算法复杂度&lt;/h4&gt;

&lt;p&gt;$O(n\log n)$&lt;/p&gt;

&lt;h3 id=&quot;有权重&quot;&gt;有权重&lt;/h3&gt;

&lt;h4 id=&quot;问题定义-5&quot;&gt;问题定义&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/asp3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;问题分析&quot;&gt;问题分析&lt;/h4&gt;

&lt;p&gt;$D[i]$：集合 ${a_1,a_2,a_3,…,a_i}$ 中不冲突活动的最大权限和&lt;/p&gt;

&lt;h4 id=&quot;递推关系建立-4&quot;&gt;递推关系建立&lt;/h4&gt;

\[D[i] = \max\{D[p[i]]+w_i,D[i-1] \}\\
Rec[i] = 
\left\{
\begin{array}{l}
1 &amp;amp; 选择活动 a_i\\
0 &amp;amp; 不选活动 a_i
\end{array}
\right.\]

&lt;p&gt;&lt;img src=&quot;/assets/images/post/asp4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-16&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/asp5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/asp6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/asp7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法复杂度-5&quot;&gt;算法复杂度&lt;/h4&gt;

&lt;p&gt;$O(n\log n)$&lt;/p&gt;

&lt;h1 id=&quot;graph-algorithms&quot;&gt;Graph Algorithms&lt;/h1&gt;

&lt;h2 id=&quot;basic-concepts-in-graphs&quot;&gt;Basic Concepts in Graphs&lt;/h2&gt;

&lt;h3 id=&quot;图的概念&quot;&gt;图的概念&lt;/h3&gt;

&lt;h4 id=&quot;图的定义&quot;&gt;图的定义&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;图&lt;/strong&gt;可以表示为一个二元组 $G=&amp;lt;V, E&amp;gt;$，其中&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$V$ 表示非空顶点集，其元素称为顶点 (Vertex)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$E$ 表示边集，其元素称为边 (Edge)&lt;/p&gt;

    &lt;p&gt;$e=(u,v)$ 表示一条边，其中 $u\in V,v\in V,e\in E$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;相邻和关联&quot;&gt;相邻和关联&lt;/h4&gt;

&lt;h5 id=&quot;相邻-adjacent&quot;&gt;相邻 (Adjacent)&lt;/h5&gt;

&lt;p&gt;边 $(u,v)$ 连接的顶点 $u$ 和 $v$ &lt;strong&gt;相邻&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;关联-incident&quot;&gt;关联 (Incident)&lt;/h5&gt;

&lt;p&gt;边 $(u,v)$ 和其连接的顶点 $u$ (或 $v$) 相互关联&lt;/p&gt;

&lt;h4 id=&quot;度&quot;&gt;度&lt;/h4&gt;

&lt;h5 id=&quot;顶点的度-degree-of-a-vertex&quot;&gt;顶点的度 (Degree of a Vertex)&lt;/h5&gt;

&lt;p&gt;顶点 $v$ 的度 $deg(v)$ 是 $v$ 关联的边数&lt;/p&gt;

&lt;h5 id=&quot;图的度-degree-of-a-graph&quot;&gt;图的度 (Degree of a Graph)&lt;/h5&gt;

&lt;p&gt;图 $G=&amp;lt;V,E&amp;gt;$ 的度，是图各顶点的度之和，$deg(G)=\sum_{v\in V}deg(v)$&lt;/p&gt;

&lt;h4 id=&quot;握手定理-handshaking-lemma&quot;&gt;握手定理 (Handshaking Lemma)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;无向图的度是边数的两倍&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;路径-path&quot;&gt;路径 (Path)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;图中一个顶点序列 $&amp;lt;v_0,v_1,…,v_k&amp;gt;$ 称为 $v_0$ 到 $v_k$ 的&lt;strong&gt;路径&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;路径包含顶点 $v_0,v_1,…,v_k$ 和边 $(v_0,v_1),(v_1,v_2),…,(v_{k-1}, v_k)$&lt;/li&gt;
  &lt;li&gt;存在路径 $&amp;lt;v_0,v_1,…,v_k&amp;gt;$，则 $v_0$ &lt;strong&gt;可达&lt;/strong&gt; $v_k$&lt;/li&gt;
  &lt;li&gt;如果 $v_0,v_1,…,v_k$ 互不相同，则该路径的&lt;strong&gt;简单&lt;/strong&gt;的&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;环路-cycle&quot;&gt;环路 (Cycle)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;如果路径 $&amp;lt;v_0,v_1,…,v_k&amp;gt;$ 中 $v_0=v_k$ 且至少包含一条边，则该路径构成&lt;strong&gt;环路&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;如果 $v_0,v_1,…,v_k$ 互不相同，则该环路的&lt;strong&gt;简单&lt;/strong&gt;的&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;无环图&lt;/strong&gt; (Acyclic Graph)：图中不存在环路&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;连通-connectivity&quot;&gt;连通 (Connectivity)&lt;/h4&gt;

&lt;h5 id=&quot;连通&quot;&gt;连通&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;如果图的&lt;strong&gt;任意对顶点互相可达&lt;/strong&gt;，则称该图是&lt;strong&gt;连通&lt;/strong&gt;的，反之称为&lt;strong&gt;非连通&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;连通分量-connected-components&quot;&gt;连通分量 (Connected Components)&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;根据是否连通将顶点进行分组，相互可达的顶点集称为&lt;strong&gt;连通分量&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;子图-subgraph&quot;&gt;子图 (Subgraph)&lt;/h4&gt;

&lt;h5 id=&quot;子图-subgraph-1&quot;&gt;子图 (Subgraph)&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;如果 $V’\subseteq V,E’\subseteq E$，则称图 $G’=&amp;lt;V’,E’&amp;gt;$ 是图 $G$ 的一个&lt;strong&gt;子图&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;生成子图-spanning-subgraph&quot;&gt;生成子图 (Spanning Subgraph)&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;如果 $V’=V, E\subseteq E$，则称图 $G’=&amp;lt;V’, E’&amp;gt;$ 是图 $G$ 的一个&lt;strong&gt;生成子图&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;树-tree&quot;&gt;树 Tree&lt;/h4&gt;

&lt;h5 id=&quot;树-tree-1&quot;&gt;树 (Tree)&lt;/h5&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;连通、无环图 $T=&amp;lt;V_T,E_T&amp;gt;$，树有 $&lt;/td&gt;
      &lt;td&gt;V_T&lt;/td&gt;
      &lt;td&gt;-1$ 条边&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;森林-forest&quot;&gt;森林 (Forest)&lt;/h5&gt;

&lt;p&gt;一至多棵树组成的无环图&lt;/p&gt;

&lt;h3 id=&quot;图的表示&quot;&gt;图的表示&lt;/h3&gt;

&lt;h4 id=&quot;邻接链表&quot;&gt;邻接链表&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;图 $G=&amp;lt;V,E&amp;gt;$，其邻接链表由 $&lt;/td&gt;
          &lt;td&gt;V&lt;/td&gt;
          &lt;td&gt;$ 条链表的数组构成&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;每个顶点有一条链表，包含所有与其相邻的顶点&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;空间大小 $O(&lt;/td&gt;
          &lt;td&gt;V&lt;/td&gt;
          &lt;td&gt;+&lt;/td&gt;
          &lt;td&gt;E&lt;/td&gt;
          &lt;td&gt;)$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;邻接矩阵&quot;&gt;邻接矩阵&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;图 $G=&amp;lt;V,E&amp;gt;$ 的邻接矩阵由 $|V|\times |V|$ 的二维数组 $A$ 构成，满足
\(A_{ij}=
\left\{
\begin{array}{l}
1 &amp;amp; (i,j)\in E\\
0 &amp;amp; (i,j)\not\in E
\end{array}
\right.\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;空间大小 $O(&lt;/td&gt;
          &lt;td&gt;V&lt;/td&gt;
          &lt;td&gt;^2)$，$O(1)$ 判断是否有边&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;breadth-first-search-bfs广度优先搜索&quot;&gt;Breadth-First Search (BFS，广度优先搜索)&lt;/h2&gt;

&lt;h3 id=&quot;辅助数组&quot;&gt;辅助数组&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/bfs1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;伪代码-17&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/bfs2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/bfs3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;时间复杂度-6&quot;&gt;时间复杂度&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;+&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;depth-first-search-dfs深度优先搜索&quot;&gt;Depth-First Search (DFS，深度优先搜索)&lt;/h2&gt;

&lt;h3 id=&quot;问题分析-1&quot;&gt;问题分析&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/dfs1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;伪代码-18&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/dfs2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/dfs3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;时间复杂度分析&quot;&gt;时间复杂度分析&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;+&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;深度优先树&quot;&gt;深度优先树&lt;/h3&gt;

&lt;h4 id=&quot;深度优先树-1&quot;&gt;深度优先树&lt;/h4&gt;

&lt;p&gt;顶点以前驱为祖先形成的树&lt;/p&gt;

&lt;h4 id=&quot;树边&quot;&gt;树边&lt;/h4&gt;

&lt;p&gt;深度优先搜索树中的边&lt;/p&gt;

&lt;h4 id=&quot;后向边&quot;&gt;后向边&lt;/h4&gt;

&lt;p&gt;不是树边，但两顶点在深度优先树中是祖先后代关系&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于无向图，非树边一定是后向边。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;括号化定理&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;点 $v$ 发现时刻和结束时刻构成区间 $[d[v], f[v]]$&lt;/li&gt;
  &lt;li&gt;任意两点 $v,w$ 必须满足以下情况之一：
    &lt;ul&gt;
      &lt;li&gt;$[d[v],f[v]]$ 包含 $[d[w], f[w]]$，$w$ 是 $v$ 的后代&lt;/li&gt;
      &lt;li&gt;$[d[w],f[w]]$ 包含 $[d[v],f[v]]$，$v$ 是 $w$ 的后代&lt;/li&gt;
      &lt;li&gt;$[d[v],f[v]]$ 和 $[d[w],f[w]]$ 完全不重合 $v$ 和 $w$ 均不是对方的后代&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;白色路径定理&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在深度优先树中，顶点 $v$ 是 $w$ 的祖先 $\Leftrightarrow$ 在 $v$ 被发现前，从 $v$ 到 $w$ 存在全为白色顶点构成的路径&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;前向边&quot;&gt;前向边&lt;/h4&gt;

&lt;p&gt;不再深度优先树种，从祖先指向后代的边&lt;/p&gt;

&lt;h4 id=&quot;横向边&quot;&gt;横向边&lt;/h4&gt;

&lt;p&gt;顶点不具有祖先后代关系的边&lt;/p&gt;

&lt;h2 id=&quot;cycle-detection-环路检测&quot;&gt;Cycle Detection (环路检测)&lt;/h2&gt;

&lt;h3 id=&quot;问题定义-6&quot;&gt;问题定义&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/cd1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;伪代码-19&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/cd2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/cd3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;时间复杂度-7&quot;&gt;时间复杂度&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;+&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;topological-sort-拓扑排序&quot;&gt;Topological Sort (拓扑排序)&lt;/h2&gt;

&lt;h3 id=&quot;问题定义-7&quot;&gt;问题定义&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/tp1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;广度优先策略&quot;&gt;广度优先策略&lt;/h3&gt;

&lt;h4 id=&quot;算法思想-1&quot;&gt;算法思想&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;完成入度为 0 点对应的事件&lt;/li&gt;
  &lt;li&gt;删除完成事件，产生新的入度为 0 的点，继续完成&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;伪代码-20&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/tp2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;事件复杂度&quot;&gt;事件复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;+&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;深度优先策略&quot;&gt;深度优先策略&lt;/h3&gt;

&lt;h4 id=&quot;算法思想-2&quot;&gt;算法思想&lt;/h4&gt;

&lt;p&gt;DFS 搜索的完成时刻逆序即为拓扑排序顺序&lt;/p&gt;

&lt;h4 id=&quot;算法伪代码&quot;&gt;算法伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/tp3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/tp4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法时间复杂度&quot;&gt;算法时间复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;+&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;strongly-connected-components-强连通分量&quot;&gt;Strongly Connected Components (强连通分量)&lt;/h2&gt;

&lt;h3 id=&quot;问题定义-8&quot;&gt;问题定义&lt;/h3&gt;

&lt;h4 id=&quot;强连通分量&quot;&gt;强连通分量&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;一个强连通分量是顶点的子集&lt;/li&gt;
  &lt;li&gt;强连通分量种&lt;strong&gt;任意两点相互可达&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;满足&lt;strong&gt;最大性&lt;/strong&gt;：加入新顶点，不保证相互可达&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/scc1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;gscc&quot;&gt;$G^{SCC}$&lt;/h4&gt;

&lt;p&gt;把强连通分量看作一个点得到的有向图&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;$G^{SCC}$一定是有向无环图&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;scc_sink&quot;&gt;$SCC_{Sink}$&lt;/h4&gt;

&lt;p&gt;$G^{SCC}$ 中出度为 0 的点&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$G^{SCC}$ 中存在至少一个 $SCC_{Sink}$&lt;/li&gt;
  &lt;li&gt;删除 $SCC_{Sink}$，会产生新的 $SCC_{Sink}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;算法步骤&quot;&gt;算法步骤&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;把边反向，得到反向图 $G^R$&lt;/li&gt;
  &lt;li&gt;在 $G^R$ 上执行 DFS，得到顶点完成时刻顺序 $L$&lt;/li&gt;
  &lt;li&gt;在 $G$ 上按 $L$ 逆序执行 DFS，得到强连通分量&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;伪代码-21&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/scc2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/scc3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;时间复杂度-8&quot;&gt;时间复杂度&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;+&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;minimum-spanning-trees-最小生成树&quot;&gt;Minimum Spanning Trees (最小生成树)&lt;/h2&gt;

&lt;h3 id=&quot;问题背景&quot;&gt;问题背景&lt;/h3&gt;

&lt;h4 id=&quot;子图-subgraph-2&quot;&gt;子图 Subgraph&lt;/h4&gt;

&lt;p&gt;如果 $V’\subseteq V$，$E’\subseteq E$，则称图 $G’=&amp;lt;V’,E’&amp;gt;$ 是图 $G$ 的一个子图&lt;/p&gt;

&lt;h4 id=&quot;生成子图-spanning-subgraph-1&quot;&gt;生成子图 Spanning Subgraph&lt;/h4&gt;

&lt;p&gt;如果 &lt;strong&gt;$\bold{V’= V}$&lt;/strong&gt;，$E’\subseteq E$，则称图 $G’=&amp;lt;V’,E’&amp;gt;$ 是图 $G$ 的一个生成子图&lt;/p&gt;

&lt;h4 id=&quot;生成树-spanning-tree&quot;&gt;生成树 Spanning Tree&lt;/h4&gt;

&lt;p&gt;连通且无环的生成子图&lt;/p&gt;

&lt;h4 id=&quot;最小生成树&quot;&gt;最小生成树&lt;/h4&gt;

&lt;p&gt;权重最小的生成树&lt;/p&gt;

&lt;h4 id=&quot;安全边-safe-edge&quot;&gt;安全边 Safe Edge&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;$A$ 是某棵最小生成树 $T$ 边的子集，即 $A\subseteq T$&lt;/li&gt;
  &lt;li&gt;$A\cup{(u,v)}$ 仍是 $T$ 边的一个子集，则称 $(u,v)$ 是 $A$ 的&lt;strong&gt;安全边&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;若每次向边集中新增安全边，可保证边集 $A$ 是最小生成树的子集&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;割-cut&quot;&gt;割 Cut&lt;/h4&gt;

&lt;p&gt;图 $G=&amp;lt;V, E&amp;gt;$ 是一个连通无向图，割 $(S, V-S)$ 将图 $G$ 的顶点集 $V$ 划分为两个部分&lt;/p&gt;

&lt;h4 id=&quot;横跨-cross&quot;&gt;横跨 Cross&lt;/h4&gt;

&lt;p&gt;给定割 $(S,V-S)$ 和边 $(u,v)$，$u\in S,v\in V-S$，称边 $(u,v)$ 横跨割 $(S,V-S)$&lt;/p&gt;

&lt;h4 id=&quot;轻边-light-edge&quot;&gt;轻边 Light Edge&lt;/h4&gt;

&lt;p&gt;横跨割的所有边中，权重最小的边称为横跨这个割的轻边&lt;/p&gt;

&lt;h4 id=&quot;不妨害-respect&quot;&gt;不妨害 Respect&lt;/h4&gt;

&lt;p&gt;如果一个边集 $A$ 中没有边横跨某割，则称该割不妨害边集 $A$&lt;/p&gt;

&lt;h4 id=&quot;安全边辨识定理&quot;&gt;安全边辨识定理&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/safe.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;问题定义-9&quot;&gt;问题定义&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/st1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/com.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;prim&quot;&gt;Prim&lt;/h3&gt;

&lt;h4 id=&quot;算法思想-3&quot;&gt;算法思想&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/prim.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;辅助数组-1&quot;&gt;辅助数组&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/prim2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-22&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/prim3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/prim4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-9&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;^2)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;优化-prim采用优先队列&quot;&gt;优化 Prim–采用优先队列&lt;/h3&gt;

&lt;h4 id=&quot;伪代码-23&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/prim5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/prim6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-10&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;\cdot \log{&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;})$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;kruskal&quot;&gt;Kruskal&lt;/h3&gt;

&lt;h4 id=&quot;算法思想-4&quot;&gt;算法思想&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/k1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-24&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/k3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;高效判定和维护所选边的顶点是否在一棵子树&lt;/strong&gt;——&lt;strong&gt;不相交集合&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/s1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/s2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/s3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-11&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;\log{&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;})$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;single-source-shortest-path-单源最短路径&quot;&gt;Single Source Shortest Path (单源最短路径)&lt;/h2&gt;

&lt;h3 id=&quot;问题定义-10&quot;&gt;问题定义&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/ss1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;dijkstra&quot;&gt;Dijkstra&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;算法使用范围：边权为正的图&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;辅助数组-2&quot;&gt;辅助数组&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/ss2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法思想-5&quot;&gt;算法思想&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/ss3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/ss4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/ss5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-25&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/d1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/d2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-12&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;^2)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;用优先队列优化-dijkstra-算法&quot;&gt;用优先队列优化 Dijkstra 算法&lt;/h3&gt;

&lt;h4 id=&quot;伪代码-26&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/d3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/d4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-13&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;\cdot \log{&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;})$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;bellman-ford&quot;&gt;Bellman-Ford&lt;/h3&gt;

&lt;h4 id=&quot;问题背景-1&quot;&gt;问题背景&lt;/h4&gt;

&lt;p&gt;当图中存在&lt;strong&gt;负权边&lt;/strong&gt;时，Dijkstra 算法不适用&lt;/p&gt;

&lt;h4 id=&quot;问题定义-11&quot;&gt;问题定义&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/bf1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;算法思想-6&quot;&gt;算法思想&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/bf2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;伪代码-27&quot;&gt;伪代码&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/bf3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/bf4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;时间复杂度-14&quot;&gt;时间复杂度&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;\cdot&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;all-pairs-shortest-path-所有点对最短路径&quot;&gt;All-Pairs Shortest Path (所有点对最短路径)&lt;/h2&gt;

&lt;h3 id=&quot;问题定义-12&quot;&gt;问题定义&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/ap1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;问题分析-2&quot;&gt;问题分析&lt;/h3&gt;

&lt;p&gt;$D[k,i,j]$：可以从前 $k$ 个点选点经过时，$i$ 到 $j$ 的最短距离&lt;/p&gt;

&lt;h3 id=&quot;递推关系建立-5&quot;&gt;递推关系建立&lt;/h3&gt;

\[D[k,i,j]=\min
\left\{
\begin{array}{l}
D[k-1,i,j]\\
D[k-1,i,k]+D[k-1,k,j]
\end{array}
\right.\]

&lt;h3 id=&quot;伪代码-28&quot;&gt;伪代码&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/sp2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/ap3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;时间复杂度-15&quot;&gt;时间复杂度&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$O(&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;^3)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post/short.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;dealing-with-hard-problems&quot;&gt;Dealing with Hard Problems&lt;/h1&gt;

&lt;h2 id=&quot;definition-2&quot;&gt;Definition&lt;/h2&gt;

&lt;h3 id=&quot;input-size&quot;&gt;Input Size&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;input size&lt;/strong&gt; of a problem is the &lt;strong&gt;minimum number&lt;/strong&gt; of bits ({0, 1}) needed to encode the input of the problem.&lt;/p&gt;

&lt;h3 id=&quot;decision-problem&quot;&gt;Decision Problem&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;decision problem&lt;/strong&gt; is a question that has two possible answers: &lt;strong&gt;yes&lt;/strong&gt; and &lt;strong&gt;no&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If $L$ is the problem and $x$ is the input, we often write $x\in L$ to denote a &lt;strong&gt;yes&lt;/strong&gt; and $x\not\in L$ to denote a &lt;strong&gt;no&lt;/strong&gt; answer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;optimization-problem&quot;&gt;Optimization Problem&lt;/h3&gt;

&lt;p&gt;An &lt;strong&gt;optimization problem&lt;/strong&gt; requires an answer that is an optimal configuration.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;An optimization problem usually has a corresponding decision problem.&lt;/p&gt;

  &lt;p&gt;For almost all optimization problems there exists a corresponding simpler decision problem.&lt;/p&gt;

  &lt;p&gt;Thus if we prove that a given problem is hard to solve efficiently, then it is obvious that the optimization problem must be (at least as) hard.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;yes--no-input&quot;&gt;Yes / No Input&lt;/h3&gt;

&lt;p&gt;An instance of a decision problem is called a &lt;strong&gt;yes-input&lt;/strong&gt; (respectively no-input) if the answer to the instance is &lt;strong&gt;yes&lt;/strong&gt; (respectively no).&lt;/p&gt;

&lt;h3 id=&quot;polynomial-time&quot;&gt;Polynomial-time&lt;/h3&gt;

&lt;p&gt;An algorithm is &lt;strong&gt;polynomial-time&lt;/strong&gt; if its running time is $O(n^k)$, where $k$ is a constant independent of n, and n is the &lt;strong&gt;input-size&lt;/strong&gt; of the problem that the algorithm solves.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Whether you use $n$ or $n^\alpha$ (for fixed a &amp;gt; 0) as the input size, it will not affect the conclusion of whether an algorithm is polynomial time.&lt;/p&gt;

  &lt;p&gt;Polynomial-time algorithm is “practical” and exponential-time algorithm is not.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;p&quot;&gt;P&lt;/h3&gt;

&lt;p&gt;The class &lt;strong&gt;P&lt;/strong&gt; consists of all &lt;strong&gt;decision problems&lt;/strong&gt; that are solvable in &lt;strong&gt;polynomial time&lt;/strong&gt;. That is, there exists an algorithm that will &lt;strong&gt;decide&lt;/strong&gt; in polynomial time if any given input is a yes-input or a no-input.&lt;/p&gt;

&lt;h3 id=&quot;certificate&quot;&gt;Certificate&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;certificate&lt;/strong&gt; is a specific object corresponding to a &lt;strong&gt;yes-input&lt;/strong&gt;, such that it can be used to show that the input is &lt;strong&gt;indeed&lt;/strong&gt; a yes-input.&lt;/p&gt;

&lt;h3 id=&quot;np&quot;&gt;NP&lt;/h3&gt;

&lt;p&gt;The class &lt;strong&gt;NP&lt;/strong&gt; consists of all &lt;strong&gt;decision problems&lt;/strong&gt; such that, for each yes-input, there exists a &lt;strong&gt;certificate&lt;/strong&gt; which allows one to verify in &lt;strong&gt;polynomial time&lt;/strong&gt; that the input is indeed a yes input.&lt;/p&gt;

&lt;h3 id=&quot;polynomial-time-reducible&quot;&gt;Polynomial-time reducible&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Let $L_1$ and $L_2$ be two decision problems.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;strong&gt;polynomial-time reduction&lt;/strong&gt; from $L_1$ to $L_2$ is a transformation $f$ with the following two properties:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;$f$ transforms an input x for $L_1$ into an input $f(x)$ for $L_2$ such that: a yes-input of $L_1$ maps to a yes-input of $L_2$, and a no-input of $L_1$ maps to a no-input of $L_2$.&lt;/li&gt;
      &lt;li&gt;$f(x)$ is computable in &lt;strong&gt;polynomial time&lt;/strong&gt; (in size (x))&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;If such $f$ exists, we say that $L_1$ is &lt;strong&gt;polynomial-time reducible&lt;/strong&gt; to $L_2$, and write $L_1\le pL_2$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;If $L_2$ is polynomial-time algorithm, so is $L_1$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;np-complete-npc&quot;&gt;NP-Complete (NPC)&lt;/h3&gt;

&lt;p&gt;The class &lt;strong&gt;NPC&lt;/strong&gt; of &lt;strong&gt;NP-Complete&lt;/strong&gt; problems consists of all decision problems $L$ such that&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$L\in NP$&lt;/li&gt;
  &lt;li&gt;for every $L’\in NP$, $L’\le pL$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Intuitively, NPC consists of all the hardest problems in NP.&lt;/p&gt;

&lt;h3 id=&quot;np-hard&quot;&gt;NP-Hard&lt;/h3&gt;

&lt;p&gt;A problem $L$ is &lt;strong&gt;NP-Hard&lt;/strong&gt; if problem in NPC can be &lt;strong&gt;polynomially reduced&lt;/strong&gt; to it. (but $L$ does &lt;strong&gt;not&lt;/strong&gt; need to be in NP)&lt;/p&gt;

&lt;h2 id=&quot;theorem&quot;&gt;Theorem&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;If $L_1\le p L_2$ and $L_2\in P$, then $L_1\in P$&lt;/li&gt;
  &lt;li&gt;If $L_1\le p L_2$ and $L_2\le p L_3$, then $L_1\le p L_3$&lt;/li&gt;
  &lt;li&gt;If &lt;strong&gt;there is&lt;/strong&gt; a polynomial-time algorithm for $L\in NPC$, then there is a polynomial-time algorithm for &lt;strong&gt;every&lt;/strong&gt; $L’\in NP$&lt;/li&gt;
  &lt;li&gt;If &lt;strong&gt;there is no&lt;/strong&gt; polynomial-time algorithm for $L\in NPC$, then there is  no polynomial-time algorithm for &lt;strong&gt;every&lt;/strong&gt; $L’\in NPC$&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;h3 id=&quot;p-1&quot;&gt;P&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;判断给定图是否为树&lt;/li&gt;
  &lt;li&gt;DFS, BFS&lt;/li&gt;
  &lt;li&gt;DMST，最小生成树决策类&lt;/li&gt;
  &lt;li&gt;2-SAT&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;np-1&quot;&gt;NP&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;D-SubsetSum&lt;/li&gt;
  &lt;li&gt;DVC (Decision Vertex Cover)&lt;/li&gt;
  &lt;li&gt;SAT (Satisfiability)&lt;/li&gt;
  &lt;li&gt;3-SAT&lt;/li&gt;
  &lt;li&gt;DMST&lt;/li&gt;
  &lt;li&gt;DKnapsack&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;np-complete&quot;&gt;NP-Complete&lt;/h3&gt;

&lt;p&gt;Knapsack&lt;/p&gt;

&lt;p&gt;NPC&lt;/p&gt;

&lt;p&gt;DCLIQUE&lt;/p&gt;

&lt;p&gt;Decision Vertex Cover&lt;/p&gt;

&lt;p&gt;Decision Independent Set&lt;/p&gt;

&lt;h2 id=&quot;question&quot;&gt;Question&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Question&lt;/th&gt;
      &lt;th&gt;Answer&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$P\subseteq NP $&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$NP\subseteq P$&lt;/td&gt;
      &lt;td&gt;unknown&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$NPC\subseteq NP $&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$P=NP $&lt;/td&gt;
      &lt;td&gt;unknown&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</content><author><name>ericaaaaaaaa</name></author><category term="Algorithms" /><category term="note" /><category term="algorithm" /><summary type="html">Introduction</summary></entry></feed>