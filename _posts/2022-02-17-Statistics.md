---
layout: post
title: 概率论与数理统计
subtitle: 统计学学习笔记
categories: Statistics
tags: note statistics math
---

# 样本空间与概率

## 集合

### 集合运算

### 集合的代数

## 概率模型

### 样本空间和事件

### 选择适当的样本空间

### 序贯模型

### 概率律

### 离散模型

### 连续模型

### 概率律的性质

### 模型和现实

## 条件概率

### 条件概率是一个概率律

### 利用条件概率定义概率模型

## 全概率定义和贝叶斯准则

## 独立性

### 条件独立

### 一组事件的独立性

### 可靠性

### 独立试验和二项概率

## 计数法

### 计数准则

### n 选 k 排列

### 组合

### 分割

# 离散随机变量

## 基本概念

**与随机变量有关的主要概念**

* **随机变量**是试验结果的实值函数。
  
  > 注意：随机变量需要有数学取值（随机变量的取值），而不能是一个序列或其它无明显取值的量。
* **随机变量的函数**定义了另一个随机变量。
* 对于一个随机变量，可以定义一些平均量，如**均值**和**方差**。
* 可以在某事件或随机变量的**条件**之下定义一个随机变量。
* 存在一个随机变量与某事件或某随机变量相互**独立**的概念。

**随机变量的分类**

* **离散随机变量**
* **连续随机变量**

**与离散随机变量相关的概念**

* **离散随机变量**是试验结果的一个实值函数，但是它的取值范围只能是有限多个值或可数无限多个值。
* 一个随机变量有一个**分布列**，它对于随机变量的每一个取值，给出一个概率。
* **离散随机变量函数**也是一个离散随机变量，它的分布列可以从原随机变量的分布列得到。

## 分布列

用**分布列**表示离散随机变量的取值概率的特征。用 $p_X$ 表示随机变量 $X$ 的分布列。设 $x$ 是随机变量 $X$ 的取值，则 $X$ 取值为 $x$ 的概率定义为事件 ${X=x}$ 的概率，即所有与 $x$ 对应的试验结果所组成的事件的概率，用 $p_X(x)$ 表示。

$$
p_X(x) = P(\{X=x\})
$$

> 约定：用大写字母表示随机变量，用小写字母表示实数。

**分布列的性质**：

$$
\sum_x p_X(x) = 1\\
P(X\in S) = \sum_{x\in S}p_X(x)
$$

### 伯努利随机变量

> 背景：抛掷一枚硬币，正面向上的概率为 $p$，反面向上的概率为 $1-p$。

伯努利随机变量呈 0-1 分布，其分布列为：

$$
p_X(k) =
\left\{
    \begin{array}{l}
        p & 若 k=1\\
        1-p & 若 k=0
    \end{array}
\right.
$$

### 二项随机变量

> 背景：将一枚硬币抛掷 $n$ 次，每次抛掷，正面出现的概率为 $p$，反面出现的概率为 $1-p$，而且各次抛掷是相互独立的。

分布列：

$$
p_X(k) =
\left(
    \begin{array}{l}
        n \\
        k
    \end{array}
\right)
p^k(1-p)^{n-k}
$$

### 几何随机变量

### 泊松随机变量

## 随机变量的函数

## 期望、均值和方差

### 方差、矩和随机变量的函数的期望规则

### 均值和方差的性质

### 某些常用的随机变量的均值和方差

### 利用期望值进行决策

## 多个随机变量的联合分布列

### 多个随机变量的函数

### 多于两个随机变量的情况

## 条件

### 某个事件发生的条件下的随机变量

### 给定另一个随机变量的值的条件下的随机变量

### 条件期望

## 独立性

### 随机变量与事件的相互独立性

### 随机变量之间的相互独立性

### 几个随机变量的相互独立性

### 若干个相互毒瘤的随机变量的和的方差

# 一般随机变量

## 连续随机变量和概率密度函数

# 经典统计推断

> 本章中认为未知参数 $\theta$ 是确定（非随机）的，而取值未知。观测 $X$ 是随机的，根据 $\theta$ 取值的不同，服从 $p_X(x;\theta)$（若 $X$ 是离散的）或 $f_X(x;\theta)$（若 $X$ 是连续的）。

**本章的主要术语、问题和方法**

* **经典估计**是将未知参数看作是待确定的常数。对于未知参数的每个可能取值都假设一个单独的概率模型。
* 在**参数估计**中，希望找到在未知参数取任何可能值的情况下都基本正确的估计。
* 在**假设检验**中，未知参数对应于对立假设取有限的 $m(m\ge 2)$ 个值，想要选择一个假设，使得在任何可能的假设下错误的概率最小。

**本章主要的经典推断方法**

* **最大似然估计**：选择参数使得被观测到的数据“最有可能”出现，比如使获得当前数据的概率最大。
* **线性回归**：在这样的意义下找出一组成对数据之间最合适的线性关系：这种线性关系使得模型与真实数据之间的差值的平方和最小
* **似然比检验**：给定两个假设，根据它们发生“可能性”的比值选择其一，使得犯错的概率适当小。
* **显著性检验**：给定一个假设，当且仅当观测数据落在某个拒绝域的时候拒绝该假设，特别设计的拒绝域使得错误的概率低于某个给定阈值。

## 经典参数估计

将参数 $\theta$ 看作未知常数，而不是随机变量。

### 估计量的性质

给定观测 $X=(X_1, ..., X_n)$，**估计量**是指形式为 $\hat{\Theta}=g(X)$ 的随机变量。注意，由于 $X$ 的分布依赖于 $\theta$，因而 $\hat{\theta}$ 的分布也一样。估计量 $\theta$ 的取值称为**估计值**。

**估计量的相关术语**

$\hat{\Theta}$ 是未知参数 $\theta$ 的一个**估计量**，也即关于 $n$ 个观测 $X_1, ..., X_n$（服从依赖参数 $\theta$ 的分布）的一个函数。

* **估计误差**，记为 $\tilde{\Theta}_n$，定义为 $\tilde{\Theta}_n=\hat{\Theta}_n-\theta$
* **估计量的偏差**，记为 $b_\theta(\hat{\Theta}_n)$，是估计误差的期望值
  $$
  b_\theta(\hat{\Theta}_n) = \textnormal{E}_\theta[\hat{\Theta}_n]-\theta
  $$
* $\hat{\Theta}$ 的期望值、方差和偏差都依赖于 $\theta$，而估计误差同时还依赖于观测 $X_1, ..., X_n$
* 称 $\hat{\Theta}_n$ **无偏**，若 $\textnormal{E}_\theta[\hat{\Theta}_n] = \theta$ 对于 $\theta$ 所有可能的取值都成立。
* 称 $\hat{\Theta}_n$ **渐近无偏**，若 $\lim_{n\rightarrow\infty}\textnormal{E}_\theta[\hat{\Theta}_n] = \theta$ 对于所有可能的取值都成立。
* 称 $\hat{\Theta}_n$ 为 $\theta$ 的**相合**估计序列，如果对于 $\theta$ 所有可能的取值，序列 $\hat{\Theta}_n$ 依概率收敛到参数 $\theta$ 的真值。

$$
\textnormal{E}_\theta[\tilde{\Theta}_n^2]=b_\theta^2(\hat{\Theta}_n)+\textnormal{var}_\theta(\hat{\Theta}_n)
$$

### 最大似然估计

设观测向量 $X=(X_1,...,X_n)$ 的联合分布列为 $p_X(x;\theta)=p_X(x_1, ..., x_n;\theta)$（$\theta$ 可为向量或数量），其中 $X = (X_1, ..., X_n)$ 为 $X$ 的观测值。那么，**最大似然估计**是使（$\theta$ 的）数值函数 $p_X=(x_1, ..., x_n;\theta)$ 达到最大的参数值：

$$
\hat{\theta}_n=\underset{\theta}{\argmax} p_X(x_1, ..., x_n;\theta)
$$

当 $X$ 为连续型随机变量时，可将同样的方法用于联合概率密度函数 $f_X(x;\theta)$

$$
\hat{\theta}_n=\underset{\theta}{\argmax} f_X(x_1, ..., x_n;\theta)
$$

称 $p_X(x;\theta)$（或 $f_X(x;\theta)$，若 $X$ 为连续型随机变量）为**似然函数**。

> 对于已知 $X$ 的观测值 $x$，$p_X(x;\theta)$ 不是未知参数等于 $\theta$ 的概率，而是当参数取值为 $\theta$ 时，观测值 $x$ 可能出现的概率。
> 为取定 $\theta$ 的估计值时，会考虑基于已知的观测，$\theta$ 取什么值可使观测值最可能出现，这就是“似然”的本意。

很多应用中都假设观测 $X_i$ 独立，从而对于每个 $i$，$X_i$ 是离散的随机变量，似然函数的形式为

$$
p_X(x_1,...,x_n;\theta)=\prod_{i=1}^n p_{X_i}(x_i;\theta)
$$

在这种情况下，为了分析和计算的方便可让其对数达到最大，下面的式子称为**对数似然函数**。

$$
\ln p_X(x_1,...,x_n;\theta) =\ln \prod_{i=1}^n p_{X_i}(x_i;\theta) = \sum_{i=1}^n\ln p_{X_i}(x_i;\theta)
$$

当 $X$ 为连续型随机变量时，类似的用概率密度函数取代分布列：

$$
\ln f_X(x_1,...,x_n;\theta) =\ln \prod_{i=1}^n f_{X_i}(x_i;\theta) = \sum_{i=1}^n\ln f_{X_i}(x_i;\theta)
$$

### 随机变量均值和方差的估计

### 置信区间

### 基于方差近似估计量的置信区间

## 线性回归

### 最小二乘公式的合理性

### 贝叶斯线性回归

### 非线性回归

## 简单假设检验

### 假设检验的基本思想与概念

#### 假设检验问题

假如试验结果与假设 H 发生矛盾就拒绝原假设 H，否则就接受原假设。

* **假设**：如 $\theta\in\Theta_0$ 或 $\theta\in\Theta_1$
* **检验**或**检验法则**：通过样本对一个假设作出“对”或“不对”的具体判断的规则称为该假设的一个检验或检验法则。
  
  > 检验的结果若是肯定该命题，则接受这个假设，否则就拒绝该假设。
* **参数假设检验问题** & **非参数假设检验问题**：若假设可用一个参数的集合表示，该假设问题称为**参数假设检验问题**，否则称为**非参数假设检验问题**。

#### 假设检验的基本步骤

> 一般情况下，寻找某对假设的显著性检验的步骤如下：
> * 根据实际问题，建立统计假设 $H_0$ vs $H_1$
> * 选取一个合适的检验统计量 $T(X)$，使得当 $H_0$ 成立时（或 $H_0$ 中某个具体参数下），$T$ 的分布完全已知，并根据 $H_0$ 及 $H_1$ 的特点，确定拒绝域 $W$ 的形状
> * 确定显著性水平 $\alpha$，确定具体的拒绝域 $W$
> * 由样本观测值 $x_1,x_2,...,x_n$，计算检验统计量的 $T(x_1,...,x_n)$，由 $T(x_1,...,x_n)$ 是否属于 $W$，做出最终判断。

##### 一、建立假设

> 背景：
> 设有来自某一个参数分布族 $\{F(x,\theta)|\theta\in\Theta\}$ 的样本 $x_1, x_2,...,x_n$，其中 $\Theta$ 为**参数空间**，设 $\Theta_0\subset \Theta$，且 $\Theta_0\not ={\emptyset}$，则命题 $H_0:\theta\in\Theta_0$ 称为一个假设或**原假设**或**零假设** (null hypothesis)，若有另一个 $\Theta_1(\Theta_1\subset\Theta$，$\Theta_1\Theta_0=\emptyset$，常见的一种情况是 $\Theta_1=\Theta-\Theta_0)$，则命题 $H_1:\theta\in\Theta_1$ 称为 $H_0$ 的**对立假设**或**备择假设**。

$H_0:\theta\in\Theta_0\qquad vs\qquad H_1:\theta\in\Theta_1$

* **简单原假设**与**复杂原假设**：如果 $\Theta_0$ 只含一个点，我们称之为**简单原假设**，否则称之为**复杂**或**复合**原假设。
* **双侧假设**或**双边假设**：备择假设分散在原假设两侧，如 $H_1':\theta\not ={\theta_0}$，$H_1'':\theta<\theta_0$……
* **单侧假设**或**单边假设**：备择假设位于原假设的一侧

##### 二、选择检验统计量，给出拒绝域形式

* **假设的检验**：对于假设的**检验**是指这样的一个法则：当有了具体的样本后，按该法则就可以决定是接受 $H_0$ 还是拒绝 $H_0$，即检验就等于把样本空间划分为两个互不相交的部分 $W$ 和 $\overline{W}$，当样本属于 $W$ 时，拒绝 $H_0$；否则接受 $H_0$。
* **拒绝域**与**接受域**：称 $W$ 为该假设的**拒绝域**，而 $\overline{W}$ 称为**接受域**。
* **检验统计量**：由样本对原假设进行检验通过的统计量。
* 检验的**判断准则**：
  * 若 $(x_1,...,x_n)\in W$，则拒绝 $H_0$
  * 若 $(x_1,...,x_n)\in \overline{W}$，则接受 $H_0$

##### 三、选择显著性水平

* **第一类错误**与**第二类错误**
  | 观测数据情况 | $H_0$ 为真 | $H_1$ 为真 |
  | --- | --- | --- |
  | $(x_1, x_2,..., x_n)\in W$ | 犯第一类错误 | 正确 |
  } $(x_1, x_2,..., x_n)\in \overline{W}$ | 正确 | 犯第二类错误 |
  * 称第一类错误为**拒真错误**
  * 称第二类错误为**取伪错误**
* $\alpha$：犯第一类错误的概率：$\alpha=P_\theta\{X\in W\},\theta\in\Theta_0$，也记为 $P\{X\in W|H_0\}$
* $\beta$：犯第二类错误的概率：$\beta=P_\theta\{X\in\overline{W}|H_1\}$
* **势函数**或**功效函数** (power function)
  设检验问题 $H_0:\theta\in\Theta_0\qquad vs\qquad H_1:\theta\in\Theta_1$ 的拒绝域为 $W$，则样本观测值 $X$ 落在拒绝域 $W$ 内的概率称为该检验的**势函数**，记为 $g(\theta)=P_\theta(X\in W)$，$\theta\in\Theta=\Theta_0\cup\Theta_1$

$$
g(\theta) = 
\left\{
  \begin{array}
    \alpha(\theta) & \theta\in\Theta_0\\
    1-\beta(\theta) & \theta\in\Theta_1
  \end{array}
\right.
$$

或

$$
g(\theta) = 
\left\{
  \begin{array}
    \alpha(\theta) = g(\theta) & \theta\in\Theta_0 \\
    \beta(\theta) = 1-g(\theta) & \theta\in\Theta_1
  \end{array}
\right.
$$

* **显著性水平为 $\alpha$ 的显著性检验**：对检验问题 $H_0:\theta\in\Theta_0\qquad vs\qquad H_1:\theta\in\Theta_1$，如果一个检验满足对任意的$\theta\in\Theta_0$，都有 $g(\theta)\le\alpha$，则称该检验是显著性水平为 $\alpha$ 的显著性检验。
  
  > 常用的选择是 $\alpha = 0.05$，有时也可以选择 $\alpha=0.10$ 或 $\alpha=0.01$

##### 四、给出拒绝域

##### 五、做出判断

#### 检验的 p 值

* **检验的 p 值**：再一个假设检验问题中，利用样本观测能够做出拒绝原假设的最小显著性水平称为检验的 p 值。
  * 如果 $\alpha \ge p$，则再显著性水平 $\alpha$ 下拒绝 $H_0$
  * 如果 $\alpha < p$，则在显著性水平 $\alpha$ 下接受 $H_0$

## 正态总体参数假设检验

### 单个正态总体均值的检验

设 $x_1, ..., x_n$ 是来自 $N(\mu,\sigma^2)$ 的样本，考虑如下三种关于 $\mu$ 的检验问题：

$$
I\qquad H_0:\mu\le \mu_0 \qquad vs \qquad H_1:\mu>\mu_0\\
II\qquad H_0:\mu\ge\mu_0\qquad vs\qquad H_1:\mu<\mu_0 \\
III\qquad H_0:\mu = \mu_0\qquad vs\qquad H_1:\mu\not ={\mu_0}
$$

其中 $\mu_0$ 是已知常数。

#### 一、$\sigma$ 已知时的 $u$ 检验

* **检验统计量** $u = \frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}$
  * 由于 $\mu$ 的点估计是 $\overline{x}$，且 $\overline{x}\sim N(\mu, \sigma^2/n)$
* **拒绝域** $W_1=\{(x_1,...,x_n):u\ge c\}$


## 显著性检验

### 一般方法

### 广义似然比和拟合优度检验